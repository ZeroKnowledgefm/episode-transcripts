00:05: Anna Rose:


Welcome to Zero Knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online.


00:27:


This week, Tarun, Guillermo, Alex Evans and I catch up for a spontaneous, in-person, end-of-year episode. We were all on the West Coast at the same time, and so had a chance to do a look back at 2023. We cover what each of us were thinking earlier this year and how the year has evolved for us. We cover many of the topics that are relevant in ZK and beyond, as well as try to paint a bit of a picture of how 2023 differed from 2022 - that is the year where almost everything that could blow up did blow up. 2023 was definitely rosier. So yeah, hope you enjoy.


01:03:


Now, before we kick off, I do wanna let you know about our upcoming multi-week virtual event, ZK Hack IV. Starting on January 16th, 2024, and running until February 6th, we will be hosting weekly workshops with top teams in ZK, showcasing the state of the art in tooling for ZK builders. Each week, we also host a ZK puzzle hacking competition. We share a system that has something wrong with it. You are meant to find the bug, hack the protocol, and the fastest hacker will make their way to the top of the ZK Hack leaderboard for prizes and glory. This is our fourth time running this event series. Thousands of hackers have participated over the last two years, so you may have been to one of our online events already. As you know, it's not a hackathon, but rather it's a chance to learn the latest in ZK tools with members of the ZK Hack community from around the world. Because it runs over a few weeks, people often make friends, find future colleagues or co-founders, and also get a chance to really dive into the ZK world with us. It's free and open to all. In the show notes, I've added the link to the first event of ZK Hack IV, that is our kickoff session happening on January 16th. In this, we will be introducing you to the larger event series and to our workshop hosts and partners. Then, Kobi, Nico, and I are planning on doing a pretty exciting intro session, helping you become more familiar with the concepts and terms used in ZK. You won't want to miss it. So hope to see you there. Now Tanya will share a little bit about this week's sponsor.


02:36: Tanya: 


Aleo is a new layer-1 blockchain that achieves the programmability of Ethereum, the privacy of Zcash, and the scalability of a rollup. Driven by a mission for a truly secure internet, Aleo has interwoven zero-knowledge proofs into every facet of their stack, resulting in a vertically integrated layer-1 blockchain that's unparalleled in its approach. Aleo is ZK by design. Dive into their programming language, Leo, and see what permissionless development looks like, offering boundless opportunities for developers and innovators to build ZK apps. As Aleo is gearing up for their mainnet launch in Q1, this is an invitation to be part of a transformational ZK journey. Dive deeper and discover more about Aleo at aleo.org. And now, here's our episode.


03:24: Anna Rose: 


It's so fun to get a chance to do a little recap with all of you. I'm here with Guillermo.


03:30: Guillermo Angeris:


What up?


03:31: Anna Rose:


Often a frequent co-host.


03:34: Guillermo Angeris:


For better or worse.


03:34: Anna Rose:


Tarun.


03:35: Tarun Chitra:


Aloha. I've now been upgraded, by the way. I'm not just a co-host. I've been promoted to the chief marketing officer for the ZK podcast.


03:42: Anna Rose:


Who's the only person who takes photos and shares it on Twitter beforehand?


03:47: Tarun Chitra:


Yes.


03:47: Anna Rose:


Correct. Tarun, also longstanding co-host of the show. Alex, not co-host, but many-time guest. Multi-time guest.


03:56: Alex Evans:


So I get a prize for... What are we at?


03:58: Tarun Chitra:


Four or five?


03:58: Anna Rose:


I think four or five for you.


03:59: Alex Evans:


Wow.


04:00: Anna Rose:


It's quite rare. So welcome back.


04:03: Alex Evans:


I'm so sorry.


04:04: Anna Rose:


So we're going to be doing a very impromptu end-of-year episode. We actually did that last year, where we split it in two. We did an end-of-year at the end, and then another one looking forward. So for this one, we're going to do the look back. Yeah, Guillermo, you weren't in it, don't worry.


04:19: Guillermo Angeris:


Oh, I see. That's fine. I was like, wow, I don't...


04:21: Anna Rose:


You were in the look forward.


04:22: Guillermo Angeris:


Yeah, I thought I was one of them.


04:24: Anna Rose:


Oh, I think you were in both, actually. 


04:28: Guillermo Angeris:


I mean, I don't know. 


04:28: Anna Rose:


Anyway.


04:29: Alex Evans:


This one's going to expose some gaping holes in our memory.


04:31: Guillermo Angeris:


Yeah, this is really bad. Maybe I should stop with the drinking.


04:33: Anna Rose:


Actually, last year when we did the look back, we couldn't remember. I remember it now that we were trying to think back, and the only way to kind of cover 2022, was to do a rundown of the catastrophes one after another after another. And we were trying to figure out the order of them, which came first, what happened when... This year, looking back, I think it's going to be different.


05:01: Tarun Chitra:


Yeah. I would describe last year's episode as taking a single picture of a failed Jenga game where the pieces are on the floor and trying to reassemble the...


05:10: Anna Rose:


Or trying to remember the way you got there.


05:12: Tarun Chitra:


The way you got there. Right.


05:14: Anna Rose:


Yeah.


05:14: Guillermo Angeris:


See, now we have a Michael Lewis book about it, so it's fine.


05:17: Anna Rose:


Very accurate.


05:20: Tarun Chitra:


I didn't read it, but I'm in it. Katie did read it.


05:23: Anna Rose:


You are in it, I heard, yeah.


05:26: Guillermo Angeris:


Yeah, yeah, yeah. And she saw your name and was like, wait, this is Tarun, right?


05:29: Anna Rose:


Wild.


05:30: Guillermo Angeris:


That's about as far as I know of it.


05:32: Anna Rose:


So to start this one off, though, I want us to go back to the beginning of the year. Put yourself back, January 2023. What were you thinking? What were you working on? What was on your mind?


05:47: Alex Evans:


What were you thinking is right. What were we all thinking?


05:50: Guillermo Angeris:


A valid question in many contexts.


05:54: Tarun Chitra:


I was actually worried about not crypto stuff. I was actually worried about the fact that the open source language models were not very good. And it was sort of like ChatGPT was blowing up, and then I had all these friends who'd been working in NLP... Obviously, the field now became only about large language models. But at that time, there was still natural language processing, and I had all these friends who were post-docs or PhDs or worked at places. And all of them were just in the doldrums, despite it being such a big thing. I mean, so the most opportunistic ones of them were like, ah, I'm gonna go raise, I'm gonna pretend it's like raising for a Solana DeFi project in 2021, right? Like I get $10 million by just showing up. 


06:44: Anna Rose:


With AI on your side.


06:45: Tarun Chitra:


But the non-opportunistic ones were like, oh my God, all my research...


06:47: Alex Evans:


It was a flat circle in 2023.


06:50: Tarun Chitra:


And then the non-opportunistic ones were like, oh man, my research all sucks, it's not worth anything, like whatever, clearly all these people have these secrets. So I was actually trying to not think about crypto. I took the crypto Xanax and I forgot about it and was like, what's happening there? So...


07:10: Guillermo Angeris:


Can I have one of those?


07:12: Anna Rose:


You're talking to your AI friends, the folks working in the field. Where were you at, though? Those are what your friends were doing, but what were you doing.


07:21: Tarun Chitra:


I was doing that to distract myself from thinking about crypto. I feel like January was this point where we're like, is there anything else that can blow up? If so...


07:31: Anna Rose:


Can it happen now?


07:31: Tarun Chitra:


Man, I really don't want to know about it.


07:33: Alex Evans:


Most people take up gardening, Tarun.


07:35: Anna Rose:


I mean, had anyone floated the idea of Binance not working in January 2023?


07:42: Guillermo Angeris:


I'm sure.


07:42: Tarun Chitra:


I feel like definitely, yeah.


07:43: Guillermo Angeris:


I feel like post-FTX, people kind of immediately jumped to that.


07:47: Tarun Chitra:


There was just like FUD, FUD, FUD, FUD, FUD, FUD. It was like FUD everything.


07:51: Alex Evans:


Yeah, the Grim Reaper meme with every logo of every company in the space.


07:54: Tarun Chitra:


Exactly.


07:55: Guillermo Angeris:


In fact, someone should have had stable diffusion at that time, I guess now there's many tons of good image models, just make the Grim Reaper for every combination of crypto entities so that you're already ready for when that Grim Reaper meme was true.


08:12: Anna Rose:


I was selling the bottom, as I often do. Of course, buying a little back, at least.


08:22: Tarun Chitra:


Wait, this show can talk about price?


08:25: Anna Rose:


No price. The topic in our chats were, I mean, I don't know if it would have been January, but it would have definitely been Q1, it was the ZKML idea. I don't know if it was even proposed in 2022, but for sure, Q1 2023, it was the topic. There was a huge telegram group that had formed, a ton of projects that had never really thought about it, but they saw some connections started to jump in. And it lasted for a few months. Out of that came two companies at least, and a bunch of interesting experiments. But I would say here, now that we're at the end of the year, it's like died down. I don't think it's as hype-y at least. But we'll see if it continues on. Wait, I want to hear from Guillermo. Where were you at in January? What were you thinking about?


09:16: Guillermo Angeris:


I think this was the point at which we started trying to understand what ZK was, which is kind of funny to think about. I think at that time, I'm going to front run Alex on this, Alex and I were starting to write what then became Succinct Proofs in Linear Algebra, which we now have a course for and all this jazz, but at the time actually it was just a variety of hilariously unformed ideas and us just being mad about reading ZK papers in general and how I couldn't parse them and so Alex would go and read them for me and then explain them very carefully. I think that was mostly it. And then afterwards, it was kind of on slightly before ZK Hack Lisbon, which is kind of where things got quite interesting. And that's where we presented the work, right? A little bit or like the very early version of it, wasn't it? It was in Lisbon.


10:07: Alex Evans:


It must have been Lisbon. When was Lisbon? Was it March?


10:07: Anna Rose:


You did a Lightning talk. Yeah.


10:09: Guillermo Angeris:


Yeah. It was... Was it March?


10:10: Anna Rose:


Well, there's two events you're talking about. There's the ZK Hack Lisbon Hackathon.


10:14: Guillermo Angeris:


Oh, sorry. zkSummit.


10:14: Anna Rose:


And then there was zkSummit9 happening at the same time.


10:17: Guillermo Angeris:


That's the one. That's the one... Sorry, I meant not ZK Hack.


10:19: Anna Rose:


And you presented a Lightning talk at ZK9.


10:22: Guillermo Angeris:


That's right.


10:22: Anna Rose:


I remember after you did it, we were like, why didn't you just do a talk talk, Guillermo? So you did a very short talk, which was, I guess, the beginning of this work.


10:30: Guillermo Angeris:


That's right.


10:30: Alex Evans:
It kind of was a talk, but you just did it in fast forward.


10:33: Guillermo Angeris:


Yeah, yeah. I did a 2.5x speed, which was rather entertaining.


10:37: Anna Rose:


No need to fast forward that one.


10:41: Alex Evans:


Already Guillermo just comes out of the box at 2x speed for your viewing pleasure.


10:47: Anna Rose:


What about you Alex? You had been studying a bit more ZK before this, right?


10:51: Alex Evans:


I got stuck in California at the end of December because I had some family members visiting. And it was very rainy, and that turned out to be the natural thing to do for a couple weeks.


11:03: Anna Rose:


Learn ZK.


11:03: Alex Evans:


And Guillermo has been paying the price for the last year, and now more people have been paying the price.


11:06: Tarun Chitra:


So the commonality here is escapism was where we all were. You were escaping your relatives, I was escaping crypto.


11:16: Anna Rose:


I was just selling the bottom. I don't know what kind of escape that was.


11:22: Alex Evans:


We all cope in different ways.


11:22: Guillermo Angeris:


I was probably just drinking or something, I don't know, whatever. Or something like that.


11:27: Anna Rose:


January, I was also... I was setting in motion ZK Hack, ZK Lis... Or yeah, ZK Hack, Lisbon, and zkSummit9, which turned out to be too much, by the way. We did it back to back. My team and I ended up doing, Agni specifically, we did the ZK Hack Weekend Hackathon. We had one day off, but that night, I think we even did the speaker dinner. Then we did a full-fledged conference with 550 people or so, zkSummit9, and an after-party. So we joke about it now that we kind of threw four weddings in a row with a very small team. Because for each one of those, you had venue, menu, attendance, tickets. It was crazy.


12:14: Guillermo Angeris:


Don't tell me these things, I'm starting to think about weddings and it's...


12:18: Anna Rose:


Oh yeah.


12:18: Guillermo Angeris:


Right. So I don't know, already fell in one.


12:22: Tarun Chitra:


You only have to plan one.


12:23: Guillermo Angeris:


Yeah, I was just saying, already one is insane.


12:24: Anna Rose:


One wedding would be so easy now. And obviously these are not weddings, but it's like the level of lift is like putting together... Each one of the summits is, I mean, it's a lot of work.


12:33: Tarun Chitra:


Yeah, yeah, yeah.


12:34: Anna Rose:


Every ZK Hack is a different kind of work. It was a big challenge. We did it, we got through it. It was crazy, because like, I know the folks who came loved it. It was magical. The venues we had were amazing. And sorry, I don't mean to pat my own back here, but...


12:48: Guillermo Angeris:


No, it was sick.


12:48: Anna Rose:


It was... The outcome was amazing, but the inside for our team was so bad, like hard. But we got through it.


12:58: Alex Evans:


Thank you for your service.


12:59: Guillermo Angeris:


I was just saying, yeah, Alex and I came out of that and we were like, wait, holy shit, ZK is... Specifically after zkSummit, we were like, ZK is real.


13:08: Anna Rose:


Was it zkSummit or ZK Hack?


13:11: Guillermo Angeris:


zkSummit. Also ZK Hack as well we were quite...


13:12: Anna Rose:


ZK Hack was the first time, ZK Hack Lisbon, that was the first time we got to see people building with the tools that other teams have been creating for so long.


13:21: Guillermo Angeris:


It's possible like the energy maybe like carried over or something, but it was very clear that it was not a niche academic field that just happened to have a lot of funding anymore. It was kind of more real than we expected. I remember we had a number of long conversations immediately after zkSummit Lisbon.


13:38: Alex Evans:


And during.


13:39: Guillermo Angeris:


Yeah.


13:40: Alex Evans:


It was like the year started out, I think, people were really excited. We were really excited with some of the launches of the rollups that were being planned for the year. Early in the year, you had zkSync, and then Polygon, Scroll, a number of these.


13:54: Anna Rose:


Which one came first?


13:56: Alex Evans:


You tell us. You're the ZK historian.


13:58: Guillermo Angeris:


I think you have opinions on this.


14:00: Anna Rose:


Do I?


14:00: Alex Evans:


I'm staying out of the line of fire on this one.


14:02: Tarun Chitra:


Remember the adage from being a child, first is the worst, second is the best, third is the one with the treasure chest.


14:10: Anna Rose:


Okay. 


14:11: Tarun Chitra:


So I don't know why everyone wants to be first.


14:14: Anna Rose:


To me, I mean, I think it is zkSync Era, February?


14:18: Guillermo Angeris:


I have no idea, I don't know. I was not paying enough attention.


14:20: Alex Evans:


I'm trying to stay out of trouble.


14:20: Tarun Chitra:


Yeah, I don't need the rollup wars touching my shores. Like that Armada can stay at sea.


14:31: Guillermo Angeris:


Yeah, you haven't had problems already. You can as well keep it.


14:33: Anna Rose:


Listen to you, you're like a poet. That's lovely. I don't need these wars touching my shores. The first one is... It's very good, I like it.


14:45: Tarun Chitra:


It's great for a chief marketing officer.


14:47: Guillermo Angeris:


Yeah, you're doing it.


14:48: Anna Rose:


Speaking of ZkVMs or zkEVMs, just today we were kind of trying to map out how many there are and what's also coming down the line. I'm just gonna name a couple that I believe are live today. zkSync ZK Era, Polygon zkEVM, Scroll, Linea, NIL. There's probably more. I'm for sure missing some. But we also, I mean, I've now heard proposals for ZkVM's Taiko. There's one that's like, it's not called ZK-WASM, but it's doing ZK-WASM. There's one that's doing zkMove. There's RISC Zero, which is kind of ZK-Rust. And it's not a VM per se, but it has the testnet, what is it, Zeth? I think. Yeah. Anyways, there's a lot coming down the line.


15:43: Tarun Chitra:


I have a spicy take, which is, company is, maybe this one will make the Armada come to my shores. But any company that names themselves with a ZK prefix that uses ZK now is a little bit like people in the 90s who put an E in front of eBay, eHarmony, whatever. Some of them survived, but they didn't become the biggest.


16:05: Anna Rose:


Welcome to the ZK Podcast.


16:08: Tarun Chitra:


Well, the ZK Podcast...


16:09: Guillermo Angeris:


Was the OG.


16:10: Tarun Chitra:


Can change its name.


16:11: Guillermo Angeris:


Oh, that's also fair, I guess.


16:12: Tarun Chitra:


I feel like the company's brand equity is much harder, or the protocol's brand equity is much harder to switch.


16:20: Anna Rose:


Well, I don't want to change the name just yet.


16:22: Alex Evans:


You hire a chief marketing officer, first thing they try to do is change the name.


16:24: Anna Rose:


First thing to do is change the name, god damn it.


16:26: Guillermo Angeris:


You gotta have some sort of impact, might as well be the name and everything else.


16:28: Anna Rose:


Do you have another idea? You know?


16:31: Tarun Chitra:


No, I just think like, there's actually this thing I was thinking about the other day. I was just sorting a sheet of projects by letter, and then I counted by letter, and the Z ones were by far the most. So there's a sense in which you're kind of like drowning in the like, there are too many of them. And so I think that's something I hope people start thinking about a little bit more, is naming and nomenclature.


16:57: Anna Rose:


Remember when blockchain started, or Bitcoin started, it was bit, bit, bit, bit, yeah.


17:00: Tarun Chitra:


Block, Block, Block, Block.


17:02: Anna Rose:


Seems like a similar…


17:03: Tarun Chitra:


It's a similar, right?


17:04: Anna Rose:


There was an ETH, ETH, ETH, ETH as well.


17:07: Tarun Chitra:


Yeah, for sure. 


17:07: Anna Rose:


And you still see remnants of that.


17:09: Tarun Chitra:


But the smartest ones changed their name, right? Like Aave went from ETHLend to Aave.


17:13: Anna Rose:


Interesting.


17:14: Tarun Chitra:


Which I thought was a very good shift on their part, because ETHLend, no one will remember.


17:17: Anna Rose:


ETHLend sounds like a hackathon project, actually. And Aave doesn't. Actually, now that we mention it, the naming, so one of the things that came up right, maybe around that time, maybe around ZKSummit time, ZK9, was this concept of ZK being misused. Like ZK, zero knowledge, the privacy part of a ZK SNARK, a lot of teams were using SNARKs, but not the privacy part, so are they really ZK? And I know Justin Thaler wrote this like “17 misconceptions about Zero Knowledge”, I think. And one of them was this naming, or maybe around SNARKs. Anyway, I just remember that being a topic. I, unpopularly with some folks, landed on the side of “I think it's a good shorthand for advanced cryptography.” But not everyone agrees with me.


18:10: Tarun Chitra:


I think it's a good way to get LP dollars into the space, because they only have to remember two letters, and their attention span is near zero. 


18:18: Anna Rose:
But I think the counter to my opinion is that it, I mean... 


18:24: Tarun Chitra:


Dilutes a lot of different things.


18:25: Anna Rose:


For sure. And the fact that a lot of SNARKs, they have no privacy component, people may actually think there is a privacy component.


18:33: Guillermo Angeris:


Honestly, who cares? I think crypto, meaning cryptocurrency, is great, actually, more than cryptography.


18:37: Tarun Chitra:


Yeah, this feels...


18:38: Guillermo Angeris:


Like whatever.


18:40: Anna Rose:


Cryptography, not crypto.


18:43: Tarun Chitra:


If I go through the Shamir hierarchy of controversies in crypto, it's like additive notation versus multiplicative notation.


18:51: Guillermo Angeris:


Oh, that's horrible.


18:52: Tarun Chitra:


It's crypto, cryptocurrency or cryptography. And now I think it's the, is ZK allowed to be used for things that don't have privacy?


18:59: Alex Evans:


Even triggered Guillermo, you're just going to trigger everybody.


19:01: Anna Rose:


But what about ZK being used for the blanket... Like the blanket term for MPC, FHE...


19:06: Tarun Chitra:


FHE, everything yeah.


19:06: Anna Rose:


Threshold decryption, all of that?


19:08: Tarun Chitra:


I mean, every talk I've given this year, I preface almost every time this thing of, I'm using ZK as the Royal ZK. Here I mean things that don't have privacy, SNARKs, STARKs, FHE, MPC. And I've learned that by doing that, you disarm people who are about to come out with the...


19:26: Guillermo Angeris:


With the claws.


19:26: Tarun Chitra:


The musket ready.


19:27: Guillermo Angeris:


Oh yeah. 


19:29: Anna Rose:


You wink before they can shoot.


19:31: Tarun Chitra:


ZK Musketeers.


19:32: Anna Rose:


Yeah.


19:34: Guillermo Angeris:


Musketeers.


19:36: Tarun Chitra:


Musketeers


19:37: Anna Rose:


Ooh. Because we mentioned the ML stuff, Kobi and I and Daniel Kang did this experiment. Tarun, you had invited Yi and Daniel on the show. I had never met them. It was an amazing episode. I'm going to try to find a link, add it to the show notes. Dan Boneh had introduced me to this before, this idea of attested images, like where you'd create an original image with some sort of signature and then use ZKPs through every transformation. So like an edit, crop, like a filter or something. Every time you added something to it, you would use a ZKP to prove that it comes from the original source. And then Yi and Daniel came on and kind of repeated it. And from there, Kobi, Daniel, and I created something called the Attested Audio Experiment, where we showed kind of provenance, the same idea that I just described for images, but for audio.


20:27:


And actually, the thing that prompted that was the zkpod.ai project that Kobi made, which we did a whole episode on that too, where you can actually ask this thing, it exists online, you can ask it a question using the transcripts. It was fed into an LLM and it will give you an answer to a question about ZK in my voice or in Kobi's voice. And that freaked me out, made me realize, I could be replaced, what if someone doesn't know? What if it says something and they think it's me? The attested audio experiment is meant as a counter to that. And so that was happening in April, actually just after the summit. Or even maybe just before. It was crazy, because while I was planning those two things, those two events, the four events actually, Kobi was like, check out this thing before we released it. And it was like a little bit of an existential moment.


21:17: Tarun Chitra:


I remember you were...


21:18: Anna Rose:


I was kind of freaked out.


21:19: Guillermo Angeris:


You released a whole note on it, I remember, right after...


21:21: Anna Rose:


Yeah, blog post.


21:23: Guillermo Angeris:


Yeah, blog post, right. Actually, we even talked about it in the episode with Nico a little bit, too. 


21:27: Anna Rose:


Yeah, back then. 


21:29: Tarun Chitra:


How do you feel about it now?


21:30: Anna Rose:


I find it less terrifying.


21:33: Tarun Chitra:


Because these models are not very good.


21:35: Anna Rose:


Yeah, I find it a little less... I don't know. We also... I mean, we want to do more things with it but to develop it further into something is quite a lot of work to create something that... I mean, I think the idea there was like, what if we could make it ask the questions I ask on the podcast? What if we could have it host an interview or something? I think to get there, we're still a ways off.


21:59 Tarun Chitra:


Yeah. I think an interesting fact, not that this is ZK or crypto at all, but the thing I was worried, I had this fear from all these people who I knew working in AI, that the open source stuff would never compete. So then your only choice was to go work at OpenAI or Anthropic or whatever. Turned out to be not true. I'd say the performance of open source models, the infrastructure for fine tuning got so much better in the last six to nine months. It's sort of adjacent to crypto because a lot of the open source model infrastructure is built off all the old mining data centers that people use because they just repurpose them to have H100s or A100s really for the longest time. Because they had these data centers that's cheap electricity, they had all the... They optimized them for a very similar performance use case. Proof-of-stake happened in Ethereum. Suddenly the only thing you can mine are kind of shit PoW coins that are not profitable. Shit meaning it's very hard to be profitable mining them. And so people basically repurpose all these data centers, and then the infrastructure, the open source model training got so much better, I think, over the last three to six months. The fact that Mistral can beat GPT 3.5, Mistral just was launched last week. They're the newest model.


23:27: Guillermo Angeris:


7BX4.


23:27: Tarun Chitra:


Yeah, exactly.


23:28: Guillermo Angeris:


7BX8 or whatever.


23:29: Tarun Chitra:


Yeah, or yeah, exactly, exactly, exactly that one. I think it's actually, I am ending the year much more hopeful that actually despite all the OpenAI drama, whatever, I actually think quietly the open source language model stuff will... Like it feels like the closed source language models are sort of plateauing, right? Like Google puts so much effort into something that feels like so marginally better than GPT-4, whereas like the open source stuff is still kind of continuing. And I think we're going to see, hopefully, that there's some proving.


24:01: Anna Rose:


So are you saying I should be scared that I'm going to be replaced.


24:05: Tarun Chitra:


Well, I actually think the fact that Google's model seems pretty useless and that they had to use some certain particular metrics that they look better on than GPT-4, like the 32 chain of thought reasoning type of metric, which is not a standard way to compare these things, it feels like we're kind of plateauing on transformers can only get you so far. Like if you wanna do voice text...


24:30: Alex Evans:


ZkVM projects comparing themselves on performance metrics.


24:34: Tarun Chitra:


No, yeah, yeah, yeah. But the nice thing is like, crypto's performance metrics are at least, yeah, like some of them are obviously gerrymandered, but the difference is you kind of know the thing actually ran and did this. These kind of statistical performance metrics, which are like, I give you these random queries and like, oh, well, I can't really perfectly compare the training set. It feels a little bit like the reproducibility crisis in science, where you have two things, someone's trying to reproduce an experiment, but they can never get exactly the same context. And so then obviously there's going to be some metrics one does better than the other.


25:10: Anna Rose:


Wasn't that in the episode with Daniel and Yi, though, wasn't there this using ZK to prove that something happening inside the model is happening correctly? Remember? But you still wouldn't be able to use that for comparative purposes.


25:25: Tarun Chitra:


You need some statistical tests for comparison, right? It's like I give you a bunch of different queries, and they're different tasks, right? Some are like, I give you a list of words, and then I say, count the number of times the word Anna appears in this list, right? And that's one type of query. That's like more of a logic query. Another type of query is one where you lead a language model on, you say, oh, by the way, most books in this building I'm in are red. David Mumford, the algebraic geometer, is famous for making a big red book. Is David Mumford's book in this building? So you've given it some context that it's led onto. This is a chain of thought type of thing. And then you say, can you answer this question? And it will oftentimes make these types of mistakes.


26:07:


And Google was like, oh, look, we can do these types of things better. But like that's one particular weird metric. And my point is I kind of feel like the gerrymandering in AI is actually a million times crazier...


26:19: Anna Rose:


And harder to undo.


26:20: Tarun Chitra:


Harder to disprove.


26:21: Anna Rose:


Yeah. Wow.


26:23: Tarun Chitra:


And so I think there's actually room for crypto as like.. Assuming people stop just fighting over like, do I count vote transactions in TPS or not, whatever bullshit you see on Twitter, I feel like it has a way of having a better standard of comping things. Because like, I think the AI rat race right now is it, a shows that like the marginal improvements are flatlining right now, but it also shows that when you have so many smart people whose entire incentive structure is built around trying to come up with metrics such that the number goes up 1%, they're going to do all sorts of bizarro tricks as opposed to having something provable that you can trust. Anyway, I don't know. That's a long rant about that world but.


27:10: Anna Rose:


Yeah. I'm going back now to the timeframe where we're at. So it's about April, 2023 in our story. Another topic that came up or a word, I think it was around then that the introduction of the concept of a ZK coprocessor was raised. What'd you say?


27:30: Tarun Chitra:


I think Yi technically called Axiom a ZK coprocessor in like December or January.


27:36: Anna Rose:


Okay. So earlier.


27:37: Tarun Chitra:


But then, I think the steam around it grew. And then a lot of people working on similar things that had a state proof somewhere, were like we're also a coprocessor. And the best compliment, I guess, is to get copied. So the fact that people change their name to your thing is actually a good sign, right?


27:54: Anna Rose:


True. And since then, there's been a lot of projects that have come out doing something like that. I'll list a couple. Axiom, Herodotus, Nexus, IronMill, Lagrange, RISC Zero did Bonsai, and I think for now those are the only public things. I know there's some other things in the works. I think one thing that had been brought up with sort of this explosion was like, is there a market for this thing? Like there's a lot of projects doing it, but it's sort of theoretical at that, it's been very much theoretical. Do you know if any of them have been now used?


28:36: Tarun Chitra:


I think they're used in these small test deployments, like DeFi yield aggregators, like how do you decide which protocol to optimize to, you run a model off-chain to decide the allocation. There've been a bunch of those types of use cases. I think it has been kind of hard to get... There's been a ton of hackathon projects. The hackathon projects are all cool. 


28:59: Anna Rose:


You mean like things built on them?


29:00: Tarun Chitra:


Yeah.


29:01: Anna Rose:


Yeah, yeah, yeah.


29:01: Tarun Chitra:


Someone has basically made NumPy, like the numerical library in Python in Axiom. So you have almost all the matrix operations like matrix multiplication, SVD, whatever. I have no clue why any on-chain application needs this, but my point is there is kind of this sense in which you can build these things you would never do on-chain otherwise. Now, Guillermo's guffawing, so I think he's clearly waiting to say something.


29:27: Guillermo Angeris:


I don't have... I don't think I have an intelligent thing to say here. I don't know. It's just like, it is funny that we then went on to do, like, let's do Python for ZK, right?


29:38: Tarun Chitra:


Or like numerical stuff.


29:40: Guillermo Angeris:


Yeah, like pretty heavy numerical stuff in ZK, which I guess is kind of all of ZKML as well. 


29:45: Tarun Chitra:


But this is usually less heavy than ZKML, right? It's like doing an SVD versus like...


29:50: Guillermo Angeris:


Or doing a median or something, right? Or even like, or median plus a few extra tricks, which is true. Just funny doing it in a Python wrapper, I don't know. Maybe this is like a weird purists.


30:00: Tarun Chitra:


Or JavaScript.


30:00: Anna Rose:


Are you shitting on the hackathon project?


30:03: Guillermo Angeris:


No, no, I think it's great.


30:04: Anna Rose:


It's lovely that someone did it.


30:05: Guillermo Angeris:


No, it's awesome. This is not me shitting on the hackathon project in general. It's just one of those things where I'm like, they're probably better...


30:11: Tarun Chitra:


Try everything.


30:12: Guillermo Angeris:


Yeah, just do it.


30:12: Tarun Chitra:


Just try all the things and we'll see afterwards.


30:14: Anna Rose:


Aren't we looking for a use case where it wasn't always meant for an application on-chain to be using this somehow?


30:21: Tarun Chitra:


So I think the DeFi applications are a little harder. One of the problems with these publicly depicted calculations is like, well, you're telling everyone how to front run you and they can obviously run it off-chain and front run you. And they kind of create more problems for these DeFi protocols... For DeFi protocols, it's not quite so simple to use these.


30:41: Anna Rose:


Would there be a way to design a new DeFi protocol with this in mind though? Because I think you're trying to plug it into existing.


30:47: Tarun Chitra:


If you had some revelation thing where like the protocol was able to use the output, but it wasn't public and then it was revealed later, there are ways that could do it.


30:57: Guillermo Angeris:


To be fair, I don't think you need privacy, but you would need a pretty deep analysis of the protocol itself. And we have no good... There are very few protocols in DeFi that we have good frameworks for. In fact, actually, I would say there's really only one or two classes of protocols that we have any frameworks at all that we can say anything about for. And it's unclear how to be like, oh, yeah, cool, now you have this whole other set of things that you can do. What can you do with that safely in a way that doesn't suck?


31:25: Tarun Chitra:


And can deal with arbitrary other protocols interacting with it. That's the hard part, right? 


31:28: Guillermo Angeris:


That or also anyone messing with you in a variety of ways. It's a pretty deep question, I think. It's not obvious. I mean, you can build these tools, which is great, and I'm glad someone should do these things. But if the end user really is DeFi protocols, we have some glass chewing to do prior.


31:49: Alex Evans:


So backing up to this idea of coprocessors, outside of a marketing term, it's been sort of hard for me to understand what people are talking about oftentimes. What I've roughly discerned, right, is some notion of a mini rollup where you don't have persistent states between runs of the prover or the software, right? And so sort of like a stateless thing. The thing that I'm seeing people get interested in is fraud proofs, proving that fraud was done, shorten windows, things like that. That seems to be something that people be willing to pay for and do. That's not an end application though, to Anna's point. I think with DeFi, there's a conceptual problem, but I think you're right Guillermo, that is more proximate than the ZK part, which is, okay, now you have this thing that's asynchronous, that maybe gives you more compute capabilities. Maybe you don't need to store all these variables anymore. You can just run the averages on the fly or whatever you might need.


32:51:


Or you could do things that are dynamic in nature. But of course we have no theory for how CFMM, for instance, which is the simplest object that we've been able to analyze, could work in a dynamic setting. We've tried to bound what's actually possible within that and the range that we found is either it gives you absolutely nothing...


33:09: Guillermo Angeris:


Or everything.


33:10: Alex Evans:


Or absolutely everything. And the truth is somewhere in there. It's actually probably just one of those two possibilities, would be my guess. But we need to go solve that problem first, and that's a hard problem. And ZK is not going to give you the answer to that problem. It can give you a great foot gun for you to shoot yourself with if you don't know the answer.


33:28: Tarun Chitra:


And or it gives you a precision weapon if you know the direction to shoot in at every point, which is the hard part.


33:32: Guillermo Angeris:


Yeah, but it's equivalent to solving the problem, as I would say, right?


33:37: Tarun Chitra:


I think, yeah, this is actually maybe one of the reasons I had escapism in January, outside of the general malaise, was I had felt, and I still sort of feel a little bit of this DeFi research slump. You know, the three of us had this 18-month period where we were like...


33:57: Anna Rose:


On fire.


33:58: Tarun Chitra:


Pushing out things every month, and there was always new stuff, and it was like...


34:01: Guillermo Angeris:


Yeah, I mean, how many papers did we do? Like 14 or something? 15?


34:05: Tarun Chitra:


Yeah, it was a lot.


34:05: Anna Rose:


Wow. This is 2021, 2022. 


34:09: Tarun Chitra:


Like late 2020.


34:11: Guillermo Angeris:


Late 2020 when Alex joined all the way to early 2022.


34:15: Alex Evans:


I'm not sure DeFi changed as much as they all of a sudden let us go outside again.


34:21: Guillermo Angeris:


Maybe that's what it was. Maybe finally.


34:24: Tarun Chitra:


Yeah, maybe it was that. But I think like, I think...


34:28: Anna Rose:


Tarun.


34:32: Tarun Chitra:


I think like what happened was I think people started getting overly excited about these things. And then in practice, when you look at the data, how people are doing things, how MEV evolved, it became much more clear you needed a theory of these MEV type of things so that you say, hey, I have a DeFi protocol and I can condition it... I can take the set of all these DeFi protocols, I'm going to find the subset that given a certain type of MEV has low resistance to it, right? And the problem is there's always this cryptography hammer looking for a nail thing where everyone is a cryptographer is like oh, I see Uniswap has tons of volume, I'm just gonna throw a bunch of cryptography at it and obviously it'll be better and solve all these problems. It'll remove MEV, all the dogshit advertising we saw.


35:17:


But when you started trying to analyze what would actually give you reductions in these things, then you start realizing the theory of MEV is actually a hundred times more complicated than the theory of the DeFi protocol. The DeFi protocol is actually easy. The MEV part is very hard. It actually is very combinatorial in nature. It has many different states, and a lot of the beauty of the DeFi research we did is there was always some way of taking a continuous limit. You could kind of shrink the block time or shrink the trade size or grow the trade size arbitrarily and you would get some invariance that your results kind of still had to hold.


35:53:


But the MEV thing is not that, right? It's like it's very, it has this inherent, discrete chunkiness to it. And then you have to count all the different ways of ordering the chunkiness, or all the ways of censoring, all the ways of removing and adding. And without having that theory, you can't really make a better DeFi protocol. Like, no matter how much dogshit tokenomics ponzi you add to it, you're not gonna fix the problem.


36:14: Anna Rose:


What happens when you add coprocessor to this mix?


36:17: Tarun Chitra:


So coprocessor lets you push off some of the compute if you knew what to compute to avoid certain types of attacks or to improve capital efficiency or whatever. But the thing is you have to have a formula for that that's resistant to people seeing how you computed it, allowing them to manipulate it more. I don't know if that's...


36:39: Alex Evans:


Yeah. If you had almost as a similar thing we had, I think we probably done a, maybe we've done a podcast on it. We've certainly done a talk on the privacy paper.


36:47: Tarun Chitra:


That's right.


36:48: Anna Rose:


Oh yeah, yeah.


36:49: Alex Evans: 


And it was sort of a troll paper saying, here's a really simple model that shows definitively...


36:53: Guillermo Angeris:


Inspired by Anna, by the way.


36:55 Anna Rose:


I love that you said that, although I don't know why. But okay.


36:59: Alex Evans:


We were showing that this thing that people claim that they wanted to do actually wasn't possible. And a very trivial model shows that you can actually recover the full trade. So the lesson there is the problem isn't a ZK technology problem. It's a conceptual error. It's the privacy in the shared space that are just incompatible with each other. And what we should have done is it wasn't a question of, can we go understand all the ZK stuff? It's like, no, let's go into a quiet room and think for a little bit before we do anything. I think something very similar is happening with this, at least my pattern recognition in the ZK process...


37:32: Anna Rose:


Cart before the horse.


37:33: Alex Evans:


Is just cart before the horse. Exactly. We haven't thought about what if you take these static mechanisms and make them dynamic? What functions would you want to compute? Maybe some of them will be very computationally intense. You might need a coprocessor, but that's second order, third order. But the first order problem is, what can we do? And do we actually need this tool?


37:52: Anna Rose:


So we listed some of the teams that sort of fall under this category. To give them credit, I think they've... Most of the ones I know well, have amassed a really good team building this kind of thing. And I'm assuming that there will be some differentiation as it goes, potentially, like a focus on a use case that they're trying to experiment with. So I have hope for at least the cohort, but I wonder if the ZK coprocessor as it's been described, yeah, wouldn't need to evolve quite a lot. From what you're saying, it sounds like the way it was presented as a solution to a problem that isn't fully understood or something like this. 


38:31: Alex Evans:


It's a tool for solving a problem. If the solution is possible, then it plays a huge role in it.


38:38: Guillermo Angeris:


For DeFi, for DeFi.


38:39: Alex Evans:


For DeFi. This is specific to DeFi.


38:40: Anna Rose:


There are other use cases.


38:40: Guillermo Angeris:


There's many other things.


38:44: Alex Evans:


Other applications might be different.


38:44: Guillermo Angeris:


But most people say, what are ZK coprocessors really gonna be used for? People are like, ah, DeFi is like a great case. Right, I think it's a common claim.


38:51: Tarun Chitra:


I think DeFi is the hardest case.


38:53: Guillermo Angeris:


But it's, exactly.


38:54: Tarun Chitra:


In fact, it's the worst case in some ways, because you have to understand the theory so much about the thing you're building, and the beauty of crypto, which is also why there's so many explosions and hacks, is that you can build whatever you want without understanding it.


39:09: Anna Rose:


And raise a bunch of money. And then see it get exploded.


39:16: Alex Evans:


I think a lot of the other things that we could talk about, about applications and so forth, including ones that we got really excited about coming out of Lisbon, you could probably broadly put in the coprocessor category, in other words, if they ever need to hit a chain like Ethereum, like I'm sure we can talk about non-native cryptography on Ethereum, things like that. It's very obvious that.


39:36: Anna Rose:


True, true. Like if you have to do something you can't do on Ethereum, you could do it in this environment.


39:41: Alex Evans:


That's right. So those things are lower hanging fruit. So not to disparage any of these amazing teams, it's just to say that DeFi and some of these problems where you have money and where foot guns can really hurt you, you really have to do a lot of thinking. And you can't just... Just as you couldn't throw privacy at Uniswap, you can't throw coprocessing at these things. Just make sure you...


40:03: Tarun Chitra:


I mean, just think about some of the attacks we've seen in the last year. Like the DeFi attack, sophistication has also gone up.


40:11: Guillermo Angeris:


Holy crap.


40:13: Tarun Chitra:


Right? And like the level of like the most recent Kyber attack is almost a crazy travesty, right? It turns out that there's exactly a particular fee limit and there was a one way difference, one ten to the minus nine basis point sort of different in terms of a multiplier constant that it actually for most numbers this thing worked, but someone figured out, oh, if I actually... You could think of as like I make a very tiny error and then it compounds to the next liquidity pool in a concentrated liquidity pool and I can keep compounding it and then it's a very complicated tag, very sophisticated. And it's the type of thing, like the ZK coprocessing part won't help you with that, right? Like that comes from the mechanism design of the thing, right?


41:02: Anna Rose:


But I mean, is the coprocessor meant to add security?


41:05: Tarun Chitra:


Well, the coprocessor might have computed the number of how much liquidity you should have put, maybe it would have put the amount that would have triggered the attack, you know. It doesn't help that you have the coprocessor doing it, you actually have to have the right constraints to say don't do this type of thing, right? Because a big pitch of what people say with these coprocessors is that we can increase the expressivity of all these smart contracts. It's like, we're having a lot of trouble with the expressivity we have today. Without more complicated reasoning. But again, I think, yeah, obviously some of the teams have some amazingly smart people and I think we're gonna have really cool coprocessors. I just don't think the DeFi use case, even though it's the one that on the surface seems like the obvious use case, I actually think it's gonna be the last use case because you're gonna really have to know the mechanisms.


41:52: Anna Rose:


Interesting. But yeah, I want to also wish everyone in that group a lot of luck with the next steps because I do think they're great teams.


42:01: Tarun Chitra:


Well, I think the hackathon does these points of imbuing non-navigate cryptography. You're already starting to see people build that type of stuff.


42:07: Guillermo Angeris:


For sure.


42:07: Anna Rose:


That's very cool. Okay, so now let's put ourselves in the middle of the year. Around Paris. So ZKValidator and Geometry did a collaboration on ZK Paris. I mean, there was a ton of ZK events there. Yeah, I'm just trying to think. What was happening in the summer? What was the topic of the summer?


42:30: Alex Evans:


Celestia.


42:32: Anna Rose:


Celestia was later, wasn't it? They did the Modular Summit. That was really good. 


42:37: Alex Evans:


And I feel like that was like the beginning of the Celestia train.


42:40: Anna Rose:


Like modular, sort of that narrative really kind of taking hold for a lot of teams, a lot of groups.


42:46: Alex Evans:


I was thinking about client-side ZK. I think at that event, I had a little talk track on it and it was... Maybe that was the trough of disillusionment of the year, at least from where I was standing. We were really excited coming out of Lisbon. There was all these cool things. Not really disillusions.


43:01: Anna Rose:


Crash?


43:02: Alex Evans:


I'm exaggerating a little bit.


43:03: Tarun Chitra:


Hangover.


43:04: Anna Rose:


Valley?


43:04: Tarun Chitra:


Hangover.


43:07: Alex Evans:


The afternoon lull.


43:07: Guillermo Angeris:


Yeah, indeed. You ate a little bit too much and need to go take a siesta or something.


43:11: Alex Evans:


That was it. That was certainly true in Paris. 


43:16: Guillermo Angeris:


I believe that. Unfortunately, I wasn't there, so I wouldn't know.


43:20: Alex Evans:


You have to come next time to find out.


43:21: Tarun Chitra:


I think the things that were actually interesting to me in that era and time were kind of the stuff that is not usually that interesting, I think, to talk about on this podcast, but is like the UX side of things. I actually feel like wallets started, at least my experience with using wallets got a lot better.


43:41: Anna Rose:


Like general crypto wallets?


43:42: Tarun Chitra:


Just general crypto wallets. I feel like people started really innovating on the UX and like, yeah, not the super technical stuff, but design interfaces, stuff like that. And I feel like that stuff has paid dividends to the current. I feel like a lot of the wallets are a lot easier to use for new users than they were even a year ago. And I think that was one of the things I remember. I was like, wow, this is the first crypto transaction I've sent since early 2021 or something. Like, and then I...


44:15: Anna Rose:


On a mobile wallet or something.


44:16: Tarun Chitra:


On mobile wallets, yeah, yeah, yeah.


44:17: Anna Rose:
Cool.


44:18: Tarun Chitra:


And then we had the friend.tech boom.


44:20: Anna Rose:


Yeah, you guys got into that. I did not get into that. Is that still happening? Is it dead or is it?


44:25: Tarun Chitra:


It's still alive, yeah, yeah.


44:25: Anna Rose:


Okay. How much are you worth?


44:28: Tarun Chitra:


0.2 ETH, I think.


44:30: Anna Rose:


Wait, what was the... Like a few years ago, there was something that Prestwich hated.


44:33: Guillermo Angeris:


BitClout. 


44:34: Anna Rose:


Yeah, BitClout. So this was BitClout 2.0, no? But better? Better executed, more real?


44:39: Tarun Chitra:


Yeah. I guess the chatroom was different. Honestly, I just... I don't know, these kinds of ideas of people trading themselves or it just don't really seem that appealing.


44:53: Anna Rose:


One topic that I mean, I don't know exactly when it was happening, but I know it got more and more important for me at least, or it became more and more visible was hardware. And then like we did, Tarun, I don't know if you remember this, like 2021 we did an interview with Supranational, and I think we maybe...


45:11: Tarun Chitra:


We were actually both in Austin and we did it IRL where we were both IRL and the people were in the...


45:16: Anna Rose:


They were calling in. But I remember asking, I think we asked them about ZK, but it was not a focus necessarily at the time. They were focused on this VDF work. I actually don't know if Supranational would be the... I don't know how much of their focus is ZK today, but there's all these hardware teams that emerged over the last year. Like Ulvetanna, Ingonyama, I mean, we actually, Alex Pruden and I did a two-part series on the Zprize winners. AMD got into the game. There's an event called ZK Accelerate focused on, I mean, not just hardware, but some sort of hardware angle.


45:53: Tarun Chitra:


Okay, so I have a hot take, which is that there will be a proving system made that is adapted to be easy to use on things whose architecture looks like H100s because there's going to be so much capacity of that stuff. And it's actually going to be like our current proving systems are actually not... Like you could modify them in some ways where they might have certain other guarantees being worse, like verification time might get worse. But the proving time is way more optimized for the hardware that...


46:24: Guillermo Angeris:


Might you mean something like...


46:25: Anna Rose:


Wait, is this Binius?


46:28: Guillermo Angeris:


Might you mean something like linear algebra could be used for this thing?


46:30: Tarun Chitra:


Some combo of all of these things. Some combination of all of these things, I think. I don't think we know what it is yet because we don't know the wall clock time performance and we haven't done the like, I'm optimizing this thing according to the device I'm looking at.


46:44: Anna Rose:


Aren't they right now? Isn't the hardware? Yeah.


46:48: Tarun Chitra:


Largely happening.


46:49: Anna Rose:


Yeah, I think it's happened.


46:50: Tarun Chitra:


No, no, but I actually think people are... People in ZK are still optimizing to slightly older chips. The new chips, which are impossible to get, right? Like basically you have to be in it. If you look at my favorite chart... So is this bearish on a mean there's going to be an oversupply of these things. Essentially, there'll be an abundance, and it will make economical sense for you to target that architecture. All of these infrastructure providers are going to start just trying to find non-AI use case once people stop fine tuning as aggressively.


47:21: Alex Evans:


Makes a lot of sense.


47:23: Tarun Chitra:


So one of the most amazing charts you can watch, you can look at is NVIDIA's chart of H100s, the current generation, the H200s coming out soon, divided by who the customer is.


47:33: Guillermo Angeris:


Yeah, that's a great one actually.


47:35: Tarun Chitra:


And you look at this exponential drop-off and it's very clear there's only two people who are getting buying like almost all of them, which is Microsoft and...


47:44: Alex Evans:


Microsoft and Amazon now.


47:45: Guillermo Angeris:


Amazon, yeah.


47:46: Tarun Chitra:


It's Microsoft Amazon and then it drops off and then it's like eventually you hit Google because like NVIDIA doesn't want to sell to Google because Google made their own chip and there's this is bad blood shit there, but the interesting thing is these crypto companies don't have access to any of these chips. So they're all looking at the slightly older... So all the optimizations we see on GPUs are having older GPUs because the AI people are taking all the newest ones. But they're pumping the price up on that so much. It's kind of like a bad token drop. There's going to be basically like AMD and NVIDIA creating so many chips in the next two years. They're increasing their fab capacity by 2X that there will be a glut at some point, and that is a perfect time for people who have the right ZK proving system to just soak up the excess supply and prove for cheap. That's my... 


48:36: Guillermo Angeris:


That's a pretty good hot take.


48:37: Anna Rose:


But I do think there is already a little bit of work in that direction in that the hardware companies have started to make proving systems optimized for hardware.


48:48: Guillermo Angeris:


Oh really?


48:48: Anna Rose:


But which hardware?


48:50: Guillermo Angeris:


Oh, well specifically here it's the H100.


48:52: Anna Rose:


That's the thing, it's maybe it's for different hardware.


48:52: Tarun Chitra:


Yeah, I'm saying the stuff that people have been making for Transformers where they have... The way the memory is laid out...


49:00: Anna Rose:


Yeah, this is different.


49:00: Tarun Chitra:


Particular units, all of that stuff, there's going to be certain linear algebra stock, because like, what is a neural network? It's a bunch of linear algebra plus a tiny bit of non-linear algebra, right? It's like linear algebra and a little bit of non-linear algebra. And so there's a sense in most of the point of a GPU from the inception for graphics cards for everything, has just been multiplying matrices. There is famous billionaire who is the third largest buyer of H100, the only non AI chip buyer, which is Alex Gurko, who's CEO of XTX which is a trading firm, who always said, like whenever anyone asks what he does, he says multiplying matrices? 


49:39: Alex Evans:


It's what we all do.


49:41: Tarun Chitra:


That's what we all do if we squint enough.


49:42: Guillermo Angeris:


If we squint enough.


49:43: Tarun Chitra:


If you squint enough, it's all multiplying matrices. And I kind of think people who take advantage of the matrix multiplication piece in their proving systems and make it look a little more like that, will be able to take advantage of these chips.


49:56: Alex Evans:


I mean, it'd be the continuation of the story of NVIDIA for the last 10 years.


50:02: Tarun Chitra:


Because NVIDIA just keeps rolling from hype cycle to hype cycle.


50:02: Alex Evans:


Yeah, just from one wave to the next wave.


50:02: Guillermo Angeris:


Yeah, it's actually incredible.


50:04: Tarun Chitra:


It's like...


50:05: Anna Rose:


Games, crypto.


50:05: Alex Evans:


Yeah, how to counter the... [?] of the semiconductor industry by just figuring out the next one.


50:10: Guillermo Angeris:


Just like an absolute arms dealer and it's awesome.


50:13: Tarun Chitra:


But I actually think in the same way that when crypto like after 2017 crash, there was this huge wave of people dumping GPUs onto the market and people buying them for doing AI training and for gaming because the chip supply got really cheap.


50:29: Alex Evans:


You're welcome AI people.


50:31: Tarun Chitra:


And the AI... It's going to go the other way. I think this time it's going to go the AI people are too exuberant. They raise too much money and crypto is gonna take...


50:38 Guillermo Angeris:


Crypto, you know, loving hardware to...


50:40: Anna Rose:


Question on AI and kind of this hardware stuff, though. Would AI ever use FPGAs or ASICs?


50:46: Tarun Chitra:


People have tried. Edge computing FPGAs for neural nets exists. Microsoft, actually, ironically, spent five years on outputting FPGAs in their data centers for doing the final leg of inference. So for edge inference, oh, I'm an embedded device in a self-driving car, and I need just a tiny inference for something.


51:08: Guillermo Angeris:


FPGAs exist on the iPhones and the Androids, actually. I recently had a friend who actually did camera work, and one of the things was using FPGAs on cell phones themselves to actually do image manipulations and image processing directly. And a lot of it would essentially be compiling a neural net down to and synthesizing it directly into the FPGAs.


51:27: Tarun Chitra:


In Apple phones, you could argue that the face ID neural net, which is a very tiny neural net that's run on chip, that the weights are trained by you showing your face, is not that different than FP... It is an ASIC but it's like lane-wise It looks a little bit like an FPGA because it has to be able to mutate its own weights, but I would argue FPGAs are sort of historically this type of thing where anytime you see them, it's like clearly something where there's...


51:54: Guillermo Angeris:


The stepping stone.


51:55: Tarun Chitra:


There's clearly a good idea. Like a thing that needs to go into hardware, but almost every time someone over-invest in FPGAs, they lose money. So one of the worst acquisitions, I will say, and I'm sure there are tons of hardware people who will fight me on this.


52:07: Guillermo Angeris:


I'm sure you're about to say Intel.


52:08: Tarun Chitra:


It's Intel buying Altera. Like it's Intel buying... Like Altera, big FPGA manufacturer. Intel was like around every... Because I used to work in hardware, so I remember this acquisition and everyone at my work was shitting on Intel like 100%, every fucking ASIC engineer was like “Intel is fucking retarded.” They said stuff like that. Okay?


52:26: Anna Rose:


I'm sure it was years ago, right?


52:29: Tarun Chitra:


Years ago, yeah. They were very, very adamant about it. I mean, Guillermo knows some of these people because he was my intern probably around that time that the acquisition happened. And the idea that Intel had was that people would put these coprocessors, and they call them coprocessors.


52:47: Anna Rose:


Oh my god.


52:47: Guillermo Angeris:


Yes, that's right. Correct.


52:47: Tarun Chitra:


FPGA coprocessor. Next to your CPU.


52:51: Guillermo Angeris:


On top of the CPU…


52:53: Guillermo Angeris:


Yeah, it's crazy.


52:54: Tarun Chitra:


And it would run certain high-end calculations, maybe signal processing, maybe image processing alongside your CPU, so your CPU can do all the, run your operating system, do all the management stuff. But these specialized calculations would go to the FPGA and this was Intel being like “fuck graphics cards”, “we don't care about graphics cards”. “We're just gonna add the special purpose unit in our chip.” That is their downfall. In fact, I would argue that Intel completely missed all the neural net stuff and then did all these crazy things like buy Nirvana, whose CEO left within a few months and started an AI company. Because they missed kind of the, what's the phrase … forest from the trees?


53:34: Guillermo Angeris:


Oh, missed the...


53:36: Anna Rose:


Couldn't see the forest through the trees, something like that?


53:38: Tarun Chitra:


Yeah, that idiom.


53:39: Guillermo Angeris:


Something like that, yeah, vaguely.


53:41: Tarun Chitra:


And they just kind of completely thought this FPGA coprocessor would solve everything. And you could argue... It's kind of a, I know we've talked about coprocessor.


53:51: Guillermo Angeris:


Guess what they're... Guess what Intel's doing now? You know, we have the Intel 1550 Max, lovingly existing in things for 17 an hour. So now they've gone into GPUs, of course, most of the past two years. 


54:04: Tarun Chitra:


Everyone is chasing NVIDIA now.


54:06: Guillermo Angeris:


That's right, that's right. 


54:07: Tarun Chitra:


And so, but I actually think all the competitors are kind of hapless in one way. NVIDIA's probably not the best software company by any means, but they're the best at the certain level of developer software, which is how to make a proprietary compiler that an undergrad could use.


54:25: Guillermo Angeris:


They also, to be fair, started developing this, which is like the most big brain of all the things. NVIDIA had the foresight in like, '07, I think, is when... Sorry, when Kudo was released, right? To just be like, what people are going to be able to do with these GPUs? They're going to be able to do whatever the fuck they want. And we're going to enable that. And people are like, what's useful? What can you do with that that you can't do with a processor? And everyone was like, maybe some specific weird niche weather prediction to add to your Stokes thing. But then quickly, you know...


54:59: Tarun Chitra:


ImageNet. ImageNet had to happen for people to realize, oh, shit.


55:02: Guillermo Angeris:


That's right. But my point is, this is well before... Essentially kind of before that.


55:05: Alex Evans:


It was like five years or whatever was, AlexNet stuff was like...


55:09: Guillermo Angeris:


Yeah, yeah. And no one was using GPUs. It was like, who the hell is going to... This is going to be great for matrix multiplication, essentially, or something that could be easily parallelized. And it's like, well, joke's on you, guess what can be easily parallelized? Linear algebra.


55:21: Alex Evans:


Don't underestimate matrix multiplication, kids.


55:23: Guillermo Angeris:


Damn right. Anyway, sorry. All right. We got far too far down the rabbit hole.


55:27: Alex Evans:


Well, that's a good part of an end of year episode. They don't need to be so structured. 


55:30: Anna Rose:


No, not at all. Anything else happening in the middle of the year?


55:34: Alex Evans:


Yeah, so right around to this slump, the thing that happened is… so at the start of the year on the research side, everybody was really, really excited about all the KZG based lookup stuff. So coming out of the Caulk, Caulk++ early in the year, you have CQ, that sort of stuff. And then you had real excitement coming into Lisbon around folding and a lot of the... Anything elliptic curve based, right? And a huge set of things that we can get into, but everyone was really excited about that side of the space. And quietly around Paris, some of the work from Polygon around Plonky3 started coming out with the Mersenne Prime (M31) stuff. Been quite a lot of work around the Brakedown sort of optimizations around it. Ulvetanna, you had on, did the logarithmic randomness paper. And so quietly there was a lot of work that was getting a lot less attention at the time that was happening in more of the error correcting codes. We were spending time on it because I was writing this paper that was around that that came out more recently. But it just... When we started hearing some of the performance numbers from some of the teams that were working on it, it's like, wow, we've been spending all this time on this other stuff and it's been really interesting and really cool, but here's a real phase transition in the space.


56:51:


And of course, the rest of the year, which we'll get to, seems to have been dominated by advancements in that side around FRI, Brakedown, error correcting code base, polynomial commitment schemes and the like.


57:04: Guillermo Angeris:


Yeah, I remember there was an earlier episode, and I won't say who it was, but someone said, oh, is it STARKs are dead, I believe was the term or something like that. So I guess that...


57:13: Anna Rose:


In fact, not though.


57:15: Guillermo Angeris:


The king is dead, long live the king. 


57:17: Alex Evans:


Don't underestimate matrix multiplication… kids!


57:20: Guillermo Angeris:


Damn right.


57:21: Tarun Chitra:


Matrix multiplication always wins.


57:23: Guillermo Angeris:


It really comes back. It's like the meme of the Simpson meme where you throw someone out and then the guy comes back behind you. And it's like, that's always matrix multiplication.


57:31: Anna Rose:


It's hilarious. Yeah, we don't have as much time. We're halfway through the year, but we actually, we're going to have to speed through the rest. I want to bring up another topic that I feel like it's been, I mean, the topic of ZK and ID has been around for, since the beginning, I think, or like for many, many years. At the beginning of the year, this year, like in our first kickoff episode, I was kind of singing, I was so excited about Sismo, and the badge system, using ZKPs to prove kind of merit, to prove that you had done some action somewhere else, and then in a fresh wallet, creating ZK badges that basically proved you had done something. What you could do with that is then you could start compiling all sorts of behavior from different addresses into one place without connecting it necessarily to the work you had done or what you had done over there, and creating a bit of an ID.


58:29:


Sadly, and this just came out, I think, in the last few days, that Sismo is no more. So they are shutting down, which is very sad. But I think the thing they did, just kind of showing what you could do with that idea, the separation of the action happening in one account, but the proof of the action happening in another, I think that idea is going to continue to be developed. It was really, it's very compelling. There have also been a few other ID projects recently. I had Kostas from zkLogin, Sui and Aayush from ZK Email come on the show. And Tarun I know you got excited about ZK Email as a potential ID solution, or just generally.


59:15: Tarun Chitra:


I think it's the closest thing I've seen to a vampire attack on existing platforms without needing a centralized Oracle. That's the...


59:24: Anna Rose:


Which existing platforms?


59:26: Tarun Chitra:


Just like a very stupid application that I personally have had a thing for it existing, but it's this idea that if you have reputation on some social media platform, can you use it as collateral to borrow against? And in theory, there's no real way to do that without being able to prove that like, I have this many views on all my videos, or I have this much... People write comments whose sentiment isn't, wow, nice, 100% like every fake robot comment, right? And there's some sense in which all these social media celebrities find this like, their only monetization is shilling products. But imagine if they could borrow against their clout somehow. And I kind of feel like there's some notion of attestations being useful for that, because once you get on-chain, once you actually have some proof of their reputation off-chain somewhere else. And I think the emails are interesting because people who are big creators get a fucking email every day. That's like, you have gained X thousand followers, here's your number of followers. And it's signed with, guess what? TLS key from TikTok.


1:00:37: Guillermo Angeris:


So yeah. What's super interesting about this technology, we were talking about this I think yesterday, is this enables you to bootstrap, like identity more generally, sure, but like, essentially it's kind of a non-stoppable force, right? Like the ZKP2P is one example of this. It's like whatever platform exists that is kind of sending you this email is unable to stop it, unless they just stop signing emails, which seems very bad for them. But you could do this... You could imagine there's any number of other things. Right? Like it's this whole crazy idea that you can essentially take any piece of off-chain data and use it in some way, of course, on-chain, but it's unstoppable. No one can be like, oh, yeah, sorry, actually, you're not allowed to use service anymore. It's kind of a mouse game. But fundamentally, you're always chasing.


1:01:32: Anna Rose:


Fun fact, Sismo, before they disappeared, were also playing in that realm. Because they could do it too with the badges. I mean, they had the badge system, but yeah.


1:01:42: Tarun Chitra:


I mean, I remember at Devcon in Bogota, Aayush, who sort of created ZK Email, he was just like, yeah, I'm working on something that will make all oracles on-chain obsolete, especially Chainlink. I think I'm paraphrasing it, but he had some like very, and at the time I was like, but you're talking to me about nullifiers for an hour, and then all of a sudden you're saying this like, you're a very precise person, you say this bombastic statement. And I didn't get it, but now I'm a total believer.


1:02:15: Guillermo Angeris:


It actually, it's really fucking sick.


1:02:18: Anna Rose:


That's amazing. There have been other ID solutions I just wanna mention quickly here. Polygon ID, I believe, released something this year. There's the zPass, the Aleo stuff. These are like KYC on-chain, maybe some way to create, yeah... I think.


1:02:34: Guillermo Angeris:


ZK Narkware.


1:02:35: Anna Rose:


I think, yeah. Well, I think in a lot of ways, you need a verification agent for these to work. Actually, as we were talking, we were actually talking about this earlier today, Tarun, we realized we have not had them on the show to talk about this stuff, and it might be worth it, because I definitely haven't gone deep on that, and I'd be curious to hear that side of it. But yeah, I think, I mean, I still think ID as a topic remains very exciting. It even... Even the thing we were talking about earlier, about the attested sensor, the attestation of content provenance, I think, if you have an attested sensor in a microphone or if you have, I mean, I know there's a team that's tried to do this with biometrics or what have you, but there is definitely an ID component to this. So I think those two things are quite closely tied, especially as AI becomes more and more close to us and looks more like us. We're going to be able to use potentially merit, email, Web2 identities, some sort of physical identity, real-world material to create our online identities that are hopefully a little more nuanced, not just your iris scan. Yeah. I don't know. That's what I'm excited about right now. 


1:03:48: Tarun Chitra: 


Lakshman from Personae has a phrase, which I think gets this, which is credible nuance, which I think is probably, it does get exactly the thing you said.


1:03:59: Anna Rose:


That's very cool.


1:04:00: Tarun Chitra:


Credible nuance.


1:04:01: Alex Evans:


Head of marketing strikes again.


1:04:05: Tarun Chitra:


Yeah. Can't take credit for that one, all right? Can't take credit for all of these.


1:04:08: Guillermo Angeris:


Take credit for spotting talent. 


1:04:11: Anna Rose:


Really quickly, because we really don't have time to go into them, other kind of categories that have come up this year.


1:04:16: Tarun Chitra:


We're not going to do predictions?


1:04:17: Anna Rose:


No, no. Predictions is the next one. We're going to do a whole episode for that. This is only the look back. But this year, the ZK and Bridges, there were some before, but I think it became more experimented with this. This time around there's now this prover marketplace idea that's been growing. I know that there were experiments with ZK governance and ZK for solvency after FTX, apparently became used for the first time for real. Although I know that there's question marks there.


1:04:46: Tarun Chitra:


For solvency ones for centralized NDs are kind of bullshit, to be honest. Like you need some notion of liabilities and the problem is the liability is the easiest thing to hide when they're all off-chain. It felt like it was like marketing, most of the proof of solvency shit. It's like marketing for people who are just smart enough to understand the concept of this proof, but not diligent enough to go read about how an exchange works. Like it just like it targets a certain type of the midwit and the meme.


1:05:16: Anna Rose:


Oh no. Yikes. I wanna just wrap up my own event schedule because after, I think, so far we talked about ZK Hack Lisbon, ZKSummit9, ZK Paris, then there's ZKSummit10 in London, where I saw all of you.


1:05:34: Guillermo Angeris:


That's right, we were all there.


1:05:34: Anna Rose:


That was so cool. Also an amazing event. We won't have too much time to dig into it, but videos of all of these events are online. We'll add links to that. And ZK9, I think that week was just amazing. ZK10, I felt like it was a much more... The thing about ZK9 is I remember there was a lot of VCs there. It was kind of more bubbly. It was more like, hypey. ZK10 was more pure. Like, the research was excellent. The folks who came were kind of the people that I'm often wanting to have at events like this. It's a kind of event where the people on stage and the people sitting next to you are kind of at a similar caliber. That's what I...


1:06:17: Alex Evans:


They're all nerds. Fair enough.


1:06:18: Anna Rose:


They're all nerds and they're really in the field for the right reasons. That's kind of how I like it. That was ZK10. And then we did... I did ZK Hack Istanbul. So that was my last event of the year. Oh my God.


1:06:30: Guillermo Angeris:


Yeah, what a number of events.


1:06:32: Anna Rose:


So that was the second hackathon that we did. I think I actually, in one of my episodes recently, at the beginning of the episode, I gave a little throwback to that, sharing a bit about it. But yeah, just another shout out to ZKP2P because we mentioned them here. They came in second for the ZK Hack Lisbon event and now are a company. I hope to see the same thing come out of ZK Hack Istanbul. And we are planning a ZK Hack online in January and another ZK Hack in the future. So if anyone's thinking of building a ZK project that could become a company, think about coming to one of these events.


1:07:07:


I want to say one more thing too about your paper, Guillermo. I want to go back to the beginning, actually both of your papers, Alex and Guillermo. Going back to the beginning of the year, you had these ideas, Guillermo, talking about the work that you did, Alex, you did as well. We've been short forming at SPLA. So yeah, let's talk about what happened with that, right?


1:07:28: Guillermo Angeris:


Yeah, so it started as we chatted, it was some understanding of ZK stuff. We actually had an episode on the paper itself. And yeah, so anyway, so this work came out, it was kind of interesting, and then I believe you, for better or worse, gave us the opportunity to actually teach a short course on it. So I think it's in the ZK Hack Discord, if I recall correctly.


1:07:49: Anna Rose:


Why don't you first, though, describe what was the work? What did it end up being?


1:07:51: Guillermo Angeris:


I don't know, Alex, do you want to do this? Go ahead.


1:07:54: Alex Evans:


So in this work, and you should listen to the episode that we have on it, we looked at succinct proofs and found some simple generalizations and reductions that we think describe a lot of how we get succinctness in protocols. It is a very, very specific toolset that we build up gradually over the course of the paper. And we found, actually in the discussion, maybe during recording or shortly thereafter, it could be suitable for a course because it's a slow buildup in classic Guillermo/Stephen Boyd fashion.


1:08:30: Anna Rose:


Oh yeah.


1:08:30: Guillermo Angeris:


Slash Alex Evans nowadays.


1:08:33: Alex Evans:


Only by association. Which was just really suitable, I think, to a course because similar to how you would do it in a normal linear learning fashion, you start out with really, really simple tools and hopefully by the end of it, you're doing some real damage.


1:08:52: Guillermo Angeris:


Right. So I think that's when Anna actually came up with the idea of being like, hey, maybe we can actually make this a ZK, what do you call it? ZK whiteboard session? ZK study session study group?


1:09:01: Anna Rose:


Study group. Yeah, yeah, yeah. And the reason being is like, I think, I don't know if we talked about it in that, but maybe I asked you this after, but it was almost like, how much does someone need to know? How much pre-studying in the ZK world do they have to do to be able to follow the logic of this paper? And a lot of what we talked about was the fact that when you look at a lot of the papers that come out, they're not really written for people who aren't deep in the field. And you kind of wrote this paper where you're leading the reader through kind of you're adding the building blocks, you're kind of defining things early so that later in the paper, when you implement them, use those techniques, do something with it, the reader actually has a reference to what you're talking about.


1:09:47: Guillermo Angeris:


Yeah, exactly. And so that naturally lends itself to kind of a course structure as you suggested. And I mean, this is like, again, big brain Anna intuition being like, maybe it should be good and moves to work. And so we have, I guess, we recorded three sessions. They're all online. The course is fully open. Unfortunately, I haven't yet posted the next homework. But..


1:10:05: Anna Rose:


But probably by the time this airs, you will.


1:10:08: Guillermo Angeris:


I hope so, yeah. But the course is essentially three sessions. It goes through the paper. I think session one goes through the introduction and part one. Session two goes through section two and three of the paper, something like that. And then section three actually goes through something like proving a certain notion of soundness for FRI, which is a pretty bit more involved in the first two sections. The first two sections kind of give you the tools that you might need to understand a lot of protocols that are kind of out in the field of ZK, the royal ZK, if we may. And the last one is, okay, fine, you've spent all this time eating your vegetables. Let's do something quite real with the tools that we've built up. And so it's kind of a weird course. There's homeworks on it and the homeworks are in some ways kind of what one would might do if you read the paper and you come up with a... You're like, okay, there's proofs here that are not fully stated, let's write them down. And some of them are actually just extensions that might be of interest and things like that. And so it's worth, if you're interested in the paper and you're quite familiar with this stuff, it's just worth taking a peek at the homeworks. They're kind of fun, I think, in my opinion.


1:11:15: Alex Evans:


I hear one of the most, the last homework that you're to post, one of the questions and extensions is the entirety of a recent paper that was published, which we will not name.


1:11:25: Guillermo Angeris:


Ooh, yeah, that's right. It's very, very possible that I might, may or may not make that a question in the last homework. It may or may not be on the GitHub. But anyways.


1:11:36: Alex Evans:


Triple dog dare you.


1:11:38: Guillermo Angeris:


But with that, at a high level, it's just kind of a fun thing. I mean, it's rare that you get papers with courses that are accompany just the paper. And it's kind of funny because it's...


1:11:49: Anna Rose:


But this was the right kind of paper for something like this because it was written for someone who's learning. That's what I've noticed right away. And just in the reaction that people were having from it, so I was like, let's do this as a study group. Study groups just for anyone who's not familiar. We have the ZK Hack Project, we've done hackathons, we do online events, but we also have a really active Discord. And there we host study groups where sometimes you'll be reading the MoonMath Manual or the Thaler book. But in this case, we decided to do a short form 3-parter. And I think we actually have built a website with all of the videos on them. So we can add the link to that if you just want to watch the videos, but also join the Discord for future stuff like this. And I know that people ask you questions in that chat, and you're still answering, so that's good.


1:12:36: Guillermo Angeris:


Yeah, it's weird. It's kind of fun, it's something it’s known for, which is teach an open source course. Actually, all of our tech code is available online for both the homework and the slides and everything, and the videos are certainly available online. And indeed, actually, as an exercise to the reader, the homeworks have no solutions. So if you would like to see solutions for the homework, you should submit them as a pull request on the GitHub repository. So anyways.


1:12:59: Anna Rose:


Nice. Very, very good. So yeah, we'll definitely add the link to that. I think this brings us then to the end of our episode. And we're close to the end of 2023. Do you feel good? 


1:13:14: Alex Evans:


What a year. 


1:13:16: Guillermo Angeris:


What a year. You know?


1:13:19: Anna Rose:


Well, thank you guys so much for doing this, and thanks to everyone who worked on the show for this year. Thank you to Agni for doing those events, Rachel for being the podcast producer, Henrik for being the editor, Tanya for reading the ads. I'm definitely missing people, all my amazing co-hosts this year.


1:13:40: Alex Evans:


And you for throwing all of these events and traveling all over the world and dragging us out there. It's been really special.


1:13:46: Anna Rose:


All right. Thanks, guys, for doing this wrap up of 2023. 


1:13:51: Guillermo Angeris:


Yeah, thank you for having us.


1:13:53: Alex Evans:


Thanks. So much fun. 


1:13:53: Tarun Chitra:


Thanks.


1:13:54: Anna Rose:


Cool. Cool. And next episode we do, we should really do our look forward.


1:13:58: Guillermo Angeris:


Let's do it.


1:13:59: Anna Rose:


See you there. And to our listeners, thanks for listening.


1:14:03: Guillermo Angeris:


You almost forgot it.


1:14:05: Anna Rose:


I almost forgot it, shit.