[Anna Rose] (0:00 - 1:38)
Welcome to Zero Knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralised web, as well as new paradigms that promise to change the way we interact and transact online.


This week, Guillermo and I catch up with Muthu from Ligero. Last year, we had Muthu and his co-founder, Carmit, on the show to introduce Ligero. This time, we go deeper into some of the characteristics of the system.


We talk about how researchers are incorporating some of these techniques into their own systems, real world cases where Ligero is being used, how this system can enable client-side proving and thus more private applications, the requirements of enterprise, the limitations of current benchmarking efforts, and more. It was a lively chat with Guillermo and Muthu at times digging deep into the details. So I hope you like it.


Now, before we kick off, I just wanted to point you towards the ZK jobs board. There, you can find job postings from top teams working in ZK. And if you're a team looking to hire, you can also post your jobs there today.


We've heard great things about teams who found their perfect hire through this platform, so we hope it can help you as well. Find out more at jobsboard.zeroknowledge.fm. You can also find a link to this from our website and in the show notes. And now, here's our episode with Muthu.


Today, Guillermo and I are here with Muthu from Ligero. Welcome back to the show, Muthu.


[Muthu Venkitasubramaniam] (1:39 - 1:44)
Thanks for having me, Anna. It's great to be here. I know it's been a while since the last podcast.


[Anna Rose] (1:44 - 1:47)
Yeah, it's been a year. And welcome back, Guillermo.


[Guillermo Angeris] (1:47 - 1:48)
What up?


[Anna Rose] (1:48 - 1:50)
It's been a while since I've seen you, too.


[Guillermo Angeris] (1:50 - 1:51)
It has, yeah.


[Anna Rose] (1:51 - 1:55)
Well, actually, wait. I have seen you, but we haven't seen you on the show.


[Guillermo Angeris] (1:55 - 2:00)
Correct. You and I chat every once in a while, but the show I've been disappeared from.


[Anna Rose] (2:00 - 2:02)
I'm glad to have you back on to co-host this one.


[Guillermo Angeris] (2:02 - 2:03)
Thank you. Thank you. Always lovely.


[Anna Rose] (2:04 - 3:01)
Very cool. Muthu, you were on the show last year with your colleague, Carmit. And in that episode, we did a full background on yourself, on Ligero, on how the research developed, what work had inspired it.


I'm going to add the link to that in the show notes. I do recommend people listen to that if they want to hear a little bit more of that full story of Ligero and the company. But for this episode, I want to understand what's happened with Ligero, the project since.


And I especially wanted to have you on now because I feel like there's been this rediscovery of Ligero or Ligero techniques. The word Ligero, like I got really good at pronouncing it. I think in the last episode I kept switching between Lee-hair-oe and Lee-gair-oe.


But I got it right finally because it just kept coming up on the show. So, yeah, it's really great to have you back. I'm very excited to dive into Ligero, what's changed, what's new, why it's getting adopted.


Yeah. So welcome. Thanks, Anna.


[Muthu Venkitasubramaniam] (3:01 - 5:23)
And yeah, it's been a while since I feel like a lot has happened since the last podcast. But maybe let me just for your listeners, let me introduce myself. I'm Mathu.


I'm co-founder of Ligero, along with three excellent co-founders, Matt Scott and Carmit. I am also a professor at Georgetown University. I'm currently on leave, you know, trying to do something with Ligero.


The company. The company. So close to our last podcast is when we closed our seed round funding.


And soon after we went into this marathon sprint of, hey, we need to build a platform. We need to build a platform, which is going to make it easy to develop ZK applications. So this was our focus from September to January.


That was the only thing we were doing. And in February, at ETHDenver we unveiled our platform. And I think the response was amazing.


I want to say that from Devcon to ETHDenver I could really see the change at Devcon. I went and talked to a lot of people. Hey, like, you know, if you're focussing on privacy applications from zero knowledge, everyone had already agreed that Groth16, Circom, you know, that's the only thing you have.


And everyone was trying to work within the limits of what that could offer. And I want to say that's really great tech. But when we showed our platform, we said that, hey, like, this is no longer a limit.


You will be able to program really scalable applications that can run on any device. And then the response was overwhelming. I want to say not just from people who want to develop applications using zero knowledge, but also the community, the ZK community at large embracing, hey, like, we should think about privacy and client-side proving.


And, you know, I can tell more about it, but I think this has been amazing. And I want to say, we unveiled the platform in February. And since then, I've been resisting myself from, like, improving the zero knowledge to become faster or better, but thinking more about how to make it more useful and usable and thinking about, you know, what's the form factor in which this ZK is going to be easy for people to plug and play.


And that's what, like, from February to now, this is what we've been focussing on.


[Anna Rose] (5:23 - 5:44)
And we've seen, like, we kind of, I mentioned in this intro, but like, we've seen visions of Ligero or influence of Ligero actually entering into some consumer-focused projects. But was that happening organically? Like, did that just sort of happen because the research finally reached the ears of enough people or was that something you were actively doing?


[Muthu Venkitasubramaniam] (5:45 - 7:02)
So I think it's a little bit of a yes and no. And maybe specifically, if we are talking about the integration of zero knowledge inside Google Wallet, which had Ligero as part of their stack, I want to say that I had known this was coming, right? My, Abhi is my colleague, like we've known for years, like, you know, from our academic circles.


Actually, I met Abhi at the Google ZK event they had hosted last summer, where he was talking about implementing ZK for identity. But, you know, we couldn't use Ligero all the way. We had to combine it with GKR in a special way to get the target parameters that we wanted.


And I was like, wow, that's nice. And, you know, I want to say it's not surprising that Ligero is performant when you want to think of it, of being deployed on any device. But it was nice to hear that they arrived at the conclusion independently to use it.


And independently, as you said, I also think this year we've seen more people understand what is it that Ligero can provide in the space and take advantage of it. And watching your podcast from before, I would say that, you know, sumcheck and GKR had the moment like probably a year or two back. And I think maybe now it's Ligero.


[Anna Rose] (7:02 - 7:16)
You just mentioned that the Google implementation and actually we did an episode. Thank you, by the way, for that intro to Abhi and Matteo. I'm going to add a link to that in the show notes as well.


That was a really great one.


[Muthu Venkitasubramaniam] (7:16 - 7:40)
I actually thought it was important for even Google's implementation to get the voice out. And I thought your show would be a great place for that to happen because, you know, for Google's project to materialise, there is still a lot more steps before governments and organisations and vendors are going to embrace it. And I think getting to the publics, you know, through your podcast and other venues is going to be important.


[Anna Rose] (7:41 - 8:00)
Cool.


You sort of highlighted already just in your description here, the client side proving and then Ligero. But I'm just curious, like, what is that connection? And we might have covered this in the last episode, but like, why are you kind of describing Ligero as like client side orientated?


I think of it as just like a cool proving system. But yeah.


[Muthu Venkitasubramaniam] (8:00 - 8:57)
Yes, I think that's a good takeaway. It is a cool proving system. I think a better way to explain Ligero than just say client side proving is really minimising the memory footprint.


Now, this has implications both for client side proving, but also for server side computation. You can think of, you know, the effort by Ethproofs on real-time block proving. It has implications across the spectrum.


I want to say that what is important when you think of memory footprint is that you have a ZK application. You know, this is something you want to verify some condition, some, you know, algorithm. You can run it on your computer.


Let's say it takes, you know, a few MBs of RAM. Now, I want to prove that same computation under zero knowledge. There is going to be a transformation of this algorithm.


For example, in Succinct and RISC Zero, they're going to translate it to a RISC-V program and then eventually into a circuit.


[Anna Rose] (8:58 - 9:02)
But the proving is often happening on a server there. It's not client side.


[Muthu Venkitasubramaniam] (9:02 - 10:30)
Yeah, the prover is happening on a server. But the point I want to actually emphasise here is that this circuit needs to be kept in memory. Now, it doesn't matter where you're proving this.


And the reason is that most of these systems use a polynomial commitment scheme, let's say based on STARKs, which require the end, like sort of computing, like an encoding of the entire computation. And this is memory intensive. You've got to put it in memory to be time efficient.


Where Ligero differs from every system out there is that we don't have to do that. We can break the computation into pieces and then we can do sort of the encoding on these pieces. This helps with parallelism, but also it helps with space.


That's one feature of it. And actually, this has already been used, for example, in the works of Brakedown. They already took advantage of this fact of that you can parallelise this.


But the second feature is that the prover needs memory proportional to the underlying computation. And this requires even showing that the constraints in the underlying system can be done in a memory efficient way. And I think this is sort of a key ingredient in, I want to say in the Ligetron system, which follows the Ligero blueprint, but it provides a compiling technique where the prover doesn't have to have enormous space to prove things.


[Anna Rose] (10:30 - 10:33)
And this is what brings it client side, potentially.


[Muthu Venkitasubramaniam] (10:33 - 12:04)
Definitely. It definitely brings it to client side.


And maybe let me talk about client side proving and server side proving for a minute, right? Now, almost everyone who is doing, 95% of the people that are trying to do privacy applications use something like Groth16 or Halo 2, et cetera. And they cannot scale beyond, I want to say 1 million or 2 million constraints because they have huge proving keys.


These proving keys, you can't, you know, imagine putting these proving keys on your cellphone to run a prover. Now, with our system, the same things you will need probably 50 to 100 megabytes. And now it becomes completely manageable.


And also it's not that we are restricted with 1 million to 2 million constraints. Technically you can do like an arbitrarily large computation, but we have tested it up to a billion constraints. And if you don't trust me, you can go to our platform, you can open a browser and you can run this today.


It will run up to a billion constraints from your browser. So on the client side, you do want a prover whose memory footprint is small. Otherwise you're not going to be able to scale it on a cellphone, et cetera.


But at the same time, I also want to say, I mean, I think bringing in the Ethproofs effort for block proving is relevant in this discussion because it's not just that people want to prove blocks in very good time. And, you know, Succinct has done a great job. They announced in summer, they were able to do it.


But from my understanding, you got to use a lot of hardware to do that.


[Guillermo Angeris] (12:05 - 12:12)
Yeah. I have a hot take about Ethproofs and proving blockchains and EVM stuff. So maybe that's what we should save for later.


[Muthu Venkitasubramaniam] (12:12 - 12:52)
Let's keep it technical at the moment. We can talk about the juicy stuff later. I think what our technology, actually, this is something we might be able to release this benchmark probably in the coming weeks.


We'll show that we can prove blocks from a browser. It might take a while right now, but we have estimates and we have a roadmap where I think we can prove pretty close to real-time proving from a browser on a decent laptop. Right.


And I think at least from what I understand from the Ethproofs effort, they care about the power it takes to prove. And now you want to minimise your hardware and minimising hardware requires minimising footprint. And this is where Ligero comes in.


[Anna Rose] (12:53 - 12:56)
Interesting. Wait, Guillermo, now I'm so curious about your hot take.


[Guillermo Angeris] (12:56 - 13:30)
So sorry, I went for what it's worth. It's actually a very technical hot take. This is not like one of those like, oh, yeah, we shouldn't, you know, here is a idea.


Number one is, first of all, why are we proving an entire EVM trace? Like that's already crazy. You can build a blockchain any way you want.


Why would you like now construct a system where you have to like build an entire system, emulate the entire system, and then afterwards prove that like now middle emulation layer, which we already agree is not good even for running on normal computers, much less proving a succinct proof thereof.


[Anna Rose] (13:31 - 13:34)
But you understand why that happened. It was just because of the history.


[Guillermo Angeris] (13:34 - 13:35)
Of course, of course, right.


[Anna Rose] (13:35 - 13:39)
There's smart contract developers. There were a lot of people who were used to this. They wanted to redeploy code.


[Guillermo Angeris] (13:39 - 13:50)
Naturally, there's path dependency, but it's like, you know, we're not building a rocket and then like changing the ship, like, you know, and then being like, OK, cool, we got a launch in your rocket now. It's like we're doing software, guys, like, like this is code that like exists.


[Anna Rose] (13:51 - 13:54)
But it was like worldwide ecosystem stuff. I mean...


[Guillermo Angeris] (13:54 - 13:56)
Yeah, yeah, I just like...


[Muthu Venkitasubramaniam] (13:56 - 14:02)
Maybe I'm missing maybe a larger point. You're asking why are we trying to prove this?


[Guillermo Angeris] (13:39 - 14:03)
Not in a concrete sense.


[Anna Rose] (14:03 - 14:07)
He's like, why are you trying to recreate the EVM in the first place, given that the EVM is annoying?


[Guillermo Angeris] (14:08 - 14:18)
This is not on you specifically, Muthu. I understand why you're doing this specifically. I'm just saying like it is a weird spot we ended up in, right?


Like this is crazy. Like we have succinct proofs. We have succinct verifiers.


We have all of this stuff.


[Anna Rose] (14:19 - 14:21)
But the ideas weren't there like two years ago.


[Guillermo Angeris] (14:21 - 14:24)
And that's OK, but they're here now. Right. Like that's the thing.


[Muthu Venkitasubramaniam] (14:25 - 15:45)
Actually, I mean, I agree with you. I also think that I mean, this is maybe a direction or effort people need to think about who are doing layer one blockchains. This includes Ethereum, Solana, et cetera.


They have to define their smart contracting system. If you want wider applicability and I'll tell you this, right, like we are engaging with the enterprise and they want to write business logic and they're going to change probably where the business logic can be easily written. And I've heard from them.


They say, well, EVM is hard. Yeah, this is not hard to get it right to do it. But at the same time, they also accept that EVM is the one that's most battle tested.


So I do think a lot of effort can go into making this system better for applications rather than ZK. I think that ZK will work on any system like I think. And the amount of people invested in it, I will tell you that the proving speed, the hardware, this is going to come down.


Ligero will achieve it. But I will say even independent of Ligero, the ecosystem will bring this down. So I think effort should not be driven in terms of, hey, we need this for ZK.


I think the effort would be better if I can, if it can be driven to, hey, for these applications, we need to make our smart contracting system better.


[Anna Rose] (15:46 - 15:48)
Okay, Guillermo, what do you have any other hot takes?


[Guillermo Angeris] (15:49 - 16:19)
Yeah, I think it's like, it's related to the first point here. And but it's like, kind of separate. I've been on this rant for a little bit, which is like, like we've done this thing where we have taken the abstraction of like a blockchain as an execution environment.


Right. And in doing so, right, you of course, have to construct these virtual machines, which run on everyone's computers, which can then verify the state transitions and all of that. But like, I think we've lost the plot on sorry, again, this is Muthu.


This is like, kind of it's like...


[Anna Rose] (16:19 - 16:21)
...criticism of blockchains.


[Guillermo Angeris] (16:21 - 17:34)
Yeah, it's like a general blockchain point here, which I think will resonate heavily with Muthu given, you know, you've done work on succinct proving systems. In fact, I would say like some of the best work on succinct proving systems, actually, is like, this is crazy behaviour, right?


Like, we've like taken five layers of abstraction, put them on top of each other now. Right. So it's like, you take an EVM, which is like the thing that like normalises all these systems and everything below it.


And like, now we're proving all of these things in the middle, to like, finally allow, you know, a Raspberry Pi to be able to check everything by rerunning everything. But now, of course, instead of rerunning everything, we're just going to rerun a succinct proof inside of an EVM, which is already crazy. Instead of just, you know, not doing any of that, like, this is like, actually like insane behaviour to me.


Anyways, the project is very cool. I'm curious to see how far we can push the succinct proofs and like zk to actually, you know, prove all of these intermediate layers. But in some sense, like, it feels weird that we are doing this as like, like, this is like the, you know, the flagship project right now.


Not for Ligero, I just mean in general, what I feel for ETH system. It's like, let's prove blocks as they exist today. And it's like, like, we're writing software, guys, we can change this at any time.


It's not like we're like, you know, 3D printing rockets or something, right?


[Muthu Venkitasubramaniam] (17:34 - 18:06)
Yeah, I mean, maybe my take on that is, I mean, I think this is how systems evolve, like even if you think of operating systems, programming languages over, like how it evolved, yeah, you know, it started somewhere and sometimes we are stuck with abstractions. You can see the constant debate between like, you know, software and hardware, like, of chips having certain opcodes, etc. Like, this is not new to the zk space, right?


Like I'm saying, to computer science, like, this has always been and


[Anna Rose] (18:06 - 18:10)
And we still use JavaScript. Yeah, and it's Imperfect. 


[Guillermo Angeris] (18:10 - 18:16)
I mean, Wasm is kind of changing that. But yeah, we do.


I mean, this is the thing. And it's like, it's very weird to me. Like, I don't know how we ended up in this.


[Muthu Venkitasubramaniam] (18:16 - 18:27)
I think this is part of evolution. Like, I don't think it's about ending up there. I think it's a process.


And you know, hopefully the system will, you know, tune it to where it has to go.


[Anna Rose] (18:28 - 18:47)
I have a question, Muthu, on what you described when you talked to the corporate orgs and like EVM maybe not being suitable, but like, a lot of what we talk about today are like the zkVMs that are Rust based. Is Rust actually better for corporates? Or is that also something kind of far off for them?


Like, what language are they using?


[Muthu Venkitasubramaniam] (18:47 - 18:59)
I think that's a good, very loaded question.


No, no, I'll tell you why, right? Because one of the first programming languages I learned from my dad was COBOL.


[Anna Rose] (18:59 - 19:00)
Oh, yeah.


[Muthu Venkitasubramaniam] (19:00 - 19:06)
And a lot of corporate still uses COBOL, right? So they are still in that world.


[Anna Rose] (19:07 - 19:11)
In the hierarchy, where does C or C++, is it before or after?


[Guillermo Angeris] (19:12 - 19:12)
After.


[Anna Rose] (19:12 - 19:14)
C++ is after COBOL.


[Guillermo Angeris] (19:14 - 19:19)
Oh, C++ for sure. C, it's what, 77?


[Muthu Venkitasubramaniam] (19:19 - 20:07)
I actually, yeah, maybe. Whenever the Cunningham and Pike book came is probably for me when C was there. But I don't think enterprise, I want to say, cares about the specific programming language.


They want something that they can write their logic in a clean way and probably to be audited. So I'm sure Rust is fine. I'm sure any of these are fine.


EVM is a challenge, because if it gets compiled down to that, it's a challenge for them. But look, that hasn't stopped people from embracing it, right? We saw the big announcement of Robinhood on Arbitrum, which I think was huge in the space, right?


So people still do trust Ethereum. And I think hopefully these are things that will get resolved along the way.


[Anna Rose] (20:07 - 20:55)
Nice. I think something that differentiated Ligero, also when we talked about it last year, from a lot of the other projects that I speak with, is a focus on enterprise. In the past, there were like the blockchain kind of projects, maybe the L1s, who were focused on enterprise corporate.


But then there was this, like in ZK, that didn't really happen. It's definitely, we were starting very much like, kind of in that independent researchy area. But yeah, your focus has been to speak with those customers.


I'm just curious, like, what else are you hearing from them? So we've just talked a little bit about like the need for an easy way to deploy the business logic. But yeah, is there interest in ZK?


Do they see opportunities with ZK or systems like yours?


[Muthu Venkitasubramaniam] (20:56 - 22:44)
Yeah, no, I, maybe this is also a good, maybe a little bit of a segue here, in terms of, I want to say, what's been our vision, or at least how do I want to frame what Ligero's vision is, right? I think a big blocker in blockchains, to me, it's not speed, it's not composability, it's actually compliance. I think a lot of the ZK industry has been focussing on privacy.


ZK is helpful for privacy. But in our mind, as much as we are a ZK company, ZK is a tool. And I would also go to an extent and say privacy is a feature, programmable privacy, a lot of chains are focussing on this, it's great.


But programmable compliance with privacy, I think is the missing link. Compliance is what is going to connect blockchains to the real world. We should be able to go and stand up in a courtroom and say, hey, I was compliant, and I didn't leak information, and that should hold.


And this is what we want to focus on, right? I mean, ZK is a great tech, but if we don't provide some compliance, and I call it programmable compliance, in an easy way, it's going to be hard for adoption. And since I want to say that, since we started, we pivoted from doing our multi-party computation protocols to zero knowledge, this has been our singular focus.


We want to think about infrastructure that enterprise can use, so that it will remain compliant and private. And I want to say this is not going to be easy, but this is something that resonates with enterprise. And again, I'm not making any judgments.


It's not like privacy before compliance. It is compliance and privacy because of compliance.


[Anna Rose] (22:44 - 23:00)
Yeah, or as part of compliance, almost. If you look at something like GDPR, where you actually have to provide privacy, but you have to comply with the law. I mean, it's an offshoot example here, but like ZK could be an amazing tool for something like that, if done correctly.


[Muthu Venkitasubramaniam] (23:00 - 23:20)
Absolutely. It's not an offshoot. It is precisely it.


I'd also go all the way back to Bank Secrecy Act that asked these banks to enforce certain privacy policies. And ZK is going to be the tool to do it. But I think the product is more about compliance than privacy directly.


[Anna Rose] (23:21 - 24:33)
Interesting. It's actually like looking at, especially this year, the amount of TradFi, you know, big bank interest in the space. I sort of wonder if like they haven't fully realised yet that the wallets that they use will eventually get identified, if not already, and will be mapped.


And that will change so many of the dynamics, investment strategies. I'm assuming this is being communicated to like some of those players, but I just wonder if they realise to the extent of which this is going to change their business. This is where I also wonder if like what you just described of like private compliant, the private part of the compliant will also start to matter.


I feel like we've been talking about the privacy and how great it would be for business for years since the show started, really. And before. I'm sure people were talking about it before that.


But like the businesses didn't use this blockchain stuff anyway. So we were trying to introduce blockchain plus this private version of it. And I think that was too much of an offering.


But if they're already going to be doing blockchain, I just wonder if now is that moment that like the privacy problem will become super, super visible to everybody.


[Muthu Venkitasubramaniam] (24:33 - 24:44)
I'll say that. I mean, this is top of mind for enterprise, right? I mean, privacy as part of compliance is top of their minds.


And it's not just enterprise. It's also stablecoin providers.


[Anna Rose] (24:44 - 25:12)
Because right now they're not. Everything's public, right? They're sort of opaque because some of the action and especially if it's one of these like stablecoins that is like off-chain stablecoin issuer.


But at the moment, all those transactions, everything is public. Like it's every cash payment, every bank transaction you're making, if you're thinking of it like a bank, will be somewhere out in the open. It'll be pseudonymous for a while.


People won't necessarily know it's you, but they will eventually figure it out.


[Muthu Venkitasubramaniam] (25:12 - 26:10)
No, indeed. For stablecoins to be adopted, I mean, these are things probably everyone is saying, but it's worth mentioning. Like, you know, if you want to imagine banks on chain, if you want to imagine salaries being paid on chain and even cross-border payments, privacy is going to be important.


Maybe we don't care about if I went to, you know, Cannes and I bought coffee at Starbucks, maybe it's fine that this is on chain. But if I'm a small business and I have my vendors across the globe, people wouldn't want to reveal who their vendors are and how much they transact with them. So for stablecoins, which again, you know, are trying to achieve these goals without easy to use and compliant solution, it's not going to go to the next stage.


And this is, I want to say, at least the primary focus of Ligero in terms of when we are thinking of product design using zero knowledge.


[Anna Rose] (26:10 - 26:30)
Is there any interest among that community also for things being open source? Like, do they care? Like, the thing that a lot of people in our community care about, the verifiability, the fact that you can look at, you know, how code is created and everything, like, does that also factor in?


Or, I mean, because I feel like a lot of what they use is actually closed source tech.


[Muthu Venkitasubramaniam] (26:30 - 27:47)
I think they care about it indirectly. Now, you can see that at least historically, enterprise, let's say even financial institutions haven't invested in cryptography or cryptographic techniques. And they won't.


They actually would go for vendors to provide this service. But to trust vendors to provide the service, they're going to require these be battle tested or standardised. And to get to that place, the best way is to be open source.


So, even if they don't, I mean, at the end of the day, they probably don't care whether it's open source or closed source. But from a product and using the product standpoint, I think that is the path. But that being said, I should tell you, all these institutions, even though they are not themselves investing in building cryptographic techniques, almost every institution has a digital asset wing, a research wing that is exploring all these techniques.


And for them, I mean, when we talk to them, hey, can I try your code, right? Like, you know, going to everyone, hey, can you sign an NDA? I mean, that doesn't, you know, bode well.


So, for them, having it open source is good. You know, we are very excited. We released our code open source just a couple of weeks back.


And please go and, you know, try our tech. You know, we'd like your feedback. We'd like more developers coming.


[Anna Rose] (27:48 - 27:49)
Do you want them to try to break it?


[Muthu Venkitasubramaniam] (27:49 - 27:52)
Please. I am. Please try to break it.


[Anna Rose] (27:52 - 27:54)
To all the ZK hackers out there.


[Muthu Venkitasubramaniam] (27:54 - 27:54)
Yeah.


[Anna Rose] (27:55 - 28:40)
I want to switch gear a little bit and talk about kind of what prompted this interview. And that is the techniques of Ligero popping up in all sorts of other projects and systems and research papers. And Guillermo, I think it was in our conversations, I think, like you found an interest in Ligero.


You kind of started to highlight this to me. And then I started to see it in other places, like maybe not by name, but like the technique that was highlighted or was kind of introduced by Ligero. We start to see in things like Samaritan and Mercury, work that came out of your group, Guillermo, over at Bain Capital Crypto, also releasing Ligero based things.


And I actually forget, like, was the accidental computer, did that have any Ligero?


[Guillermo Angeris] (28:40 - 29:07)
Yeah, yeah, yeah. Of course. Absolutely.


Essentially everything. Like the way I would put it is like Muthu, I don't know how you did it, but like Ligero is like God's given protocol. Like this is like the way I would put it.


I know this is like a very strong term and this is rare to say in academic circles, but I'm going to like go out and fucking say it, which is like there is one protocol for essentially almost everything. And it is Ligero. And then everything else is like very downstream of that.


I know people look at it the opposite way.


(29:07 - 29:11)
We need to hire Guillermo as our PR. We have to, we have to.


[Anna Rose] (29:11 - 29:12)
He's your hype man.


[Guillermo Angeris] (29:12 - 29:23)
Like a hundred percent, dude. This is like, I don't know how you came up. I know there's like a history of it and stuff.


At some point I need to like, I don't know if you drink, but I would love to like grab a beer with you and ask you the questions.


[Muthu Venkitasubramaniam] (29:23 - 29:32)
You can, but you don't need to.


Like, you know, I think I'm kind of the same both ways. I don't hear too much gossip, so you can't hear gossip from me.


[Anna Rose] (29:32 - 29:43)
Are there any papers and are there any actually works that I missed here? You also mentioned the Google work, the actual research that they created also using Ligero. But is there anything else that I missed?


[Guillermo Angeris] (29:44 - 29:56)
I mean, there's a lot of stuff I think is fundamentally based on this. There is like BCG 20. There is like Brakedown.


There is Blaze essentially uses stuff like this.


[Speaker 4] (29:57 - 29:57)
Interesting.


[Guillermo Angeris] (29:57 - 30:14)
I mean, in some sense, the simplest possible protocol you could think of that actually works and it works like right. And this is why it's like, it's funny because you kind of see some rediscoveries of it in some weird sense. But in reality, it's like the thing that you would expect works.


[Muthu Venkitasubramaniam] (30:15 - 31:57)
I mean, one of the things, I don't know if I mentioned it in the last podcast, but also just want to bring my, you know, my five-year-old daughter, right? Like we watch Kung Fu Panda and, you know, they say, what's the secret ingredient? And there is no secret ingredient.


And really, I mean, as much as like, I want to talk as well as Guillermo about Ligero, there isn't a secret ingredient in Ligero. It is based on techniques that we have known since the eighties. Like this MPC in the head, the MPC we use is not something like really new that we have done.


We have definitely tightened the screws to the best way possible to extract as much efficiency from it. But the underlying techniques uses nothing more than secret sharing, which we have known for a very, very long time. But just to maybe trace out Ligero and the ZK space since blockchains, right?


We published our paper in 2017, actually. This was before StarkWare. And in fact, when we were talking to Eli and Eli formed the company, he was like, hey, like, you know, we want to benchmark Ligero.


And he said, the first system they built was Ligero. And if you look at their first paper, either, I don't know if it was StarkWare or Aurora, they actually benchmarked. And you will see that Ligero has a faster prover than their system.


So the fact that Ligero can give a fast prover, I think, I mean, for people who have developed it, it is obvious why it gives a fast prover. But this has already been with people. But here is where I want to kind of maybe distinguish Ligero and STARKs, right?


What STARKs and I mean, Eli has done like an amazing thing with the, you know, with making this really the space it is today.


[Anna Rose] (31:58 - 32:08)
For sure. STARKs being adopted throughout like STARKs and SNARKs blurring together into a single thing. I think there's very few SNARK systems that don't have some STARK somewhere.


[Guillermo Angeris] (32:08 - 32:22)
I mean, Eli is also an OG in the sense of like a lot of the results that we use, even nowadays were like Eli's results, like Eli himself, like derived a lot of these like error-correcting code results that are like very non-trivial. Swastik Partee.


[Muthu Venkitasubramaniam] (32:23 - 32:26)
Swastik and I went to school together in IIT Madras.


[Guillermo Angeris] (32:26 - 32:31)
So I mean, naturally, right? It's like it's all the same soup, right? It's like it's gotta happen.


[Muthu Venkitasubramaniam] (32:32 - 33:59)
So the thing that is there in STARKs is what I call is succinct verification, which Ligero doesn't have. This is something, wait for an announcement in a month and a half, Ligero will have succinct verification. But succinct verification is important.


And I also want to say that one of the focusses of StarkWare has been verifiable computing. They come from this view of verifiable computing. And we are coming from privacy and making it more verifiable compute.


And in blockchains, you want succinct verification. You want to verify on a smart contract. This is, you need, you know, succinct verification.


And this, I mean, there's been a lot of work refining StarkWare, STARKs to get this property. Ligero, on the other hand, I want to say hasn't found that much, at least since we've started, you know, from 2017, hasn't found its place in blockchains because of the lack of succinct verification. It's still viewed as a Web2 thing.


Hey, like I can send it and, you know, you can verify it. And I can see Guillermo laughing here because he's going to talk about Ligerito next. But here is the thing I want to say, right?


We've built something that is ZK. Now we know the wealth of how to make it succinct verification. This is going to come next.


And I think now we're going to get sort of a best of both worlds with Ligero.


[Guillermo Angeris] (34:00 - 35:03)
Yeah. It's interesting. So I think, like, I want to go back a little bit to something you said, which is like the techniques that have been known for a long time.


And like, yeah, of course, like the things have been known for a long time. And this is like, what do you do? You take error-correcting code, which have been known since like, whatever, it's like the forties.


And you take random linear combinations over finite fields, which is like, okay, yeah, like that's the natural thing to do. Right. I think that's all true in this, like, general.


So is Shamir secret sharing, which is like, what, 50 something, 60 something. But but it's the combination of the stuff that's very, very nice. What's interesting is like, Muthu, I think you come from like a like an OG MPC background.


Right. And so this is like why the MPC point is like so specific, like, oh, we took MPC in the head and made it and tightened the proofs. Whereas for me, it's actually completely the opposite.


For me, it's like the MPC in the head is now like almost like a discovery method. But the like natural thing is like error-correcting code version from which like the MPC view is a consequence thereof rather than a cause. Right.


And so anyways, I just I love this is what was very fun reading the transcript of the previous episode.


[Anna Rose] (35:04 - 35:05)
We were talking MPC in the head.


[Guillermo Angeris] (35:05 - 35:16)
Yeah. Yeah. Which I for what it's worth, I still don't actually understand.


And I probably will never, I will die not understanding MPC in the head. But that's fine. That's fine.


I mean, like, I don't think it's a particular pen and paper glass of beer.


[Muthu Venkitasubramaniam] (35:16 - 35:16)
I'll explain that.


[Guillermo Angeris] (35:16 - 35:27)
Let's do it. Okay. One of these days we will like absolutely do it.


It's going to be great. And I'll ask you a crap-ton of questions about all of this. Maybe over a whiteboard.


Maybe over a whiteboard. That'd be fun, too. Yeah, yeah.


That's right.


[Muthu Venkitasubramaniam] (35:27 - 36:52)
No. So let me say this about your comment, Guillermo. The thing is that now we have better abstractions.


Polynomial commitment scheme is the abstraction that everyone uses. So MPC in the head can be viewed as a polynomial commitment scheme. I think from even from an efficiency standpoint and even a perspective standpoint, I think where Ligero differs from other polynomial commitment scheme with the matrix and encoding is that people who have come from the complexity like, you know, Eli, where he did probabilistically checkable proofs, etc.


The perspective has been that when I make a query into this oracle, it's an element. It's either a bit or a field element. It's small.


But if you think of a query in the Ligero system, it's actually a column of elements. It's a field of elements. And in the complexity world, they want a small alphabet.


This is really what they call it. Right. And for optimising things, they need it to be a single element or a single bit.


But we come from the space where, hey, that is no longer a restriction. And so the Ligero space really explores that. And I want to say that that's one of the aspects that actually a lot of the systems today that are trying to use Ligero is taking advantage of.


Right. Like we no longer have to think of these probabilistically checkable proofs, etc., or even IOP proofs where these elements are small. We can think of them as big elements.


[Guillermo Angeris] (36:53 - 37:28)
Yeah. I will tell you that, like, I've never thought of anything as probabilistically checkable proof or even an IOP. Like, yes, implicitly, it's somewhere in there.


But like, I come from, like, you know, convex optimisation and linear algebra. And for me, it's like, dude, this thing is a matrix. Your query ain't, let's say, columns now, because we're in the column space version, querying some columns of it, asking some questions about it.


And out of it, you get some hypotheses that you can test. Right. And that's what the verifier is doing.


Anyways, this is, like, maybe for a deeper discussion on some other point. But it's so interesting to see. We have, like, what are now, I would say, like, four different perspectives, just like error-correcting codes, OGs, which I would put, like, Ron is kind of that.


Right. Like Ron Rothblum.


[Muthu Venkitasubramaniam] (37:28 - 37:30)
He's a cryptographer.


[Guillermo Angeris] (37:30 - 37:34)
Yeah. But like, you know, it's really like...


[Anna Rose] (37:34 - 37:36)
We did an episode with him on error correction.


[Muthu Venkitasubramaniam] (37:36 - 37:42)
That's how I know him too. I mean, cryptographers are experts in error-correcting codes, excluding me, but you know. Yeah.


[Guillermo Angeris] (37:42 - 38:00)
I am trying to nerd snipe. Mary Wootters has been, like, my one goal of, like, truly, like, an error-correcting code person to just, like, try to do some of this stuff. Then there's, like, you know, MPC people.


And there's, like, Eli, who comes from the PCP world. And actually, so does, I believe, Justin Thaler was doing complexity stuff on circuits, right? Way back in the day.


[Muthu Venkitasubramaniam] (38:00 - 38:22)
He's also from complexity. And again, things are changing.


I do have a complaint in this word is because they put zero knowledge secondary. So this is a complaint for me. But again, this is changing.


I want to say since we announced, like, in Denver, etc., now a lot more companies, I think, including StarkWare, where I see their announcements, they want to do client-side proving. I mean, this is great for the community.


[Anna Rose] (38:22 - 38:27)
We've seen it throughout this ecosystem. Client-side is back, kind of.


[Muthu Venkitasubramaniam] (38:27 - 38:43)
Absolutely. What I want to say here is that I'm also looking forward when they can put zero knowledge back into STARKs, right? They're working on this.


This also, you know, we invited their people to ZK proof. They're doing it. But that, I'm really looking forward to seeing when they are able to do that.


[Anna Rose] (38:43 - 39:48)
For sure.


I think part of that, by the way, that reintroduction of ZK as ZK, like, not the royal ZK, but the real ZK, ZK for privacy, the private part of it. I think there was this, like, ZK was exciting. It had all these interesting characteristics.


Then people focused on privacy. Then there was the pushback against privacy with a couple of, like, Tornado and other teams. There was, like, this scaring off of a lot of teams from focussing on the privacy part of their systems.


So I think they just put it on ice. They didn't, like, walk away. It just sort of, they went on hold on that part and they focused on these other optimisations that were, like, definitely less controversial.


In the last six months, eight months, maybe a little bit longer, but, like, around, like, really recently, it's this full resurgence of just, like, yeah, we're going to do privacy. We're going to do it smart. It's more sophisticated this time around, too.


I think you talked about this compliance. Like, I think it's, like, a little bit less big hammer privacy and a little more, like, fine screwdriver. I don't know if that's a very good analogy, but it's, like, it's definitely more thoughtful the way the privacy wants to be used now, I think.


[Guillermo Angeris] (39:49 - 40:17)
I think there's, like, yeah, there's a bit of a convergent and divergent thing happening here, too, where it's, like, yeah, like, the TC stuff happened and that's fine. I think what also happened is, like, a lot of focus went into making the proof systems fast and small, right? And that came in spite of the privacy because it turns out, like, you know, Muthu is, like, OK, like, we should have the ZK part in ZK, but certainly it's much easier to reason about a lot of these systems without the ZK part and then add the ZK in.


[Anna Rose] (40:17 - 40:23)
And the quality that they were looking for was that sort of compression, like the rollups, which don't care about privacy.


[Guillermo Angeris] (40:24 - 41:00)
Ethproofs being one prime example, right? If you're focused on Ethproofs, like, the ZK part is very cool, but it is otherwise, like, an overhead because fundamentally you're just checking stuff that's already public.


So anyways, but now it's, like, OK, cool. Like, now we have really fast things that are really, really cool and really quick to prove locally and don't require that much memory and are succinctly verifiable. Cool. Like, what do we do now?


And it's, like, well, like, we better go back to adding some privacy to this stuff, man. I don't know. Like, we called it ZK. Like, we called it ZK for a reason.


So I think that's also partially where the, like, you know, we're not kind of converging back to the point here where, like, you know, these histories merge.


[Muthu Venkitasubramaniam] (41:00 - 42:14)
Maybe one maybe controversial statement I will make is probably that it's not easy to put ZK back in. Like, I'll just say that. And if you don't trust me, go watch you know, ZK proof event on how to put ZK into STARKs.


You'll get a flavour of what I'm trying to say. But that doesn't mean they can't do it. I'm sure they can do it.


But I want to say you want you have to seriously, deliberately think about it. And one of the things, just going back to MPC in the head, is that you get privacy for free. If you started thinking from MPC in the head, secret sharing rather than error correction, because secret sharing has privacy built in it, then you know, what follows is you get these properties automatically when you are building the ZK system.


And for us, at least again, Carmit and me, what drove us to this is about the privacy and verifiable compute. I think now there's been so much progress we can, we have been good in taking all the techniques from others and putting it into our system. And I'll just give you a couple, right?


Like lookups, again, lookups were known since the 80s, 90s by Manuel Blum, but you know, using it in zero knowledge, we know how to do this now in Ligero.


[Anna Rose] (42:15 - 42:29)
I mean, lookups have been also in our, I mean, we went through, what is it, Flookup, CQ, Caulk, Logup, like, yeah, there was this whole chain of lookup work. Did you use that? Or was it, did you go back to the original sources on lookups and re-implement?


[Muthu Venkitasubramaniam] (42:29 - 44:20)
Once you abstract it away, like, you know, it's one and the same. You understand how you know how to do the memory checking, and then you can use it. In fact, we have a couple of papers, which you will see it coming along.


I can tell you a little bit more. This is about pre-compiles, you know, DSL versus ZK VM debate, I can tell you a bit more. But I wanted to go back to this point that you said of, you know, the OGs of privacy, Zcash, and also like the notoriety of Tornado Cash, et cetera.


The missing, as you pointed out, is compliance. If these things already had compliance baked in, and I maybe here, I want to tell you Railgun is one such privacy pool on Ethereum L1 that is trying to take this, that's trying to take this path. Now, I want to tie this back down to client-side proving, because you want compliance, you want something that is gated, you want to do private transactions, you want to do it gated.


Today, with Groth16, with CIRCOM, you can only get to some amount of things that you can prove. But what you can do with Ligero is now I can prove a lot more using the ZK. So every transaction, it's faster, but also I can prove a lot more compliance.


For example, you take the Google identity, what they've proved, I can use that and say, look, I'm going to use a pool only for people who have a valid driver's licence. I can also talk about, hey, I am not part of an OFAC list, et cetera. These are things that you can bake into the ZK system.


And listen to our announcements, we are going to show all the different compliance, KYC, AML regulations, including, say, even liveness check, which you have to do, can be done from client-side. And I think this is going to change the narrative of how we bring privacy to blockchains. And you're right, Anna.


I mean, TornadoCash, et cetera, has kind of...


[Anna Rose] (44:18 - 44:20)
Well, it chilled it for a period.


[Muthu Venkitasubramaniam] (44:20 - 44:32)
Yeah. And now people want this tech and we want to deliver something that people can use off the shelf and give the necessary tools so that they can comply with regulation to operate on a chain.


[Anna Rose] (44:33 - 44:53)
It's interesting. We're talking about the nuance of privacy and these different kinds of privacies. Kind of going back to the scaling side, we are getting things like benchmarking, very clear ways to compare teams.


Is there a way to compare teams on the privacy front? Like, is there any effort to do that, I wonder? Could that be coming?


[Muthu Venkitasubramaniam] (44:53 - 48:00)
I think this could be coming.


And I'll say that when it comes to benchmarks, really the one that everyone's using right now is proving a block of transactions of Ethereum. I think that's a great benchmark, but also it has focused all the efforts in, for example, pre-compiles for this, pre-compiles for that. And that doesn't quite tell you how well are you going to do when you have to do compliance of, I don't know, video recognition, et cetera.


It doesn't tell you how you can extrapolate the results for that. But also when it comes to privacy, here, maybe I will lay it down. 100 million constraints on a browser, on a laptop of your choosing, right?


Pick some application that will yield that many constraints and show your performance on a browser. And I want to say that this doesn't mean just for privacy or client-side proving. I think this will hold even for server-side computations.


If you can achieve memory footprint, et cetera, on these, I will bet you, if anyone does this, like us, even the server-side computation will become extremely faster on smaller hardware. If you think about it, and I want to say like Ron Rothblum in Succinct, he had initially two papers, and actually our paper Ligetron followed that. He had two papers on space-efficient SNARKs, but it used public-key assumptions.


No one's going to, or at least no one has tried to implement that because it's going to be pretty expensive. But that made us think about the question of, can we design... Actually, this memory efficiency, I would tell you, it actually falls under the bracket of something called complexity-preserving ZK, or complexity-preserving proofs.


And let me explain what. If you think of ZK, like initially, at least after the advent of blockchains and using Zcash, et cetera, people focused on improving the time complexity. And they were about, I want to get quasi-linear, I want to get linear time, linear time and encodable codes.


There was a lot of works trying to optimise this. And what were they really trying to optimise? Hey, if my original computation took T steps, my prover should take roughly some constant times T steps.


So the overhead is this constant in time. Now, when you think of a computation, time is not the only metric. There is space, there is parallelism, et cetera.


And now, theoretically, this has been understood what you can do in terms of overheads. But practically, let me say that I have a computation that on, I don't know, eight cores and so much memory, I can do this computation. Now, the overhead of this, when I want to prove it, how many cores do I need?


And how much space do I need? And complexity-preserving says that, hell, the overhead on every dimension should be a constant. And what we did was for time and space, can we get good overheads?


And this is what Ligetron did, really. We said that if the original computation had T steps and used a memory of some size S, then the prover will also require roughly the same overhead. And I mean, thinking of the question this way actually will help you at least target the benchmarks that you want for scalability.


[Anna Rose] (48:01 - 48:23)
Yeah. I'm wondering, do you think that like in the move towards more client-side-focused things, does the hardware question, because I mean, there was last year, in the last two years, ASICs and FPGAs and this idea of optimising hardware has been the focus. Does this sort of like walk that back?


Does this sort of like make that less important? Okay.


[Muthu Venkitasubramaniam] (48:24 - 49:22)
Controversial statement number two, I guess. I think for us, we've been thinking about hardware, of course, for a long time. But here is sort of at least my take on it is if GPUs, even commodity GPUs on the laptop browser can come within 2x speed of ASICs or FPGAs, like there's no point in going it.


And I also want to say in today's system, and I'm sure most people will agree, like doing this encoding or NTT, that is not the bottleneck. It is witness generation. And these hardware or at least what people are focussing on is improving the encoding time using this hardware.


But really you want to, if you don't improve your witness generation, it's not going to matter. So we haven't quite actively pursued using hardware for this reason, because the GPU has delivered us. And in fact, even in our current system, the encoding is probably less than 5% of the time that we spend in generating the proof.


[Anna Rose] (49:22 - 49:27)
Wow. Well, that is controversial. First time I've heard that.


[Muthu Venkitasubramaniam] (49:27 - 50:58)
Okay. So maybe this is the only segment, maybe I'm going to tell something a little more technical just for the people who care about it. Go for it.


Is that, again, as much as I loved all the research that came into linear time encodable codes and all these things, I want to say at the end of the day, we don't need to think beyond Reed-Solomon codes. Okay. And here is my take on this.


And also maybe a side remark here, like I didn't do a course on error-correcting code, so I don't know beyond Reed-Solomon codes. So take what I'm saying with a grain of salt. So here is the thing.


Now, when you think of doing error-correcting codes, now how much time does it take to do it? Now let's say that you have any amount of parallelism that you want. And the point is that any code, you need what are called linear codes, meaning codes that you can add homomorphically, like this is at least needed in most systems.


Even if you had infinite parallelism, you need at least what is called log n time to do encoding of a length n. Okay. Like we don't know error-correcting codes in NC0.


That's the technical, at least additively homomorphic linear error-correcting codes in NC0. So Reed-Solomon codes, if you give parallelism, you can do it in log n time. So even if you had linear time encodable codes, like if you think of it with enough parallelism, you can't do better than log n.


So maybe let me explain this in a different way.


[Guillermo Angeris] (50:58 - 51:03)
Yeah, sorry. I actually have no idea what that means. As somebody who like kind of knows error-correcting codes.


[Muthu Venkitasubramaniam] (51:03 - 51:29)
Good.


Let's say that I want to encode something of length n. Okay. A linear time encodable code says that I can do this in time order n.


Great. But what it doesn't say is if I give you enough parallelism, what is that time? And the point is it cannot go below order log n.


Oh, sure. Yeah, that I believe. Okay, good.


And Reed-Solomon also, you can get order log n with enough parallelism. On the GPU, if we do encoding, we get it in order log n time. So why do you want to go beyond Reed-Solomon codes when it's nice?


[Guillermo Angeris] (51:29 - 51:59)
The problem actually doesn't come from the log n factor, although I agree with the theory here. The problem actually comes from the fact that like Reed-Solomon codes absolutely trash your cache unless you're like really careful about it. Right.


So like now it's actually like the big O constants matter a lot. And in some linear time encodable codes, this is very good. I would say the RAA codes of Blaze are actually fairly good, although the permutation stuff actually becomes a little bit complicated because you end up moving a lot of data around in different ways.


[Muthu Venkitasubramaniam] (51:59 - 52:09)
That's because you are still in the stark kind of thinking where I need to encode a long thing. But when you think you're encoding something small, the cache is not the problem because it's like square root size.


[Guillermo Angeris] (52:09 - 53:13)
No, I agree. Yeah. Like when you're encoding square root, I think that's true.


I actually have an argument for why you do not want to do square root. And this is maybe gets to Ligerito if we do want to talk about that, but that's fine. I think like what is really gets really, really difficult here when you are restricted to Reed-Solomon codes, although it actually turns out to be a little bit different in the case of like binary fields versus like fields that are smooth or whatever is in smooth fields actually do have a lot of this weird switching that happens and you have some lower bounds.


Actually some friend worked on lower bounds for IO for how much you like actually need to do IO to be able to do these Reed-Solomon codes versus like binary fields, which are a little bit nicer on the cache, but not super nice. So I don't know. It's kind of hard, right?


Like asymptotically Reed-Solomon codes have a lot of very nice properties. Practically linear time encodable codes also have a lot of nice properties. So I actually, like, I don't know.


I don't make a strong of claims either way. I just think it's like cool that we have things that can encompass both. And at some point we'll figure out which is better.


Maybe it's Reed-Solomon codes in the end. And like, you know, it's the the midwit curve where it's like, you know, everyone who's in the really complicated codes in the middle or something.


[Muthu Venkitasubramaniam] (53:13 - 53:52)
No, I'm saying like, it's the same. I would apply the same logic, right? Like if linear time encodable codes are not going to give me like more than five or 10x performance, why go there, right?


Like, I mean, if it gives you more than five to 10x, like I would switch to a like an FPGA or ASIC, but I haven't seen this happen yet. Right. So, you know, definitely more research has to go.


I, you know, I'm a proponent of research. People should study linear time encodable codes. I just want to say that in case of like implementing the ZK.


And in fact, if you look at the Brakedown paper that did do linear time encodable codes, they had a version with Reed-Solomon, which was called Shockwave, which was faster than the linear time encodable codes. But, you know, that doesn't seem.


[Guillermo Angeris] (53:53 - 54:35)
Yeah, no, I agree. I agree. I mean, like, I think you can get Reed-Solomon codes can be very fast.


And in fact, actually, we have a specific demo of it being very, very fast. In fact, we did it in Julia. Anyways, we can get to that if that's of interest.


But yeah, I'm with you. I just like, it feels like we've been stuck in this world of Reed-Solomon for a long time of like, here are a bunch of nice properties that this thing has. And we're going to like decompose it.


But it turns out for pretty good performance systems, you actually don't need like the structure of Reed-Solomon codes at all. I just need like a linear code that's like quick to encode. And that's a surprising thing that feels like it's like a weird like feeling thing that I don't really know how to describe.


And maybe that freedom is completely hard won and for no reason, right? Or maybe it's actually really useful. I don't know.


[Muthu Venkitasubramaniam] (54:35 - 54:48)
Maybe I will say that differently. I don't think that's where the bottleneck is there today. But maybe as we approach it, that could become the bottleneck.


But I think we're far from that being the bottleneck. Fair enough. Yeah.


[Anna Rose] (54:48 - 55:52)
So we don't have too much time, but I wanted to highlight two talks from the recent ZK Summit, 13, that happened in Toronto back in May, both relevant to this conversation. One, Guillermo, you just mentioned was about, and I'm not going to say this right. I'm so sorry.


Like the same way it took me a while to get to. But yeah, so there was a talk by Kobi, but actually like prepared slightly by Guillermo all about Ligerito. So we should talk a little bit about that.


And then Muthu, you did a talk all about, I mean, it was, it was such a cool talk. I actually also rewatched that recently before this episode. And you talked about ZK DSLs.


You mapped ZK DSLs to like old programming languages to say where we were. You talked about vibe coding. There's like some cool stuff in there.


And so I wanted to touch on both of those talks. Let's start on Ligerito. Ligerito, it's great.


[Guillermo Angeris] (55:52 - 55:56)
You're killing it. I think it's like, it's a cute version of Ligerito. 


[Anna Rose] (55:56 - 56:09)
Very cute. It just takes me a while.


But yeah, do you want to just explain what that is, Guillermo? Also how it relates to the original system? Like, is it a variation on it?


It's smaller, I guess.


[Guillermo Angeris] (56:09 - 56:11)
Yeah. Muthu, how would you describe it? I don't know.


[Muthu Venkitasubramaniam] (56:11 - 59:06)
I'll describe it. So as I said, right, like, I mean, Ligero, just like STARKs, I mean, they don't get very short proofs like SNARKs do, right? They're not a few bytes. They are a few hundred kilobytes.


And how they scale with circuit size, again, it, you know, STARKs and Ligero change differently. Ligero scales square root in this.


Now, there is an obvious way of reducing the size. You use recursive composition, okay? Like most people, as you know, today, they use STARKs composed with Groth16, and they get, you know, the best of both worlds, fast prover and succinct proofs.


You can do the same with Ligero as well, right? I mean, once we get succinct verification, you can start with Ligero and end with Groth16. But someone can ask, hey, can I have the original Ligero system itself with smaller proofs?


Why should it be square root? And now you have to play with some trade-offs to get something smaller than square root size. And again, here, I want to say, one can recursively compose Ligero with itself in, like, sort of the most naive way.


The naive way will require, is what people do today with sharding, like, you know, Succinct, RISC Zero, they have different shards, and they compose two proofs into one and make it smaller. You can do the same. But there is another way of compressing, which I want to call is something called black-box compressing.


And what is black-box is that when I want to compress the proofs, in the second part of the proof, I don't want to prove something cryptographic. I don't want to prove the inverse of a hash function, et cetera. And under this category, I would say Ligerito falls under.


And maybe here, there is a plug-in to my academic work. There was a work called Ligero++, where we did reduce the proof size, but we reduced a different aspect of Ligero. In Ligero, there are two competing factors that makes it square root.


One is the query symbol size, which is of size square root. And the other is this random linear combination for, you know, proximity test and, you know, linear test, et cetera, which is also square root. The Ligero++ shows how to reduce the other, which is the query complexity, smaller.


And Ligerito shows that you can, I mean, you can do the other, which is the row or columns, again, you know, row and columns, but the random linear combination, you can recurse into that. But maybe before Guillermo can, maybe I should take a hot take on this so that Guillermo can answer on this as well. Now, I want to say that when we think of designing our system, I mean, you know, we would love to implement anything.


Is it WHIR, STIR, Ligerito, like any of these things, if it makes sense in our system, we will definitely pursue this. The optimisation that I want to say we are focussing on currently is not proof length, but verification complexity. At the moment, I'm not convinced that the verification complexity is going to help us in this composition.


But that being said, A, the name is super awesome. And B, the work is also awesome. 


[Guillermo Angeris] (59:06 - 1:01:33)
Thanks. Okay, so.


So like very quickly, I'll like re-explain the thing that Muthu said, but in like our own words, the way I think about Ligerito is what happens when you recurse Ligero into itself without the annoying parts, right? Like if you recurse Ligero in the standard sense, like you prove that you have, you essentially put a verifier inside of, like Ligero verifier inside of Ligero, you end up with a bunch of extra terms. Like you need to prove, like Muthu said, all of this construction about you're, you've done your hashing correctly.


You have like, put the right elements, you've done your openings correctly. And that's very weird and kind of silly. There's two observations, but the main one is the actual most expensive part of a Ligero proof is surprisingly not opening the rows, but it's in fact the verifying that, like, you have correctly encoded a vector.


And if you make that vector very, very large, you can make the rows in turn, very, very small, right? So you can like, you take this like matrix, which is your witness, you stretch it out. 


You can make these rows very small, and then you make this one vector that you receive in Ligero very, very large. But the observation now is that that thing that you now have this big object you now have, you can put back into Ligero to prove that you have opened it correctly, right? And then you can just recursively do that.


Like now we've just like created a complete, and you can do this by combining over sumcheck in like a weird way that requires not just Brakedown sumcheck, but indeed like this log randomness stuff that only happened later in 2023 via Diamond and Posen. So it's like, there's a bunch of like little tidbits of stuff that kind of like people didn't seem to have picked up at the time. And then we just kind of like put it all together into one simple system that says like, you actually can recurse Ligero into itself.


The observation that makes two things, I think true. Number one is actually, pretty easy to add ZK is my hot take. And number two is you actually do have succinct verification is twofold.


Number one is it is very cheap in this setting to evaluate things which are tensor products of each other. And the reason why is because these things decompose in exactly the same way as the witness decomposes whenever you do these recursive steps. So the verification is actually succinct at the end of the day.


And number two, and the ZK part is here is like a very dumb observation of Ligerito is once you add one more column to this matrix, it's uniformly random. Everything downstream of that is also uniformly random.


[Muthu Venkitasubramaniam] (1:01:34 - 1:01:37)
That's masking. We do that in Ligero. That's the masking.


[Guillermo Angeris] (1:01:37 - 1:02:40)
But I'm just saying like now you, the things that you're opening are also themselves very small and you're opening up very few of them. So the amount of bits to reveal is actually relatively small. And now you only need to do a mask in this like sumcheck way that people do in the standard way for this very, very first layer, which is very, very short.


And the overhead is roughly constant, right? Not, I don't mean constant in the like times N. I mean constant in the plus N sense, right?


Because it's only masking for the first subject. So I actually like we don't state this because like, you know, we wrote a note. It's like, we're probably never going to publish it anywhere because it's like just a bunch of silly observations.


Giacomo and Remco have pointed out that like some parts of the stuff they were kind of, you know, independently developing and is like in some GitHub repo and some PR, which is like worth checking out. So it's like not a thing about like the mechanics of the protocol. Like it's just kind of like, look, man, we threw five observations together and in doing so got something kind of interesting, including a super fast prover that we wrote in like Julia.


It's like 300 lines of code where we wrote all of the libraries. You know, there's no dependencies on anything. Like if you just run it.


[Muthu Venkitasubramaniam] (1:02:40 - 1:02:45)
Can I just maybe qualify that? Like you only wrote a polynomial commitment, not an application.


[Guillermo Angeris] (1:02:45 - 1:02:46)
Yeah, I only wrote the polynomial commitment.


[Muthu Venkitasubramaniam] (1:02:46 - 1:02:49)
That's not a full ZK, not a product. I just want to.


[Guillermo Angeris] (1:02:50 - 1:02:54)
Yeah, no, sorry. To be 100% clear, this is not a full ZK system by any stretch of the imagination.


[Muthu Venkitasubramaniam] (1:02:55 - 1:03:02)
This is not a complaint. It's not a complaint. I actually have two maybe specific comments to what you're saying.


And I want to say that.


[Guillermo Angeris] (1:03:02 - 1:03:16)
Sorry, before you get to that, I really want to give a shout out to Andrea, who is my co-author on that paper. He's a he's an absolute monster. And like, he's the reason why that thing exists and in a not shitty way.


It's great. Yeah. Anyway, sorry, go ahead.


[Muthu Venkitasubramaniam] (1:03:16 - 1:04:59)
I want to say that you use sumcheck on reducing this column, random linear combination column. We had the observation of recursing with Ligero itself on doing that. We have some internal numbers in terms of what the proof length will be. If we did it.


Again, we need to understand what would be the growth 16 complexity of recursing this finally to do it to understand whether that's useful. But the second point I kind of want to tell you is that you're making these matrices skinnier so that you can leverage more out of this. And I'll tell you where that can pay.


That can pay in memory efficiency. And the reason because when you make the rule, when you make the columns bigger, you need memory proportional to the column. So you will have to if you do care about memory efficiency, memory footprint on these, you can't make it too skinny because then you're going to pay the price there.


So the two competing factors. And I also want to say that we haven't used sumcheck for this reason. Sumcheck as it is, is not memory efficient.


And Thaler and other, Justin and others, they're doing work in making this more. But sumcheck or even GKR, you know, they move from output to input, which requires all your computation roughly to be in memory. And we have religiously focused on saying, look, I don't want to do anything that will remove this portability from our system.


And we are trying to work within the confines, which might be a stupid thing to do, but we want to keep it as long as we can. Like, I don't want to adopt something that will let go of this memory efficiency. And even if we were going to do this Ethproofs with real-time proving, we're going to have it memory efficient and hopefully running it from a browser.


[Guillermo Angeris] (1:04:59 - 1:05:22)
Yeah. So one statement on that, which is funny is actually on page 20, I don't know if another paper that does this. And the reason why is because we were also a little bit obsessed with this is we actually have in page 20 of the paper, we have a table that gives the actual complete prover allocated memory, like over the entire time period, not the maximum allocated memory, but the entire thing.


And it is like, only like a constant of the witness, a very small constant of the witness.


[Muthu Venkitasubramaniam] (1:05:23 - 1:05:25)
But Ligetron is smaller than the witness.


[Guillermo Angeris] (1:05:25 - 1:05:47)
Yes. Yeah. Right.


Because you do specific columns, which we can do here. So here we have total prover allocated memory over all things. But like you said, a natural thing to do is you just take column by column.


But I have my one argument here is witnesses often fit in RAM. Maybe not for like Ethproofs, but you're not going to be proving ETH proof on a phone, right? You're going to be proving it on a laptop.


[Muthu Venkitasubramaniam] (1:05:48 - 1:05:52)
Are you going to prove liveness, video recognition, compliance on your phone? Like that's going to be...


[Guillermo Angeris] (1:05:52 - 1:05:52)
Yeah, yeah, yeah.


[Muthu Venkitasubramaniam] (1:05:52 - 1:06:06)
Look, I'm not saying it's going to be billions of constraints, but 50 to 100 million is reasonable, right? Like to do 50 to 100 million constraints in like, you know, five to six seconds. In a Safari on an iPhone, you have one gigabyte of RAM.


[Guillermo Angeris] (1:06:06 - 1:06:15)
I think for two to what is a 16 million, we have 600 megabytes. That fits in RAM. 


[Muthu Venkitasubramaniam] (1:06:13 - 1:06:15)
16 million, I was saying 5-0 million.


[Guillermo Angeris] (1:06:15 - 1:06:15)
Oh, 5-0.


[Muthu Venkitasubramaniam] (1:06:15 - 1:06:17)
Yeah. 50 to 100, I was telling. Yeah.


[Guillermo Angeris] (1:06:17 - 1:06:23)
Okay. Yeah. It's like not that far off.


I guess that's my point. You know, like if you just half it or do...


[Guillermo Angeris] (1:06:23 - 1:06:31)
But yeah, I'm with you. I'm with you. We should totally do that.


And nobody is doing this. Like literally not one person is doing this thing, which is like very interesting.


[Muthu Venkitasubramaniam] (1:06:31 - 1:06:31)
Absolutely.


[Anna Rose] (1:06:32 - 1:07:13)
So I'm going to add a link to the video of Kobi presenting it and that paper. People can look at page 20 if you want to see that chart. I also want to talk about this other ZK Summit talk that you gave, Muthu, where you talked about the ZK DSLs.


You talked about... I mean, it was such a cool talk, like the history of also what your dad was working on. And you sort of at some point, though, talked about vibe coding ZK, but I was kind of confused.


Like, were you vibe coding on Ligetron or in Ligetron? Like, was it like you're vibe coding and then you just add ZK proving as the last step and actually can do it? I'm just curious about your experiences there.


Maybe we can talk about it.


[Muthu Venkitasubramaniam] (1:07:14 - 1:10:27)
I'll say, and again, I want to tell this and probably in all honesty, like I gave the title before knowing what I wanted to present in that talk. I mean, I had vibe coded, I vibe coded ZK, but I didn't know what will, like, what is the entire talk about? But I really loved the way it came out, like, you know, a little bit of homage to my dad in the presentation.


But let me say this, right? Like, since ETHDenver, when we unveiled the platform, what we have been thinking is how to make it more useful, more easy for people to develop. We are not going to imagine regulators, people to learn ZK, to learn circuits, to learn DSL.


They're going to program it in familiar languages. Even in that, like, we are not going to imagine them writing algorithms, right? So how do you make it more easier?


Well, we have LLMs that do vibe coding today. So I was like, let's try these applications that I've showcased on our platform. Can ChatGPT produce that application?


So to answer your question, Anna, what we are trying to do is how do we code a ZK application using vibe coding? The ZK part is under the hood. No one should know even what's happening there, right?


So I want to prove I have a driver's licence. My age is over 18. These are the applications we are thinking of.


So go to ChatGPT, say, I want to verify this of a certain, you know, a piece of data. This is how it is authenticated. It should produce this code.


You take it, you copy paste it into our platform, and you have a ZK application, right? Now, as a cryptographer, I should also tell you, please don't do this without, you know, supervision, because you're talking about privacy, etc. But that being said, I will say that there is a way that these systems can self-check.


And I'll just give a simple thing is that in our, in fact, none of the systems today, you can mark an input as private because none of them is ZK. But if you go to our platform and you have to mark which inputs to your application are private, this means that when I verify it, all those inputs are not provided to the verifier. Now, if you're worried about if your code is going to leak some of this input, there is a semi way of checking this.


I won't say it's foolproof is that I run my prover on this. And then if I can verify it without using that data, then my application at least is protecting the privacy of my sensitive input. So even if I use vibe coding, there is some amount of safety you can do.


But I recently saw Dan Boneh give a talk, and he was like, look, probably in the within the next 50 years, it's not just that LLMs or these AI models can generate code, it can also generate a Lean proof that the code is fine. So, you know, this is, I mean, I don't think this is sort of impossible within, I would say, even within my lifetime. So the vibe coding part, as much as it was maybe a little bit a cheesy title, it was more that we want to make it easier for people to develop applications.


And I think we've done significant strides in that, but it's still not close enough. Like it has to be even more easier to like drag and drop and do these things to build ZK. That's the only way people are going to adopt it.


[Anna Rose] (1:10:28 - 1:10:40)
You made be curious, what is the actual language that it is writing in? Like, I know you're not, you're just vibe coding saying what you want, but like, what is Ligetron actually reading or interfacing with?


[Muthu Venkitasubramaniam] (1:10:40 - 1:10:52)
So Ligetron reads WebAssembly files. This is what our prover does. So instead of, we don't do RISC-V, we do WebAssembly.


And you need a whole separate podcast. I need to explain WASM versus RISC-V.


[Anna Rose] (1:10:52 - 1:10:58)
Well, I think we've covered WASM a lot, like a long time ago, but I don't know if we've ever done a comparison.


[Muthu Venkitasubramaniam] (1:10:59 - 1:11:08)
Actually, Wei Dai in one of the ZK summits actually compared RISC-V versus WebAssembly. I think it was ZK Summit 11 or 10. I remember watching this.


[Anna Rose] (1:11:08 - 1:11:08)
London.


[Guillermo Angeris] (1:11:08 - 1:12:53)
Yeah. Yeah. One random tidbit on the Lean prover stuff.


So I've been going down a little bit of this rabbit hole of like type systems as proofs and like what it means. So I actually think it's possible to like construct type systems for which essentially like the properties that you get of this privacy, like public private divide, how you actually operate on these things, can certifiably at the end prove that no part of your data has been leaked. Or if not, like what parts of the data have been leaked at what points?


Because like there's this obvious, one of the things that I don't see yet, which probably we'll see at some point is like, it's weird that we like think of ZK proofs as like separate from like mathematical proofs, but we know mathematical proofs can be represented as like types and like a type system, right? And Rust or like Julia as we did or whatever. Right.


And so one of the things that I just like, I think would be so fascinating, especially in the age of vibe coding and AI and LLMs is, can you construct systems for which like once you write a piece of code, the output of that piece of code, much like Lean code gives you guarantees about the truthiness of a theorem. This thing gives you guarantees about the security or the privacy of like a particular underlying system, right? By composing certain pieces.


So one of the things that, you know, it's like right now we have the Dan Boneh, which is like, oh, we have the code. And then we have like a Lean proof that shows that the code is true. But like, why not combine those two?


Why can't the code itself not be its own proof of its own correctness, right? Because it compiles and type checks. Anyways, so this is just like just throwing it out there for everybody, Muthu you, but also the audience.


[Muthu Venkitasubramaniam] (1:12:54 - 1:14:10)
No, let me actually, I have a response to that.


Okay. So first I want to tell you, you probably want to, I mean, in this direction, you should look at a lot of work that is done in MPC in this space. And I am not strong in programming languages and, you know, but I have imagined exactly what you said, which is mostly that I want to define like a type system and such that any program you do in that, you have a simulator.


In zero knowledge, which I've seen in most ZK places, they don't talk about a simulator. Something is private because there is a simulator. But I think there is this theorem you can prove in this system that if it is type safe, then there exists a simulator.


If there exists a simulator, it is private. Okay. Now I want to say that since I've come full time at the company and taken a leave from Georgetown, I want to say one of the things I'm losing is these citations, right?


Like, you know, when you write a paper, I know what citations, like which year. And now you were telling me when is Hamming, when is this? Like, I was like, I have to search through my brain, like what the year.


I will tell you a year back, I would have been able to quote it like, you know, just directly from. It'll come back more too. I know it will.


But the point I want to tell you, like maybe one paper that I remember in this space is something called Wysteria. You should look at it. It's an MPC paper, which is related to programming.


[Guillermo Angeris] (1:14:07 - 1:14:08)
Is that Wysteria?


[Muthu Venkitasubramaniam] (1:14:08 - 1:14:11)
W-Y-S-T-E-R-I-A.


[Guillermo Angeris] (1:14:11 - 1:14:11)
Oh my God. Okay.


[Muthu Venkitasubramaniam] (1:14:11 - 1:14:25)
Wysteria. It's an MPC paper. And I also remember there's some work of Elaine Shi that was also related to doing programming language and proving security.


This way. So I'll send you the references.


[Guillermo Angeris] (1:14:25 - 1:14:27)
Yeah, that'd be great. I would love that.


[Anna Rose] (1:14:28 - 1:14:50)
Maybe we'll add that to in the show notes in case people are curious. Very nice. Folks, thank you so much for this amazing episode.


Wow. It was really fun to explore all these different sides of Ligero, the variations, the history, the compliance, the privacy, and also we did a few detours along the way, but it was really nice to get a chance to catch up.


[Guillermo Angeris] (1:14:50 - 1:14:51)
Super fun.


[Muthu Venkitasubramaniam] (1:14:51 - 1:14:55)
Thanks really for having me on. I really enjoy coming to this.


[Anna Rose] (1:14:56 - 1:15:05)
I wanted to say one more thing, Muthu. Thank you so much for these great guest recommendations you've been sending our way. I try to sort of do shout outs when you do that, but it's been really great.


[Muthu Venkitasubramaniam] (1:15:05 - 1:15:19)
I mean, cryptographer contacts, you have anyone? Let me know. I'm happy to introduce, like in the cryptography space.


I mean, if they're willing to listen to my email, then you'll get the contact. Very cool.


[Anna Rose] (1:15:19 - 1:15:27)
I want to say a big thank you to the podcast team, Rachel, Henrik, Tanya, and Kai, and to our listeners. Thanks for listening.