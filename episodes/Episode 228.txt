AnnaRose (00:00:05):
Welcome to Zero Knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online.

AnnaRose (00:00:27):
For this week's episode, we have something a little out of the ordinary recorded near the end of the Amsterdam DevConnect week. Guillermo, Tarun, Brendan and I jumped on the podcast for a spontaneous and pretty chaotic conversation. We do not stick to the script and manage to explore how blockchain and AI thinking differs, where it might intersect how science could benefit from more adversarial testing, why peer reviews, broken math theory stuff, and lots of random odds and ends. We may or may not have been drinking while recording this episode. So you'll have to listen to find out, but before we kick off, I just wanna highlight the ZK jobs board, which is a spot where you could find a new gig working directly with ZK tech. And I specifically wanna highlight one job post, which would have you working with my team over at the ZK validator. We are right now looking for junior researcher who is interested in exploring and writing about ZK proof of stake, general meta blockchain topics, and ways these intersect with privacy. Ideally, you'd have some technical background because we do wanna go deep on these topics. So if this sounds like something you would be interested in, check out the job ad and get in touch. Now I'll let Tanya the podcast producer share a little bit about this week's sponsor.

TanyaK (00:01:38):
Today's episode is sponsored by Zcash community grants. Zcash community grants is a grants program within the Zcash ecosystem. That funds projects that advance the usability security, privacy, and adoption of Zcash. Their primary areas of focus include wallets, core security, interoperability, Zcash apps, ongoing services, education, ecosystem, and community. With that said, they also welcome novel ideas outside of these areas of focus, Zcash community grants are huge about inclusivity and the grants committee will also consider grants of all sizes from individual hobbyists to large organizations that build on or contribute to increased integration of Zcash. Previously awarded grants have ranged in size and scope from a $3,000 grant all the way to a $1.2 million grant to apply for a Zcash community grant and contribute towards the development of the Zcash protocol. Visit the Zcash grants hub at zcashgrants.org that's zcashgrants.org. You can find the link in the show notes. So thank you again. Zcash community grants. Now here's a DevConnect chat with Anna Tarun, Guillermo and Brendan

AnnaRose (00:02:44):
We're here during a, should we still call it blockchain weeks? I don't know what they are, whatever weeks full of conferences in various cities currently, the city that we're in is Amsterdam. I think I I'm actually on day seven or eight. Oh, nice. Okay. And it is a marathon, not a sprint.

Tarun (00:02:59):
You went to the cosmos thing.

AnnaRose (00:03:00):
I put on the cosmos thing on Friday. I would do it and I feel like these weeks are incredibly fun. You meet a lot of people. It's great, but it's also like, there's this battle for sleep and not losing your voice and trying, it's like, you're trying to get around a city you're not familiar with. So there's like a lot of logistical thinking and yet you're zoned out and it's really hard. So I do feel like every time I go on one of these adventures, it is an adventure and it, it is hard actually. There's like a, it's a, it's an, you know, there's a journey that we're going through. So I do wonder Guillermo how, at what point of the journey are you right now? I am because you're long. You're six days.

Guillermo (00:03:38):
Yeah. Well, six days is like kind of a weird lie, right? Because I, I feel like it's the, the flight here and with the delay, I feel like I, I don't know if time has gone faster or slower because of like my brain being turned into a mush by the time zone change.

AnnaRose (00:03:51):
That's the other thing that it gives you is the jet lag that's right at a little doll of jet lag and much too much alcohol. What do you have this bunch?

Guillermo (00:04:01):
<Laugh> yeah, just, just say at least that's one way of putting it.

AnnaRose (00:04:04):
What about you? Where are you at on your journey?

Tarun (00:04:07):
I've been to like too many of these lately, but one thing I will say that I, I think is maybe an observation that seems positive for the Ethereum ecosystem is I say this in jest, but it, it does seem to be quite true, which is the more hackathons that happen. The more that actually any protocol development gets done, it feels like people need to have hackathons to actually, and like, there's like almost one every two weeks now, so, oh God, they really wanna get the merge done. This is,

Guillermo (00:04:32):
This is quite spicy.

AnnaRose (00:04:33):
Yeah. That's true though. I mean, it's,

Tarun (00:04:35):
I feel like it's a hundred percent true. They get everyone the same place and they're not like a company. Right. And

AnnaRose (00:04:40):
They get them thing with the tools that are there. Fair enough. I mean, that's what was really missing, I think over the last few years.

Tarun (00:04:45):
Well, I think that's the difference between like VC chains and organic chains, right. Is like they have to keep having conferences, whereas like, you know, more corporate, like blockchains end up not having to do that. Cause they have like corporate stuff, right? Like, like company. So middle

Brendan (00:05:02):
Management for 

Guillermo (00:05:04):
<Inaudible> <laugh>

Tarun (00:05:05):
Hackathons are a form of middleware.

Guillermo (00:05:07):
That's right. That's right. That's

AnnaRose (00:05:09):
Right. What about you? What at what stage of the journey are you?

Brendan (00:05:12):
So I had a bad week because I procrastinated preparing a talk that I had to do on the first day that I was here for the second day. And so I like stayed up really late. And so I, I just never had a shot at

Guillermo (00:05:25):
<Laugh>. It was getting over for you from the beginning. Sorry.

Brendan (00:05:28):
Yeah. So yeah. It's, I mean, it's been good, but, but also bad <laugh>

AnnaRose (00:05:34):
Okay. So I think what I, what I think we can start to explore is like, what, what have you been up to this week? Like what are the things that have happened? We can start easy. What are the events that you went to? You kind of remember those. Yeah. Let's start with like, what are the events, maybe some of the folks and then let's go into some of the ideas. Oh no. So what are the events that you've been to,

Guillermo (00:05:55):
Tarun you wanna wanna

AnnaRose (00:05:56):
Go first? I've spoken at or enjoyed

Guillermo (00:05:58):
This? I mean, Tarun like making a face literally approximately like 70 events. And at each event he's given like three talks. Each

AnnaRose (00:06:04):
Is the face because you don't like the question or you can't remember.

Brendan (00:06:11):
Ooh.

Tarun (00:06:12):
You know I, I, I think the events have been interesting. I didn't really actually go to the main event, like the actual hackathon, but I think the campus off, whatever, I don't know how to, would

Guillermo (00:06:27):
It be side chain events

Tarun (00:06:29):
Were pretty interesting. There's definitely a lot of people at them. You know, I, I don't think I heard too many new ideas to be honest. Oh, I feel like it was a lot more, you know, I think a lot of stuff that was like coherent it, you know, I think if you're a new person in the space, it was probably really educational. You would've learned a lot. I think MEV day was actually probably the best organized event I've gone to perhaps ever in crypto. I thought it was like really well put like professionally put on that's

Speaker 7 (00:06:56):
Cause you didn't go to zkSummit. Yeah. yeah.

Tarun (00:07:00):
<Laugh> I mean, I knew I was, I was walking into this one with that. That's why I was like, oh, you're like, oh, do you, what do you wanna talk about? Oh, talk about every event other than the one related to this podcast that we can land base you that's right.

Guillermo (00:07:13):
That's how it is. I think that's actually exactly what, what it

AnnaRose (00:07:15):
Was maybe. So didn't make it to the ZKsummit. But I think the, the reason being is that (he's boring). There was another event on the same day that asked Tarun to speak like three times, which meant he could not leave that space. Oh, right. And I, my bad was, I should have been way more communicative with you about the date. Like, I, I, I think you knew it was happening, but I wasn't like, this is the date you have to be here. And so I'm sorry. I actually, cause I really wanted you to be there.

Tarun (00:07:40):
It's alright. Everything is chill <laugh> I think that I, like I said, I kind of feel like I didn't get, and maybe, maybe ZK summit was the one place. There was lots of new stuff, but I do feel like the, some of the other conferences I feel like were more about bringing in new developers than it was about. Say like some new kind of crazy idea. The starkware thing today. I think actually I, I heard some cool projects coming out of that. So I'm kind of interested to hear go, like watch some of the talks from that. 

AnnaRose (00:08:11):
I think it's a hackathon isn't

Tarun (00:08:12):
It's hackathon. Plus people are like kind of giving talks, talks on stuff. So, and it it's like I feel like interesting thing. And, and I think you kind of pointed this out too. And I was like, we went from maybe like ZK events being mainly like, Hey, here's a paper for like a new thing that I've worked on. And like hopefully we find investors and or engineers who wanna build it to like, Hey, actually we're building this thing on top of something. So you know, that change, I think I'm not sure exactly what precipitated it, you know, things, things I've seen that I thought were interesting were like people who made tools for using a lot of, kind of, not so fun ZK software, like IDs Circom, which, you know, a couple years ago people would just be like, oh, why aren't you hand wiring circuits? I think, I literally remember once like talking to Howard and he was like, Howard from Aleo, like just like 2018 or 19. He's like, yeah.

Guillermo (00:09:09):
You know, like,

Tarun (00:09:10):
I, I don't, I don't know why I don't why people complained so much. Like everyone could just like the circuits manually. Why.You need tools to do <laugh>. Why

Guillermo (00:09:17):
Don't you just write the <inaudible> by hand? It's fine. It's easier. And I think

Tarun (00:09:19):
It's like interesting to see that, Hey, people are like building dev tools for ZK stuff like that. Actually wasn't I don't think people gave a shit as much about that before.

AnnaRose (00:09:27):
Okay. What about you?

Brendan (00:09:29):
So I went to the layer to like the L two beat conference and ZK summit, which I thought was the best. That was probably the best produced event that I've

AnnaRose (00:09:39):
Been to. He has to say that. No, no,

Guillermo (00:09:41):
I think he was paid to say that independent. I was not paid to say that. And actually it's true.

Brendan (00:09:46):
The only reason I'm actually on this episode is to say that, but <laugh>

Brendan (00:09:51):
But that, that was super cool because the venue was excellent. The food was T <affirmative> and I thought the talks were really good. I liked producer's talk on delegated proving and my teammate Jacob's talk was awesome. Oh,

Guillermo (00:10:03):
You didn't come to my talk. I'm just disappointed in you.

Brendan (00:10:05):
So I think it conflicted with something or

Guillermo (00:10:08):
Actually, no it's cuz you didn't come to my talk actually. It's probably for the better for your health. More generally speaking so, so,

Brendan (00:10:13):
So Guillermo, I'm sure it was excellent. I it, it, it either conflicted with with a polygon talk or with the time that I spent on an deck chair, like sleeping fully in the garden

Guillermo (00:10:24):
<Laugh> oh, I see. So you were sleeping in my talk. I get it. Know, I understand that. It's fine. It's fine. It's fine. Understood

Brendan (00:10:31):
What struck out to me from layer two and this might be kind of controversial was how I think expectations were being dialed back a little bit in terms of roadmaps. And I, I think like, you know, a unnecessary dose of realism <laugh> was, was like refreshing to see. So

AnnaRose (00:10:49):
Are you talking about the L two beat that?

Brendan (00:10:51):
Yeah. Yeah.

AnnaRose (00:10:52):
And you mean like everyone had been saying, we are, we are about to enter of this like full roll up world and it's actually, cause I didn't, I wasn't there. So maybe you can yeah. Say more.

Brendan (00:11:02):
Yeah. So I think at least some of the ZK teams were sort of candid about things taking a little bit longer than they had anticipated and yeah. I mean, nothing obviously against those teams, but I think it was good to like, be realistic about when things are coming up

AnnaRose (00:11:16):
Guillermo?

Guillermo (00:11:17):
Oh yeah. What events was I, I guess I was mostly just at ZKsummit and the Celestia event, which actually don't even know the official title

Tarun (00:11:26):
Of modular summit, modular

Guillermo (00:11:27):
Summit. There we go. That's the name, which I think I found out I was speaking to that, speaking at that one or in some panel or something because of a tweet thread like that. Everyone

AnnaRose (00:11:37):
Called you Tarun's alt. Yeah.

Guillermo (00:11:38):
Yeah. That's right.

AnnaRose (00:11:39):
How is Tarun and Tarun's Alt speaking on the same panel that

Guillermo (00:11:41):
That's right. Yeah. And, and I had no idea. I was speaking and I, you know, afterwards I was told like, oh yeah, I was on this telegram group with like 150 messages. I'm like, I, sorry guys. I didn't mean it. I promise. And then afterwards, yeah. So those were the two.

AnnaRose (00:11:55):
So the, and those were on the same day they were

Guillermo (00:11:57):
On the went the same day

AnnaRose (00:11:58):
Two on the same day. That's right.

Guillermo (00:11:59):
The reason Tarun couldn't come is because they were on the same day. I, you know, I really struck it out. I actually went to both and heroically showed up approximately like 20 minutes late to the other one and ran on stage. Oh. And

AnnaRose (00:12:12):
Everyone, I didn't know that I

Guillermo (00:12:13):
Damn

Tarun (00:12:14):
Could, honestly though it could have been a little more dramatic.

Guillermo (00:12:17):
I knowing kinda background, like,

Tarun (00:12:20):
Yeah, you were kind of like not rockying it. I know

AnnaRose (00:12:23):
You hadn't supposed to, what did you do? He was supposed

Tarun (00:12:24):
To Rocky and he just kind of like,

Guillermo (00:12:27):
I just kinda like hobbled off

Tarun (00:12:28):
Jogged like a 50 year old man in a neighborhood. Okay. Neighborhood in the suburb.

Guillermo (00:12:34):
Wow.

AnnaRose (00:12:34):
You could have done like some crowd work. Like

Guillermo (00:12:36):
If you, oh, I could've got everyone.

Tarun (00:12:38):
You should

Guillermo (00:12:38):
Have done that. I should have gone around clapping men. Like yeah. You know, I, I was, I was worried. Well, I was, first of all, hoping there was gonna be some background music while I was hopping on that. Would've been ideal, but I didn't get any of that. So

AnnaRose (00:12:49):
I, I feel like that day you had told me you were pretty tired too. Was a rough day.

Guillermo (00:12:54):
I was like, I literally, I don't remember actually my ZK summit talk. Wow. At all. Like I just like have no idea what happened. My brain is, it

AnnaRose (00:13:02):
Was really good. All good. Was it actually? Yes. There's recording. Are you, are

Guillermo (00:13:05):
You saying that? Just because you're on this podcast, you know, <laugh>, I think that's the only reason you're on this podcasts. Cause you have, you all say that are, you must say that

Tarun (00:13:11):
Just by law.

AnnaRose (00:13:12):
You brought me on this podcast. That's that's right. That I said, you said very good. No, I think, I think we're good. Okay. Okay. We're good. You were good. Aw, thanks. It was really great. And people can actually now see it. I mean, it's already on the livestream. We're gonna have videos soon, so that's

Guillermo (00:13:23):
Right. Cause you're like cropping them to the individual things.

AnnaRose (00:13:26):
Yeah. Yeah. I don't think you need to worry. You also, you had a few people in the audience who like I could tell there was like a language that you were speaking to them about some kind of theorists. Oh yeah.

Tarun (00:13:36):
The,

AnnaRose (00:13:36):
The measure the, there a few people going like yeah,

Tarun (00:13:38):
He knows what he's saying,

AnnaRose (00:13:40):
But it was very niche.

Tarun (00:13:42):
No, no, no. The best

Guillermo (00:13:43):
Making

Tarun (00:13:44):
This is Guillermo loves shitting on this one particular type of math. There's there's a couple types of mathematicians that he, he, he Guillermo likes to like smoother version of the world than exists. And so one of us

Guillermo (00:13:55):
Roasted live,

Tarun (00:13:56):
One of the ways of doing that is to shit on people who have who have somewhat complicated mathematical theories that in practice, you don't actually, you know, you might be computing, something that is related to this, but you actually never use the theory. But like, if you go talk to like a math person they're no, no, no. This is obviously the thing you're doing in production. You're obviously competing a big integral. It's like, no, you're not,

Guillermo (00:14:19):
None of this actually matters. Right.

Tarun (00:14:21):
Right. So,

Guillermo (00:14:22):
But, but yeah, yeah.

Tarun (00:14:22):
It does matter filtrations matter, man.

Guillermo (00:14:25):
They do not.

AnnaRose (00:14:25):
What kind of math was that? It's

Guillermo (00:14:27):
Called measure theory. I mean, I should be very careful because I, I suspect that there's a non zero number of people who are gonna listen to this and be like, oh my God, like this do it is either absolutely insane. Or, which is true. I guess that's fair. But, but secondarily like has no idea what he's talking about. No, I promise I've studied measure theory. It's it's unfortunate for everyone involved. I'm sorry if you have as well, I would not recommend

Tarun (00:14:46):
It. I love measure theory.

Guillermo (00:14:47):
I know that's exactly why I would not recommend. I mean, imagine the kind of people that study it is like Tarun. So I don't

Tarun (00:14:52):
Wanna do that. It's so there's a lot of very well known paradoxes in like the formalism and formal logic of math, where like math is like not consistent in a lot of ways, like the kind of basic rules of like how you count

Guillermo (00:15:05):
Numbers

Tarun (00:15:06):
Or proofs about the natural numbers don't work. And one of the most interesting set of these counter examples that like, say that like, Hey, one plus one might not equal two in like all scenarios that you might care about is usually these examples for measure theory. And so like logicians really care about this stuff. Most people who are practitioners who like care about something like in the real world don't but if you care about like the foundations of math, like does, is can math be logically consistent from like a philosophy standpoint, not like a practitioner standpoint, you know, this is, this is actually like a very interesting form of,

Guillermo (00:15:41):
I still dunno where you're talking about. I think Manar, the fact that you can decompose a sphere into four spheres makes perfect sense. A hundred percent makes,

Tarun (00:15:48):
But, but these logical paradoxes teach you about the limits of your abs traction. So like that's a, that's a worthwhile, that's a worthwhile endeavor like philosophy. Like it's not like you're thinking of it from the perspective of like, can I, can I put it in a touring machine? <Laugh> that's not the point. The point is like the epistemological foundations of like a lot of stuff that we talk about has to somehow be consistent, but it's not. And the, these counter examples are worth understand Reality.

Guillermo (00:16:12):
I could fully agree. I could, I, I'm not saying the term I have for this is I believe mental masturbation. I'm not saying that that's a, that's necessarily a bad thing. It's a worthwhile endeavor. We, I mean, yeah, at some point we were just talking about math as art or something, but you know, like, it's great. I'm just saying, you know, if someone tells you, but not Tosky and prod, you should run away immediately or even sure.

Brendan (00:16:33):
Sure, sure, sure, sure. If we, if we start talking about ZFC, I'm leaving <laugh>

Guillermo (00:16:39):
I didn't,

Tarun (00:16:39):
This is why I didn't mention any of the set theory, reactions. I just like went straight to like epistemology and philosophical arguments directly. But I, I think, I think like the, the, the mental masturbation aspect of it is, you know, why do people like reading fiction? They like this like imaginary notion, like the notions of like, I have some core abstractions I can build up these complicated things and I can run into conflicts dilemmas that I would maybe myself never run into. And for mathematicians, this is the same thing. Wow.

Brendan (00:17:10):
Yeah. I mean, like, even in crypto people like thinking about things to are imaginary, like, like developing apps for Cardano

Speaker 8 (00:17:17):
<Laugh>

Tarun (00:17:21):
Right. Well, I guess

Guillermo (00:17:22):
Wow. What a spicy take maybe,

AnnaRose (00:17:24):
Shall we let our listeners know what we're drinking right now? Or shall we not?

Guillermo (00:17:29):
I, we could leave it. We'd leave it as a, as a surprise at end of the episode. I don't, I don't think it's gonna be that surprising. I given our current state of being, but, you know,

Tarun (00:17:37):
All right, well, actually a kind of related question to this, which is a debate I had with this old coworker of mine, who like, I guess maybe you actually,

Tarun (00:17:46):
You worked with him was with is my, my friend who, who works on sort of like building these like human level performance game bots at Facebook and deep mind. And like the things that like beat humans at like StarCraft or go or whatever. And he's been working on this game called diplomacy <laugh>, which is like, which is like a really annoying, like, it's one of these games where like you coll with other people playing by like sending them text messages. So like, you're, you're, you know, the game is like, you want to like, kind of like control all the property in this like virtual world, but you can't do it on your own. And you have to like form these allegiances and then betray people at certain times, it's a form of like game where it's like, it looks like a GoBoard or Stratego, but because of the spoken language thing, the state space of the game is way bigger. Mm-Hmm <affirmative> because people can suddenly collude. And like, when they collude, they like change, like how many moves are actually accessible to the different types of users, stuff like that. So like, it, it

Guillermo (00:18:41):
Real world.

Tarun (00:18:42):
So from a right from this kind of like, Hey, do we, how do we build automated bots that can be humans at this, but also

Guillermo (00:18:48):
Like predicting collusions, all these things, there's all the mechanics within it too. Right.

Tarun (00:18:52):
And a lot of it, a lot of the success of like being able to beat the humans comes from these like large language models, like G P T Three style stuff. And the problem with that, like, I, we were just having this argument at this bar in, in New York. And I was like, obviously like drunk yelling. I was just like, like

Guillermo (00:19:08):
Usually are I the reason

Tarun (00:19:09):
You, he, he was just like, ah, like we don't have theory for this, but like, just make it bigger. Like just make the model bigger. I, I don't really give a shit why it works. And, and like, we were just, we had this like interesting kind of philosophical argument between of like the difference between like AI and crypto, where like in crypto, because you actually care about the adversarial behavior, existing against your model. You're not just like, oh, I, I don't care if my model is like good, perfect. In some sense up to some like very, very well controlled error, you basically need a lot more mathematical formalism. And, and, you know, my friend was, he was just like, yeah, like, who cares if we don't know the theory? If it works and it's like, good enough, if it quacks like a duck, it looks works like a duck. It looks like a duck then like, it must be a duck. And I was just like, yeah, but like, do you have any sort of like, there's no epistemology for why this thing even behaved correctly. You're just like, okay. Yeah. I was able to sort of predict that like Anna, when she plays diplomacy, talks a lot about sparkling water. When she's trying to like, say that she makes these like sparkling wine, Jo, you know, like, you know this, so people write that are like X is sparkling. Oh, I

Guillermo (00:20:15):
Love that joke. That's my favorite joke in the world, your

Tarun (00:20:17):
Template. What is

Guillermo (00:20:19):
Joke's have you never seen this?

Tarun (00:20:21):
You, you explained one.

Guillermo (00:20:22):
Cause so the, the, the classic joke goes it's it's only a Frankenstein if it's from the Frankenstein region of France, otherwise just a sparkling monster. Yes. Got it. That's so got it. And then it's like,

Tarun (00:20:34):
It's like, you know, yeah, sure. They're learning some pattern matching on this, but like, you don't actually understand like why people are colluding or like the strategy that's actually being learned of the different players in the game. And yes, it's effective, right? Like it somehow has worked, but yet you have absolutely no understanding how to transfer any of this knowledge. And you have to like, basically increasingly just throw more and more computation at it and like less and less like actual strategy. And so I, this is

AnnaRose (00:21:01):
A game.

Tarun (00:21:01):
This is diplomacy game. And

AnnaRose (00:21:03):
Is the point of the game to show you that you're just throwing a lot of computation at it instead of being able to do this, or is this more like, this is how this game, this is kind of the no

Tarun (00:21:11):
Humans have played this game for like almost a century. Oh,

AnnaRose (00:21:14):
You mean diplomacy? Like the concept of

Tarun (00:21:16):
Diplomacy? No, no, no, no. This is a game game with specific rules. It's a game called diplomacy. Okay.

AnnaRose (00:21:20):
I don't, I

Tarun (00:21:21):
Don't. And it's like a board game that like can last like 20 hours. It's like a really like intense a game and it's can played up to like, I think eight players. And basically what happens is like in the middle of the game, people will start colluding with each other and they kind of can communicate with each other in certain ways. And so a lot of the game strategies, not just like the pieces on the board, it's also like trying to figure out if like two players are actually one now or like, if they're breaking up and that opens up the state space. Right. Cause like, you, you, you, as you're playing the game, you might have gone from eight real players, only two, because there's two cartels of right. And so that, that changes how you design, how you try to beat this versus like something that's a go where it's yeah. It's like sort of partial information, but it's actually really a, a game of complete information. It's just that like, it's too big of a search space. So you're just trying to like, not pretend it's incomplete and try to learn as much as you can from a small number of moves here. It's actually incomplete. Cause it depends on our spoken language. Like we are talking to each other and communicating and like that changes the, the kind of action space. Again. It's also quite imperfect too.

AnnaRose (00:22:25):
And it's, it's almost emotional, right? It's like, you're gonna collude. Right.

Tarun (00:22:28):
That's why I made this kind of bad joke about like, Hey, maybe like you, when you like, you, you make a joke to someone when you're colluding with them. You like say the sparkling France region. Oh, <laugh> Mayos a little too. Yeah.

AnnaRose (00:22:41):
There's, there's a lot of references there.

Tarun (00:22:42):
I may not have had.

Tarun (00:22:43):
Yeah. But, but but, but, but I, I get, the reason I bring this up is like, there, there's some sort of notion of one of the reasons I like crypto, even though this is not a reason, GMO does clearly <laugh>. Is that, is that like, I, I believe in like very strongly in the value of like the epistemological foundations of like, whether you can reason about why something works and you just in AI, we're just like completely just, we went, we started the early days of AI actually were really focused on. Right. And we just threw it outta the water cuz we're just like, yeah, we're just gonna throw more GPUs at it. We're just gonna use the energy consumption of Kenya to just like, you know, to train this diplomacy model and it, but also not have any understanding of like why certain strategies work or, or the reasons for anything. And, and that I think you know, one thing about cryptos, I feel like it does actually try,

AnnaRose (00:23:32):
I, you think it does do it, so it,

Tarun (00:23:35):
But this gets down to the, the one philosophy I was is you should care about epistomological foundations, including measure theory, which he I mean, no, I care about measure. I like measure theory. It's a very pretty thing.

Guillermo (00:23:44):
It's irrelevant in a lot of cases, but I, I think the big thing is that unlike cryptographers, right? Like AI machine learning, you know, none of this has had to deal with the fact that like North Korea is trying to like screw with your like, system, right? Like in order to do that, you have to like, they're

AnnaRose (00:24:01):
The hackers in.

Guillermo (00:24:01):
Yeah. Right. Like my point is, you know, crypto have, is this like daily attack audit. That's like crypto, I mean, cryptography generally, although we suspect crypto as well, but, but you know, like, no one's gonna be like, ah, yes, I'm gonna screw with your GT three model in order to like, make you say something you did in intent. Ha like whatever you're gonna do about that now. But people

Tarun (00:24:19):
Do do that for these image models. No, no

Guillermo (00:24:21):
People do do that. And this is great. I love, love, love adversarial, not adversarial learning, but in fact like adversarial, like yes,

Tarun (00:24:26):
Someone, someone, someone I do think actually we should get on this podcast is this guy who is fuck, I'm forgetting his name, but he's he's one of bonnets he's co advised by bonnet and someone in, in the theoretical computer science department of Stanford. Okay. And he, he has like, his entire PhD has been, he, he actually did a bunch of like Manero attacks in the beginning of his PhD, but the end of his PhD was just like, adversarily breaking like lots of AI things and like trying to generate like kind of treat it like a crypto problem. And then like destroying like the facial recognition thing. Mm-Hmm <affirmative> or like turning like hotdog into not hotdog. Yeah.

Guillermo (00:25:02):
With like single stickers or single pixels or something that you can do that.

Tarun (00:25:05):
Absolutely. And, and I think like, yeah, you know, the point is like, if you don't understand how your model works, you can never actually make it outta super resistant. And that's just like, I don't, I think that's like a fundamental truism of nature and like, we haven't, well,

Guillermo (00:25:15):
Some people might tell you not, that's not true. Right. They might just like, be like, oh, it's just fine. It's train on the distribution of like generated samples of generative service samples. And afterwards retrain again, until you reach a fixed, you

Tarun (00:25:25):
Don't even know if you have the right. I,

Guillermo (00:25:27):
I, I look, I'm just, I'm just giving you the argument. I'm not saying I agree.

Tarun (00:25:30):
Yeah. Yeah. Look, look, a lot of people got very rich from convincing people that like, that was all you needed to do to do self-driving cars. <Laugh> like, I, I, I mean, yes, this is true, right. I, it has not happened yet. So let, let, let the point be known that the's no self-driving cars really. They're not many like right. Most of it is still like

Guillermo (00:25:48):
SFA where it's always beautiful and sunny and there's no problem. Well,

Tarun (00:25:51):
Phoenix really?

Guillermo (00:25:52):
Oh yeah. But that's just

Tarun (00:25:53):
Phoenix apparently really easy. No, no, no pedestrian traffic, cuz it's like a suburban city. So even though they had one accident, one person came by self turn car there. So

Brendan (00:26:04):
It's all of puristics. Right. It's not like a, this like single model, like knows how to drive a car. They just like put them around edge cases and

Tarun (00:26:11):
That's right. But the investor pitch decks,

Guillermo (00:26:12):
<Laugh>, it's all they all

Tarun (00:26:14):
Say about this shot. Right? Like, and, and like, this is why I like my, my friends in AI. I feel like I'm just like philosophically drifting further and further away from them because of this, like this fact that like none of them seem to give a shit about the same anymore. They're just like, must just like throw more data at, in pro odd. It's fine. We'll eventually fix itself.

AnnaRose (00:26:30):
<Laugh> is there a moment where these two fields merge enough that like the attack surface is attractive so that it could be like adversarial? Oh,

Guillermo (00:26:39):
I really hope so. That would be

AnnaRose (00:26:40):
Interesting that you actually like have to be serious.

Tarun (00:26:42):
Well, I think maybe a good question is like what types of applications of AI do you think that would happen? Like the nation states fucking with facial detection so that someone else can't detect their spies, like a simple I'm sure that look given how many papers have been written on this in the last five years of machine learning literature. I would not be surprised if like there are some nation states that's tried to do that.

Guillermo (00:27:02):
Yeah. Yeah. For sure. It like, that's the easiest, low hanging fruit, but like you could imagine any number of other things, right? Like you could imagine like more complicated systems where you're just like, by putting in just the right input. Like, congratulations you're like now in, or like you just like more interesting things, like just end up being wrong at a structural level that are really hard to notice until like way later.

Tarun (00:27:18):
Yeah. And one of the problems, I think like philosophically between something like classical optimal control, which is like, what's used to do autopilot in planes where you

Guillermo (00:27:26):
Do have weird, we do have guarantee there are quite weird, but you know, quite strict guarantees about what it does

Tarun (00:27:31):
Versus like the self-driving car, doing reinforcement learning and like trying to like teach itself from its mistakes is like, you don't have any guarantees in the latter case. And in some ways, like, I, I like think people kind of underestimate the more and more we have the internet of shit. I mean the internet of things, <laugh> the more, the more more and more of these, like it's a great account ML attacks that will happen. And the more that maybe crypto and AI have, like, but it's gonna be AI having to like eat some humble pie. I really

Guillermo (00:28:02):
Hope. And Andrea does not listen to the spot, get asked 

Tarun (00:28:05):
Or which Andre

Guillermo (00:28:06):
Tesla.

Tarun (00:28:07):
Oh, <laugh> I mean, come on. The dude wrote a fucking blog post of writing a Bitcoin node as if he's like paying attention new in cryptography. Oh, very recently too. That's right.

Guillermo (00:28:19):
Yeah. Yeah. Recent

Guillermo (00:28:21):
Finish him.

Tarun (00:28:21):
<Laugh> no, he's, he's like, he's like, he's kind of like,

Guillermo (00:28:26):
He's really fucking smart though. He's

Tarun (00:28:27):
Like the GMO of the, the, the self-driving car revolution. I can't tell

Guillermo (00:28:31):
Whether this is an offensive statement or a really flattering one. I, I actually think

Tarun (00:28:35):
It was both.

Guillermo (00:28:37):
Hey, well, thank you. But

Tarun (00:28:39):
Hey,

AnnaRose (00:28:40):
I, I am now wondering though, what is the overlap like of the AI community? Like you were to talking about like your AI friends. Yeah. Have some of them moved over?

Tarun (00:28:48):
No. A lot of them just are view me as the weird like guy in crypto. Who,

AnnaRose (00:28:52):
Who like has their

Tarun (00:28:53):
Nephews that's right.

Guillermo (00:28:54):
You're like you're you're creating systems to attempt to topple governments, yourself personally, Bernie.

Tarun (00:28:59):
Well, they all still kind of only think of it in terms of this, like whatever Bitcoin maximalism, like God, like everything about like escaping a country and stuff like that. Oh

Guillermo (00:29:08):
No. But I

Tarun (00:29:09):
Do think they've like started to appreciate stable coins. Like, so for instance, like my mom has started sending stable coins. I'm bucketing my mom in this cuz like, you know that she she's like statistician and she's more of like classic

AnnaRose (00:29:21):
She's AI.

Tarun (00:29:21):
No, but she's like classical statistics, like, you know, clinical trial stuff.

Guillermo (00:29:26):
My mom sends me stable coin stuff, but for a very different reason. But

Tarun (00:29:28):
Your mom's a degen. Yeah. That is true. Like GMO's mom is like farming alongside of the big dog, which Anon is she? Then I have no idea. She has not told me. I did. I did get the privilege of finally meeting her recently at graduation. And she thought I wasn't real. So it's like, it's the same as the alt thing where people

Guillermo (00:29:44):
Think she really did. Yes. For the whole, for the like the longest time

AnnaRose (00:29:47):
Keeps talking about this fictional character called Tarun that's

Guillermo (00:29:50):
This joke he's telling him to do things. Yeah, yeah, yeah, no, no, it's this joke. It's like, it it's definitely like tos, not real. Like every time we're gonna meet him, like he just somehow dips the last at the last second. So he like, obviously can't be real. Even my girlfriend was thinking this too. And she was like, are you serious? Like, like I've seen pictures, but like clearly, probably a paid actor. So, wow.

AnnaRose (00:30:08):
That's such a flip on the Twitter narrative, you know,

Guillermo (00:30:10):
Know it's exactly the opposite shock

Tarun (00:30:12):
Exactly. IRL on Twitter, not the same who would've thought.

Guillermo (00:30:15):
I mean, and then, then you,

AnnaRose (00:30:16):
Who is, who is out.

Guillermo (00:30:18):
Right. And then you ate repa actually, but sounds weird to, but I literally do mean like Venezuela and REPA is like, you know, we're just for my 

Tarun (00:30:25):
Her Carolyn's mom's food. You gotta eat it. All

Guillermo (00:30:27):
Right.

Tarun (00:30:27):
There you go. Confirmation. No shout out.

Guillermo (00:30:29):
There

Tarun (00:30:30):
You go. But I guess one thing that maybe the ZK stuff, I think in general maybe, and I don't know if you guys I'm curious of like, whether you think this will be the way that AI and crypto actually is that there's just like a lot more complicated applications that are sort of closer to not, not the complexity of like a GPT 3 style model, but like simpler AI models that I think we're gonna start seeing people make ZK proofs of validity for. So like one way of saying, Hey, this AI model was a not manipulated by some adversary example. Neat is it was like trained on like these particular data set and you can verify here's a proof of the data set. Here's a proof of like the training model, the inference. So one of the cooler examples I saw was this topology, which is like this like starkware game engine disclosure, tiny investor, but <laugh> but they made a neural net on starkware that only inference.

Tarun (00:31:26):
So like, it, it, you had to train it elsewhere, but it would like generate a proof that, of like given a set of input data points that like it generated the right data points. And like, you know, in crypto that amount of computation, they were doing like pretty dense matrix matrix, multiplies, like the matrix sizes were like the, you know, a thousand by a thousand, like it was something that like you could never even imagine doing on a public chain right now. And somehow the there's also this future world where the ZK stuff enables these adversarial things to somehow be more transparent and like that, I don't know who in the world is thinking about that, but like, there's gotta be some genius somewhere in Russia, like thinking about, or like maybe a left Russia out think like that.

Brendan (00:32:05):
I, I know of one, I think world coin is looking at doing

Guillermo (00:32:09):
That's difference coin actually

Brendan (00:32:11):
Like on the so on hardware. Yeah. I

Tarun (00:32:14):
<Laugh>

Guillermo (00:32:15):
And I was like, no world, but

Tarun (00:32:17):
Yeah. I love Remco though. Yeah. Very smart too.

Guillermo (00:32:20):
Yeah. Although we had a weird Twitter thing with what is it on Ramez on Ramez? That's right. That's right. That's right. But, but

Tarun (00:32:27):
Anyway, I guess my point is I, I, I think like I hope that maybe, maybe if I actually make it to the ZKsummit and anna, lets me give a talk <laugh> I'm I'm actually gonna try to do a talk of like zero knowledge proof for AI people and like try to give these like examples because I, I actually think like there is a lot of potential overlap if the ZK stuff gets to the point that you can like help enforce some like, Hey adversaries didn't do more than X. Well,

Guillermo (00:32:53):
But that also yields really funny things. Right. Where if you have an adversarial example for a fixed network, you could just to put it in and have like a very nice little proof that says I computed it. Right. I promise which you did. Well, the key, the key, the

Tarun (00:33:05):
Key though, let's say, let's say you're doing, if

Guillermo (00:33:06):
You have a robust algorithm on fine. Yeah, yeah. Fine. Robust training. We are, we are pre like, assuming that okay,

Tarun (00:33:12):
Fine. We're we're assuming like here's one, one example that like I have this, you know, I have this friend who does like, like research that I find very, like it's never gonna, it kind of is always gonna be an orabora in some sense, but like sort of like ethics and AI and like, how do you reduce bias stuff? Because it's actually quite hard to do, but imagine if you could actually say like, I trained this algorithm on this data set, here's a public data set and here's a proof that I did not edit the weights and I did not retrain or augment any of it. And like, you can see that like, Hey, like this is the sample has this much diversity or, or of like, you know, population sampling. Right. And like that way you can publicly verify that, Hey, it's not biased in some way. And somehow like the ethics in AI, people aren't super technical, don't know a lot about crypto. And so they don't think about this to type of stuff. It's the same for like a lot of adversarial learning people. And someday there will be that a different type of process. The

Guillermo (00:34:07):
Merge.

AnnaRose (00:34:07):
I wanna go back to, I wanna go back to the <laugh> the topology one, like the thing is with that example that you were giving, were you when it says like, is the validity proof, like the, this idea of like using validity? Is it in the protocol itself or is it just the, that it's on a ZK roll up the fact that it's no

Tarun (00:34:24):
Like, yeah. The contract actually does generate a proof of each constraint on like each matrix on each multiply fuse, multiply ad tech.

Guillermo (00:34:32):
I mean, they also did like integrators on chain and stuff. Right? Like RK four, like, like

Tarun (00:34:36):
They're definitely like of all the ZK

Guillermo (00:34:39):
Crazy.

Tarun (00:34:39):
They're like the only ones where I'm like, wow, you're really trying to do something that's gonna take 10 years. Cause like,

AnnaRose (00:34:44):
It's like your big vision.

Tarun (00:34:45):
It's like kind of crazy trying to do a full game engine this way. But like, if you can do that then like this AI type of stuff is gonna be similar. It's gonna have a similar, so there's like a whole world of these things people don't think about. And I guess open end episodes a good time to pose that question.

AnnaRose (00:35:02):
Yeah. That's good. If you have a plan for that talk. Ooh, I'm so down.

Tarun (00:35:06):
I mean, I'd probably do it with my friend. I'd basically be like, he's a skeptic and I'd try to like basically bring him and be like, we're gonna, we're gonna,

Guillermo (00:35:13):
We're gonna, we're gonna show you some stuff kid

Tarun (00:35:16):
We're no, no, no. We're gonna have a dual, a dual talk. We're gonna have like, oh, okay. That like I present the crypto side, he presents the AI side. It's like one of those like thesis, antithesis synthesis type of talks. And like he does the, I do the first thing. He does the second thing and then we kind of merge. And so like where could they merge?

Guillermo (00:35:32):
You have not been drinking enough m to not be able to say antithesis yet.

Tarun (00:35:35):
<Laugh> anti oh

Guillermo (00:35:36):
Shit. I already, oh,

AnnaRose (00:35:37):
You gave away. Damn

Guillermo (00:35:38):
It. Well, if people are listening well, no. Then there you go. <Laugh>

Tarun (00:35:42):
Are there any other types of technologies you guys are like, oh, I wish like crypto intersection. That

AnnaRose (00:35:47):
Was exactly the question I was just about to ask you. I kid you not, you literally, we just had like a, like I was about to say I was, what I was gonna say is like, I know this episode is about us being an Amsterdam, but are there any other fields basically that we should be having adversarial models in? Like, why aren't we using a lot of this stuff and you go to AI because it's like, so super technical, a lot of data. It's very exciting.

Tarun (00:36:11):
Also influences like everyone on Earth's life now at this point. Oh yeah. But are there in weird ways? Terrifying. It it's terrifying.

Guillermo (00:36:17):
S yeah, I dunno. I dunno. Was it told me, and I have no idea to the aspirate story, but apparently like auto land on planes now actually uses neuralnet stuff. I

AnnaRose (00:36:25):
Feel like the other, all the

Tarun (00:36:27):
Other times,

AnnaRose (00:36:27):
That's right. Maybe the challenges every time, every other time, you're trying to like mix crypto with something you end up with these sort of like, we're gonna tokenize, oh, God, look

Tarun (00:36:36):
Denta coin exists. We're gonna tokenize no denta

AnnaRose (00:36:39):
Legal fees. And it's just very boring. <Laugh> you're what denta coin max, is that what

Guillermo (00:36:47):
You just said?

Brendan (00:36:48):
No,

Guillermo (00:36:48):
Denta coin whale

Tarun (00:36:51):
Denta was a really bad ICO in the, in 2017. That was like a legend Was like

Guillermo (00:36:57):
The,

Tarun (00:36:58):
Like a billion dollar market cap. And its entire entire pitch was was a coin for dentists to use with each other. Didn't even have like a good pitch. Oh,

Brendan (00:37:08):
Wouldn't wouldn't that? So I'm, I'm a, I guess full disclosure, like a crypto investment idiot. But if you had something like denta coin, that was just notorious, wouldn't it sort of make sense to accumulate a large position? Oh, like, like when it was at the bottom, because you know that people will always be talking about that.

Tarun (00:37:25):
Oh,

AnnaRose (00:37:26):
It might just be at the next dog going. <Laugh> why not from dogs from, to dentist dentists.

Tarun (00:37:34):
I mean, I I agree, but it, it depends on whether you're an Anon crypto investor. This

AnnaRose (00:37:39):
Is not financial advice

Tarun (00:37:41):
Or whether you're a self-respecting one and you

Brendan (00:37:43):
Just put it in your ENS. Oh

Tarun (00:37:45):
No. Yeah, exactly. Well, you know, I think you know, if we're thinking about other technologies or at least things in science there, there's kind of this funny, weird thing where crypto and AI, maybe that's the reason they keep popping up and like you see really bad ICOs that don't really make any sense or around this is that they, they have this, they both are, are like the ultimate narrative storytelling, right? Like they both have these like different versions of the world. They're easy to tell a lot of people there's been a lot of advancement. You can be like, ah, I can impact people's lives more directly.

Guillermo (00:38:17):
There's a point to specific things too. Right? Like that ha that have happened and these things in these fields. Right,

Tarun (00:38:21):
Right. Yeah, yeah, yeah, exactly. Like you can, you can point some impact that like, you know, maybe not every person on earth can see exactly what they're doing, but you're like, okay, I kind of can get like a large portion of the planet's population. Appreciate them. Right. But one thing that's interesting is like adversarial models don't exist in, in science in some ways it's like

Guillermo (00:38:41):
Opposite adversarial, God just fucking with your experiments. I mean, that's

AnnaRose (00:38:44):
What is adversary in this case? Like what would it look like?

Tarun (00:38:48):
Peer review system is adversarial. Guillermo. Guillermo can tell you lots

AnnaRose (00:38:51):
Of wait, wait, could that be then I, you don't wanna, you don't, you wanna tokenize it. I'm like tokenizing.

Tarun (00:38:59):
You don't wanna be the Desi stuff. That stuff is like half

AnnaRose (00:39:03):
Desi,

Tarun (00:39:04):
Decentralized science there. You, you go <laugh> learn you anything.

AnnaRose (00:39:08):
Is it cool?

Tarun (00:39:10):
No. Okay. <Laugh> but decentralized peer review or like having a way of paying people, people who do peer review somehow would maybe that

Guillermo (00:39:18):
Might be interesting. Yeah. The question's how do you align in subjects? Well,

Tarun (00:39:21):
Actually you as the only actual PhD in this room. Oh God, I, you don't have one here yet. Right? Okay. You as the only actual PhD in this room, what You should explain the problems and pitfalls of peer review, the pros and cons, you know, explain how it works. Cause like people might not okay. That's right. That's right. Cause in crypto, a lot of people never like publish their papers. They're just like put, they just put an archive Eprint. Yeah. So,

Guillermo (00:39:42):
So yeah. Yeah. So, so the peer review process is, you know, you submit a paper usually to some cranky old people who are

Tarun (00:39:48):
A

Guillermo (00:39:49):
Conference

Tarun (00:39:50):
Tenured, tenured cranks and tenure are very correlated. That's right. That's

Guillermo (00:39:54):
Right, indeed. And what happens usually is, you know, you get some pretty good comments back. So, so often, often people are actually quite nice and they're like, oh, this is good or interesting. And then every once in a while you get one reviewer who just absolutely shits on your paper and says, sorry, like, it doesn't matter what you do, but like there's no way you could ever get this in because like X or Y or Z reasons, this is not always true. Often people are generally nice. But the, the point is, you know, there's this weird system also, by the way, the, the fact that I'm gonna go on a little side rant here is that peer review is the golden standard. Is it it's a standard. It is a shit standard. And I'm not saying like, there are like necessarily better standards I can think of immediately, but it is a garbage standard. And everyone tells you, like, it's not a peer reviewed study. You should tell them like any number of things are not peer reviewed that are useful. Like jumping out of an airplane probably causes death of high probability is a particularly useful thing that we have not peer reviewed.

Tarun (00:40:42):
Well, well, an interesting thing is that like, we've actually developed these kind of like meta adversarial things against peer peer view, peer review, like P P value hacking. So it's

Guillermo (00:40:51):
Beautiful.

Tarun (00:40:51):
So, so P values are just like under a lot of very stringent assumptions, a way of like measuring, like, Hey, like I did a hypothesis test that says is it possible for the opposite of my conclusion to be true? I

Guillermo (00:41:03):
Still don't think most people can define what a P value is, who use P values in their papers. That's my hot to, that's

Tarun (00:41:08):
True,

Guillermo (00:41:08):
Actually, Actually. Yeah.

Tarun (00:41:11):
But, but, but the idea of a P value is it tells you sort of an estimation of the probability that your, your prediction of solution to hypothesis is incorrect and people interpret it as a percentage. So if I say P equals 5%, that means that I have 95% confidence that the hypothesis is true. But the problem is, yeah. The note definition of a P value assumes a certain model for how you generate the data, how you actually compute what the error probability is.

Guillermo (00:41:37):
It's just central limit. The dude. It's just like, it's obviously a caution. Everything's obvious everything, everything CLT, independent ID, CLT

Tarun (00:41:44):
Humans exist because all their molecules are

Guillermo (00:41:46):
In are independent. That's exactly right.

AnnaRose (00:41:48):
<Laugh> okay. I think that's a good one here. Here's a small question. Has anyone explored, like reviewing the peer reviewers? Mm. Like, has there been an evaluation technique on peer reviewers ever? The answer is attempted

Guillermo (00:42:00):
Maybe not evaluation on peer reviewers, but often like open peer review is a thing that happens, for example, in AI a lot. Right? Oh, where you peer reviewers, like when they post the review. So you have to post your paper online. Okay. Publicly social for everyone to see and reviewers have to post their reviews online also publicly assessment. Interesting. Even though they are pseudonymous. Oh, so they do have an identity, but it's like, no, no point is that you can't often you can't track

AnnaRose (00:42:25):
Thumbs up, thumbs down,

Guillermo (00:42:26):
Roughly

AnnaRose (00:42:28):
The wisdom of the crowd. Oh

Guillermo (00:42:30):
Yeah. Is the crowd

AnnaRose (00:42:31):
Don't don't you worry about that a little bit. Like, because then that's, gameable,

Guillermo (00:42:35):
That's just hilarious. You hire

AnnaRose (00:42:36):
A bunch

Tarun (00:42:36):
Of bots. This, this is exactly why, like there has to be some weird solution that maybe it's not like crypto itself

Guillermo (00:42:43):
Tokenize it

AnnaRose (00:42:44):
<Laugh> tokenize it

Guillermo (00:42:47):
Go. <Laugh>

AnnaRose (00:42:48):
It's a terrible idea. Nailed it. But we should make the jingle. Oh

Guillermo (00:42:51):
No. We'll just come

AnnaRose (00:42:51):
In once in a while.

Guillermo (00:42:53):
I just there's

Tarun (00:42:55):
Sound, think the craziest thing about peer review is it reminds it's it's you know, there's a lot of like labor abuse that exists in a lot of like established very like high 

Guillermo (00:43:05):
Garbage fields. Sorry, I didn't

Tarun (00:43:06):
Say that. No, no high. No, not that I, I mean more like high sort of like societal value fields, even though they might not be like a large part of the economy. So like in fashion, in music, in like art, there's like tons of unpaid internship intern. I'm putting air quotes on it. Like there's a lot of these unpaid jobs and people are, or like people who pay for them in some cases. And they basically effectively are jobs where it's like, Hey, I get to say, I like status work. It's the status thing. Right. You're

AnnaRose (00:43:34):
Paid in status.

Tarun (00:43:35):
But the weird thing is usually that happens to people early in their career. Yeah. The peer review system is actually kinda opposite people later in their career. Don't get paid to review all these papers for free. And then ... And publishers are the ones who sell it back to the university.

AnnaRose (00:43:49):
Yeah. Wait, is it status there though? Are they status peer reviewing? Why do they do it? 

Guillermo (00:43:53):
In part

AnnaRose (00:43:53):
I think they have to,

Tarun (00:43:54):
Well, no, no, no. A collusion effect. You actually want other people to basically be saying like, your papers are good. And there's kind of like a, like EV

AnnaRose (00:44:03):
Wait, are you saying like you, right. You don't become a peer reviewer by

Tarun (00:44:07):
Reviewing. You're able to like express your preferences. Not necessarily objective. Okay. And about what

AnnaRose (00:44:13):
About your own papers? You

Tarun (00:44:15):
Might say things like, Hey, cite me in a peer view. People say it all the time,

AnnaRose (00:44:19):
But do you get to shape the narrative in a weird way? Do you get to direct ideas towards your idea? You're

Guillermo (00:44:25):
A producer.

Tarun (00:44:25):
It's like the difference between producer and director in a movie.

Guillermo (00:44:27):
That's right. But you also gotta say yes. And they are the

AnnaRose (00:44:30):
Producer.

Tarun (00:44:30):
I think they're kind of the producer. Right?

AnnaRose (00:44:33):
Okay. Cause yeah, they don't create the, the art. They don't create the world. Yeah, that's right. That's right. They're like, I want you to give it like a little bit more superhero

Tarun (00:44:42):
For whatever this conference, the, the, the sort of essence of this conference is X and this paper does not meet the essence of this. Right, right. Right. Well, what does the fucking essence of the conference mean? Well, it's like, whatever that reviewer thinks wants,

Guillermo (00:44:56):
But, but also,

AnnaRose (00:44:56):
I mean, and whatever their work may represent. Right,

Guillermo (00:44:58):
Exactly. You also got to do it via like kind of quasi censorship effect. Right? Like you also get to vote down on papers that you don't think should make it. And dependent of, like, there might be many reasons why this is true. Of course, many papers are usually garbage, even those that are published, but really speaking. Right. Like there is a censorship idea of like someone tries to publish something that you kind of don't think is interesting or doesn't fit the narrative. Even though it might be interesting in like a very general sense. But like, of course we only have our own weird subjective things. Right. And you just got to like download it and be like, sorry, actually this is not that interesting at the end of the day, even though it might be a very interesting topic. And, and again, this is always true,

AnnaRose (00:45:30):
Interesting that there's like voting, you're voting. There's why there's something,

Tarun (00:45:36):
This is why a lot of the, this is why a lot of the crypto stuff somehow should intersect here. Yeah. And also get rid of a lot of the labor abuse because like, right in my mind, there's this huge labor abuse going on. You ask us for status, but also someone is making money off this. Right. And it's fucking crazy when you're a professor at a university you're reviewing and then you go to a publisher like Elsevere or nature or science. And then the publisher is the one who's like, Hey, give us reviews for free. Yep. And then the publisher sells that back to your institution. Yep. Like that is the ultimate scam. Like, like they're the taking free labor and it's all based on the brand of the journal and the impact factor and some fucking metrics that are gamed.

AnnaRose (00:46:18):
I mean, okay. One, are they making a,

Guillermo (00:46:20):
A lot of money? Yes. Their margins are like, they're like over

Tarun (00:46:23):
50%.

Guillermo (00:46:24):
Yeah. Okay. There we go. 80% as,

Tarun (00:46:26):
I mean, it's not like, they're not like bigg growing businesses, but they're like 10 billion businesses.

AnnaRose (00:46:29):
They're like stable businesses maybe

Tarun (00:46:33):
Of free, very high skill labor. In fact, the like medium skill labor, the ones who are like distributing in the sales and whatever they're getting paid with the highest skill labor. Isn't, it's the opposite of the art music in right.

AnnaRose (00:46:44):
Owns them though.

Tarun (00:46:46):
Who? The public companies.

AnnaRose (00:46:48):
Oh, they're okay. They're

Tarun (00:46:48):
Huge public companies. Are they? Yeah. We're in the Netherlands. The home

Guillermo (00:46:53):
Actually, right.

AnnaRose (00:46:54):
Journals.

Tarun (00:46:55):
Yeah. Yeah, yeah. Journals. There's these aggregation company, but it's

AnnaRose (00:46:58):
Aggregation. Nothing thing about this journal where I, I mean, I know they exist. I know that like, but like

Tarun (00:47:03):
Think you, do you get why the labor thing is like kind of an abusive labor thing, right? Like it's like, why are the professors and grad students doing this for free and then their institutions paying to buy back their labor labor

AnnaRose (00:47:12):
Thing. And at the same time, like the right now, as you described this, all I can think is it's, it's gonna go out the door. Like there's no way

Tarun (00:47:20):
Sort of,

AnnaRose (00:47:20):
And, and how annoyed will they be when that happens? Like the industry in 1999,

Tarun (00:47:25):
The thing is AI and high energy physics and math have moved off the journal system. They do everything in pre-prints. There are journals, but only when it's like really seminal, like, you know, Terence towel prove some weird kind of crazy. So

AnnaRose (00:47:38):
Wait, who's on it then.

Tarun (00:47:41):
Well, no, no, everything is just done on the internet more publicly and then

Guillermo (00:47:45):
Submitted to journals.

AnnaRose (00:47:46):
And then later you submit first. Oh, okay. You're so, but

Tarun (00:47:50):
The only certain fields, like if you go to biology it's no, no, you didn't publish nature. Like, what are you doing? Like your career is shit. Like, there's, there's a lot of this status and stuff that like you see in like art music, finance, or art music. Sort of like

Guillermo (00:48:02):
The crazy part though, is it's not just the reviews though. It's literally like the papers themselves are like essentially done for free, right? Like, like the, a lot of the work that goes into not just like reviews, but also the papers like just gets done for these like publishers for free. And then they go and sell it back. And I mean, in a lot of cases in math and computer science and physics, it's very, very common to upload your pre-prints first mm-hmm <affirmative>. So it's always available publicly online, but in some cases, actually not like you will get sued if you, you like publish your papers online for free, and then like try to publish it like afterwards

AnnaRose (00:48:34):
And stuff. Like, wait, you just said like a bunch of fields moved off it that's right. How does that work? Then?

Tarun (00:48:39):
They just started publishing on the internet. So archive which is sort of the main pre preprint archive was created by Paul Ginsberg, who is a physics professor at Cornell. Yeah. Who famously I remember when I was an undergrad there, he they built a new physics building and he, he's kind of a true, true hippie, like, and he was like in his office and I guess he like passed out in his office and then like the police came and like were like, oh, this homeless guy, like sleeping. And then there was, yeah. So I remember that was like one of the funniest things that happened. This is like 2007 or eight or something. Oh God.

Guillermo (00:49:17):
I Was Dying. That's really funny.

Tarun (00:49:19):
But he, he, he's an interesting character. And so like idea was that a lot of H energy physics research? A little bit like AI at that time, like, obviously in a different scale was stuff where there was stuff that was done in empirical stuff. So people at particle accelerators mm-hmm <affirmative> were kind of writing technical reports on like things they saw that were sort of like the way Giermo. And I started writing papers, we just like post 'em online. We would see what feedback is before we refine them. Yep. People would just post those and they'd usually only share them within each elevators, like CERN particle, CERN, Switzerland. They would have their own technical part. That's mailing List.

AnnaRose (00:49:56):
That's Their Mailing peer review cuz peers actually

Tarun (00:49:59):
Peer, but

Guillermo (00:50:00):
It's huge.

Tarun (00:50:01):
Right. It's sort of like push, not pull or, or, or vice versa, pull, not push, like you'd use post it. And then if people review, it's not like a thing where you're forcing people to

AnnaRose (00:50:09):
People will comment. Right. Exactly.

Tarun (00:50:12):
And so then a bunch of the different particle accelerators, like started realizing like, Hey, we actually should be like sharing our technical reports. Yeah. They're not finished. But if we like shared some of that, we would like probably save someone like some dead ends that they couldn't go to

Guillermo (00:50:26):
Also catch early mistakes too.

Tarun (00:50:27):
A lot catch. Yeah. I mean like

Guillermo (00:50:29):
The whatever, super Luminal nutrinos and all this stuff. Right.

Tarun (00:50:32):
Right. Well, we were at a, We were a time where like barons were still not classified fully. So

Guillermo (00:50:39):
We, this is jumping ahead on the timeline, but I, when was like, this was caught before, like went out, I

Tarun (00:50:44):
Think people who were like at the boundary of the theory and production, like people who are trying to take theory and like do really hard experiments to like validate really complicated theory. They oftentimes need, and it's not, not true that like other fields don't have this, but like, for some reason that ends up being this space where people want to make these kind of like right. Very quick intellectual works that they share quickly rather than like, have to go through the whole full peer review process. And so that was where it started. And that sort of is how was sort of yeah. The, the for formation, the Genesis of, of archive. But then of course the most famous thing was par. Who, who, who on field medal and kind of went to go live in SI goat and whatever. Yeah. True goat, true goat, true goat. None of us are none of he you know, he posted this proof of like this, this very famous conjecture on archive never, never got peer reviewed. And then it turned out it was right. And like he won this million dollar prize and he hated, he hated society for giving him a million dollars. So then he went to go live as a recluse with his mother or in Siberia. That's

Guillermo (00:51:49):
Right.

Brendan (00:51:49):
I thought, I thought he was working on the reman or

Tarun (00:51:52):
Conjecture point. No,

Brendan (00:51:54):
No, no, no, no. So I know that he proved the <inaudible> Conjecture, but I, I thought that people speculated that he hadn't actually like retired entirely from, oh,

Tarun (00:52:01):
I'm sure he is not retired, but he hates institution. He basically was like, why does it matter that I am an academic institution? If I, I published something that was correct

Guillermo (00:52:10):
And there's

Tarun (00:52:11):
Truth. And there's both like good things and bad things, institutions are a heuristic. They let you like assume a lot of things without having to like actually spend years figuring them out at the same time, he has a good point of like, there was like, he, he was able to kinda like do a lot of stuff in his own. So I, I, but I don't know if he would be doing <inaudible> Because like, his background is more in like

Guillermo (00:52:32):
Richie

Tarun (00:52:33):
Flow and like probability stuff, measure theory, all the shit that like GMO hates, Hey, no, it's true. It's like, literally, literally like say one of my undergrad advisors like proved this measure theory, inequality that was used in that paper. And like, when I looked at the proof of that, I was like, this is all like in reality, like no fucking thing. That's like really, you know, homo... Equivalent at three sphere, whatever fucking look like this edge case. And that's like the GMO, like measure theory is useless thing. No.

Guillermo (00:53:00):
Okay. Now I'm on the measure theory thing. I wanna set the record straight. I don't hate measure theory. I actually find it quite beautiful. Right. Like I have studied measure theory, Stochastic, you know, whatever process is stochastic differential equations, the whole thing. Right. But like my point is what I'm pushing back against a lot. And I do this a lot is like in papers, it's very easy to go down a fucking rabbit hole of just like proving a bunch of shit that turns out to kind of be irrelevant. And it's really obvious if you know, like basic real analysis or, you know, basic measure theory, but like reviewers will come back to you and be like, oh, but like, how do you know this in like, dude, it's literally three lines. Like if you, if you took an undergrad class in this thing, you would know what

Tarun (00:53:38):
I, one place I will disagree with this is that, you know, there there's a lot of like counter examples that generally come up from you not stating the correct assumptions. No,

Guillermo (00:53:48):
No, but, but like, okay. Okay. So being very clear here in, in our papers, we, we state the exact assumptions.

Tarun (00:53:55):
Yeah. We, ours are not like real math. No, no, this is fine.

Guillermo (00:53:58):
This is

Tarun (00:53:58):
Very D not like, I mean like actual, like yeah. Aesthetically pretty math is very Different I mean, like

Guillermo (00:54:03):
Even, even whatever, like the Jordan curve, the right is really easy to prove in the case where you assume that everything is differential or like point wise.

Tarun (00:54:10):
I mean, it's homework problem, but that no, no,

Guillermo (00:54:12):
No, but it's not homework problem now. Right? The general case is pretty hard. The general case isn't even, isn't even true. All courses. I'll sorry. Sorry.

AnnaRose (00:54:19):
Can I actually bring us back to peer review? Cause I was so down.

Tarun (00:54:22):
Yeah. Gear just doesn't like me making fun of this, but this is actually you something I personally face in peer review where we're like, usually people are just like, oh, like you like, didn't mention this complicated counter example. And I usually am like, oh yeah, you're right. You on the other hand, like, no, no, no. My definition should have restricted it so that you never had that fucking that's right. That's

Speaker 11 (00:54:40):
Right. Yeah. Absolutely.

Guillermo (00:54:41):
But

Tarun (00:54:42):
No, that's a philosophical difference. No,

Guillermo (00:54:43):
No. But my, my point is like, I, I don't, it's not that I don't think that people shouldn't be careful is that like, I think people should be extremely careful, but in the paper it does not matter like you, if you knew the thing you needed, like if you knew the exact, for example, in one of our cases, we have somebody that like is technically not necessarily even like integerable in like a usual sense. It is like LA bay integerable, but not like normal reman integerable.

Tarun (00:55:09):
Oh, you mean the optimal fees paper?

Guillermo (00:55:10):
No. In the,

AnnaRose (00:55:11):
I love that we've fed you this much mezcal. Sorry. And you're arguing right now about a very specific part. This

Tarun (00:55:17):
Is like, you may have to, you may have to cut this cause this is like, so in the, I know,

AnnaRose (00:55:22):
I know we're gonna leave it, but I, I might bring us back.

Tarun (00:55:26):
I'm fine.

AnnaRose (00:55:27):
Because actually it sounds like what you were actually proposing. I don't think we've proposed a solution. I think we've oh, to the a problem. Right? Right. I think we've said, Hey, there's a problem. It's also, I mean, it's a problem for ZK papers as well.

Brendan (00:55:41):
Yes. It's a problem. We've actually run into, but

AnnaRose (00:55:46):
Tell us

Tarun (00:55:48):
I'm no, I'm not gonna say, wait, wait, wait, wait, wait, wait. But even, even if he's not gonna say one, I think the, the, the, the plunk trail of bits thing is a really great example. Right? Where like a mistake in the paper was never verified until like later by a auditor trail

AnnaRose (00:56:02):
Of bits. The recent thing.

Tarun (00:56:03):
Yeah. Yeah. Yeah. And like, to some extent, I remember when I first convinced GMO that crypto wasn't a scam am. I was like, Hey, like, he's like, what's the cool thing. I was like, yo, there's all these papers. They use a lot of algebras and you're not gonna like it, but it's like zero knowledge stuff. <Laugh> and he was just like, yeah, I can't even fucking verify any other fucking proofs. Like they, they like standard their standard. Their standard of proof is like weird.

Guillermo (00:56:25):
Even,

Brendan (00:56:25):
Even the notation is no,

Guillermo (00:56:26):
No it's yeah. Yeah. There's the whole subscripts and superscripts. And you know, you have functions that depend on eight different things, even though like seven of those are completely irrelevant. Yeah. Sorry. Anyways, but, but besides point, sorry, because

Tarun (00:56:37):
Everyone likes to write out the proof as like they write out the full algorithm algorithm instead

Guillermo (00:56:41):
Of like completely

Tarun (00:56:42):
The component, which like,

Guillermo (00:56:43):
It's like

Tarun (00:56:43):
A cryptographer style difference between like

Guillermo (00:56:46):
Math people, between normal people and cryptographers you,

Brendan (00:56:49):
You should just teach one cryptographer, Einstein, summation notation. Oh, that would spread like a virus.

Guillermo (00:56:56):
Actually. I, I think,

Tarun (00:56:57):
I, I don't think it would I feel like they, like, they don't like they like writing like five millions. My,

Guillermo (00:57:02):
My hottest take is that I think teaching cryptographers like a normal linear algebra course would do like wonders for humanity where you don't actually have to write out the sums for 90% of these things. You just define them as linear operators. Anyways.

Tarun (00:57:17):
Another, another, another thing I think that's like kind of a, a stylistic difference. You oftentimes see when you like read applied by math papers from different fields is like some people like writing papers in a, a sense of like, oh, like here is actually the most general possible, oh, mathematical thing that like, sort of correlates to this scenario. Even though like, if I look at the set of all possible things, you defined less than one, 1000000th of a big point of the possible things is actually like, you think that you care about. And the other type of people are like people who define things too narrowly. And they're like, are like it's too, to my use case. Mm-Hmm <affirmative>. And then like, you can't use it somewhere else. And there's always this kind of trade off in applied research of like, do I make the most general thing or do I make the specific thing? You kind of like, have to learn that in like some ways. And I just feel like ZK people haven't figured out their sweet spot for that. And AI people were the same. Like they, it took them a fucking long time. They haven't 20 years. I would, I would say they don't, but it much better than it was in the nineties. No,

Guillermo (00:58:19):
This is, this is quite true. I even, I wouldn't even say their early two thousands. I mean, some of like, look, you read a lot of the papers, like even random kitchen sinks. There's like a pretty simple paper. It's kind of illegible the original time around.

AnnaRose (00:58:29):
I feel like there's two things happening here though. It's like one question here is like, how do we better peer review ZK papers? And the other question is how do we fix peer review? Sorry, this

Guillermo (00:58:37):
Is how we, there are topics.

Tarun (00:58:40):
We're we're we're

Guillermo (00:58:41):
We're

AnnaRose (00:58:42):
Do we use ZKP to fix peer review? Oh

Tarun (00:58:45):
No.

Guillermo (00:58:46):
Well, you didn't have a shit post office, didn't you?

Tarun (00:58:48):
Yeah. Yeah. I, I, I wrote that making fun of defi people though. Really? But like, it was a subtree I don't think anyone really got it. <Laugh> unfortunately

Guillermo (00:58:55):
It's fine. It's fine. I got it. Yeah.

Tarun (00:58:57):
I

Guillermo (00:58:57):
You're understood really. I was pretty, I think I retweeted the,

Tarun (00:59:00):
The, the alt har cartel. Cheers. The altcartel. I guess like the, the, the main, main thing of this, these like stylistic differences. Yeah. Though, for things that have to be very precise. Is that which

AnnaRose (00:59:17):
Part are we talking about by the way we're talking about like ZK being peer reviewed or,

Tarun (00:59:22):
Well, well, well, we are getting back to that, but we're kind of talking about like this idea that like, what is written in the paper, how do you actually verify the proof is correct. Right. And, and like, Guillermo's philosophy is that the implementation needs is the actual proof. Like if the implementation works, which is definitely true, like that's the most true form, but there's also a sense in which the style in which things are written can also be adversarial to the reader. And then peer reviewers just go, LGTM looks good to me. <Laugh>

Speaker 12 (00:59:52):
Plus one lazy comes up

Tarun (00:59:54):
Like code review has the same problem, like for the record.

Brendan (00:59:58):
And, and, and I think this like is actually really important because especially in fri, there's a lot of like, sort of ambiguity and soundness and there's some conjectures. And like, I, I feel like there could have been more attention placed on that if it was a little bit more clear that those existed and like how they functioned and real protocols. And so

AnnaRose (01:00:16):
Is this you finding this out because of like actually trying to implement it?

Brendan (01:00:20):
Yeah. Yeah. So, yeah. So, so we rely on a soundness conjecture that has not been formally proven. I believe really starkware does as well. But it it's like, it would be nice if there, if there were more attention and formal proofs, but

Tarun (01:00:34):
<Laugh> that, that last friend

AnnaRose (01:00:36):
Is annoyed because we're just pouring more. He's he asked us at the beginning of this interview, actually, do I have, have to,

Guillermo (01:00:43):
And the answer is yes.

AnnaRose (01:00:44):
Drink all of it.

Tarun (01:00:45):
The answer was always yes.

Guillermo (01:00:46):
Yes. because as of now there is a bottle of mescal that is officially empty.

AnnaRose (01:00:52):
Very nice just to the listener. This is not the future of the ZK podcast. <Laugh> we will have normal ZK podcast episodes soon <laugh>, but week it's a week of Amsterdam. And honestly, there's a lot here happening here. <Laugh> 

Tarun (01:01:09):
I, I guess, like one other thing that's like, kind of interesting about this, the trailofbits report is just that it kind of says like, oh, well, the peer review for these ZK things was this auditing firm deciding to like, go read the implement. Right. And so that's where I, I think there's, there's like kind of a notion of peer review that we haven't figured out push versus pull. And it, it, it it's like there, the academic version of the world is push. Like you send a centralized authority, the journal, which is some institution with some cultural definition for itself. Very much like NFT Doas, but hopefully smarter, but not all. Usually they're still humans.

AnnaRose (01:01:45):
Yeah. It's too, too early. Okay. Go.

Tarun (01:01:47):
And then, and then usually then they, they are like, push here's the, here are the papers to review. Here's what we think is cool. Here's whatever the, like the, the program committee type of thing. Mm-Hmm <affirmative> and then people review, and then you have the opposite, like the ZK world or the high energy physics world was like this before, where there was a lot more like pull, like we just shoved the shit online. And like, the problem is in the eighties, there was no one else posting content internet. So, but

AnnaRose (01:02:13):
In the case of an auditing firm doing it was, were they hired to do an audit and then found it,

Tarun (01:02:18):
Oh, I think they were hired to do one of the audits. And then they started doing the rest. Yeah. There's

Guillermo (01:02:22):
No way. This was like just like, oh, we got hired to do this. And therefore we like went into this. It got, it had to be like an internal thing. Right. I don't know. I mean, I'm just

Brendan (01:02:30):
Curious. Yeah. So, so I, I, I believe that they were hired, I, I think another wrinkle that's sort of interesting in this case is that this bug didn't exist everywhere. So certain teams had fixed it because like the, the

AnnaRose (01:02:42):
They spotted it

Brendan (01:02:43):
Or no, no, the, I think trail of bits spotted it, but, but yeah. So, so I, I think there's like a deeper, like maybe structural problem in ZK where there's like, not always that level of collaboration and right, right. And so not, they here. Yeah. Yeah. And so I, I think that's like interesting thing. I mean, because like the bug was fairly like straightforward. It was just not including public inputs in Fiat ... Oh, interest like a pretty like, yeah.

AnnaRose (01:03:10):
Basic

Tarun (01:03:13):
<Laugh>.

AnnaRose (01:03:14):
But, but actually just a question on that, like, what you just said was like, it wasn't the, I just asked, like, were, was it that like some teams had implemented it and then found that problem and changed something like, well, I, to me, the bug was in like some overarching, like research paper that was implemented in the way it was supposed to be. But you just said like, like you just said, like not everyone had the bug. I actually don't understand why they didn't.

Brendan (01:03:38):
Yeah. So, so I think my understanding I could be wrong is that in the plonk paper, it wasn't like it wasn't explicitly hashed into some input for Fiat ... And, or it wasn't included as, as part of the input. And that was true in both bullet proofs and in plunk, but there were a number of teams that just knew to do that. Yeah. Right, right. Yeah.

Tarun (01:04:02):
This is what I guess is,

AnnaRose (01:04:02):
That's what I thought it was implementation, but why did they not notice the problem? No,

Tarun (01:04:07):
No, no. The problem is people just open the paper and these crypto papers are written as like, here's the algorithm. It's a algorithm, but it's nots. Exactly. But I don't have to think about it because I assume the one in the paper is correct. There's there's

AnnaRose (01:04:20):
No, I get that. But I, the, what I don't get is like, why did somebody implement it correctly? Well, because, and fix that and not dis not, not like disclose, but why, like, why was that not communicated somehow it's

Guillermo (01:04:30):
Common that people have a lot of context when they read these papers. Right. It's not like in a lot of cases, right? You, the paper is the best to represent like a fairly high level, but reasonable idea of how one might implement this concretely. Right. And in a lot of cases, if you have enough context on the paper, it's very obvious to you that this is a thing you have to do, but one might call it an implementation detail. Right.

AnnaRose (01:04:49):
Is it almost like, because of who's actually making the changes, they're just not like super tapped into like the comms team. They're like, they're not gonna be the people who are like raising. Like,

Guillermo (01:04:59):
I mean, like, why would you

AnnaRose (01:05:00):
Escalating it up? They're just like, we're gonna, oh, this doesn't work. I'm gonna fix it. But then they don't, it doesn't go higher that people who have like, decided to use the paper, they're not aware.

Guillermo (01:05:11):
So in some sense, when you read the paper and you have enough context, it's almost an obvious thing. Right. It's a thing you just read. And you're like, yeah. I mean, of course, like they didn't do this check in the paper because it's like, you know, why would you do it? You should already know to do it. Right. But in general, this is not true. I mean, as we found clearly, right. You know, if, if you just implement straight algorithms in the paper and the same way as if you implement like a lot of like ran mathematical papers by just like reading the thing kind of front to back and be like, all right, here's what I need to do. <Affirmative> it's not immediately obvious that you have to do these like extra checks, these like, even like in a lot of cases, you're doing kind of a lot of reductions down into like something that you can actually use. So it's I think it's a lot of contextual questions that are not easy to answer.

AnnaRose (01:05:52):
This is, this is a bit of a like left field, but like coming back to Amsterdam where we are right now. Oh,

Guillermo (01:05:59):
No,

AnnaRose (01:06:00):
There were a few topics we had meant to talk about that we have not <laugh> because we've kind of run out of time, but I think

Guillermo (01:06:07):
We've also had a whole

Tarun (01:06:08):
Bottle of mezcal. I

AnnaRose (01:06:09):
Also think the conversation we had was pretty amazing, but I am wondering what are in a short moment, like, what are the take ways from this week? What are the, the ideas you had sort of said earlier on like idea wise, you didn't feel like necessarily inspired, but like, what do you think are the topics at least that are being discussed right now or something that you're thinking about?

Tarun (01:06:33):
I think mev day again and not to, to, to harp on it being, I, what I thought was a really great event. Congratulations to Tina for also give her, I wanna give her a shout, like clap and shout out, cuz that was, Tina's been putting out events for a long time, just like You Anna. And like, I feel like she had started by being renegade and rag tag and like would like do these free events and then

AnnaRose (01:06:57):
What the fuck? Defi. Yes, exactly. What the fuck? What was the other one? WTF?

Tarun (01:07:03):
Me, me

AnnaRose (01:07:05):
WTF.

Tarun (01:07:06):
So, so she like did these kind of like very grassroots events that like to see it grow to something is actually like, I, I, I, I just like feel like as, as her friend, I just feel like she like has clearly like built this awesome Institution around it. And also just like, I do think they got a lot of interesting talks. I, I, I don't think anyone answered the question that I care about personally and Guillermo, which is just like, how do you actually write down some type of like mathematical theory about MEV that like actually combines things that we know about. Like, I mean,

Guillermo (01:07:38):
As we found, it's

Tarun (01:07:38):
A part

Guillermo (01:07:40):
It's very hard

Tarun (01:07:40):
To answer. Cause there's some notion of like subjectivity of value, but there's also some notion of like optimality when you have many parties like defining the social welfare of like all the participants is actually quite hard. It might actually be in some cases. And I think this is something I, I really kind of felt a lot from that mevday is like the existence of MEV for a lot of chains actually is a good thing. It like drives volume there <laugh> and it actually has these like weird, ironic effects of like, oh, volume increased because people are getting sandwiched, oh, people add more liquidity, cuz they're like, oh, there's more volume here. And it like has this weird like growth hacking bootstrap effect,

Guillermo (01:08:18):
Bad metrics, but also interesting. Are, are

AnnaRose (01:08:19):
You an ex, what is it accelerationist as

Tarun (01:08:23):
Like Dean kept saying <laugh> I, I, I am not per se. I do think Dean had a very funny comment, which is like, I would never use a chain that I make money from. Ooh.

Guillermo (01:08:33):
That is, that is actually, that

Tarun (01:08:34):
Was like, he was like, they're all centralized <laugh>

Speaker 13 (01:08:36):
That was like a very harsh

Guillermo (01:08:38):
That was actually, yeah. Yeah. He like, I will not mention them Bri, but you know, but

Tarun (01:08:41):
Then he just said BSC, like almost the neck, he's like there's 21 validators and 11 of them are owned by an exchange.

Speaker 13 (01:08:48):
Was like,

AnnaRose (01:08:49):
He actually said that on the episode we did with him. Oh he

Guillermo (01:08:51):
Did he okay. That's all clear.

Tarun (01:08:52):
Yeah.

Guillermo (01:08:53):
Yeah.

Tarun (01:08:53):
He,

AnnaRose (01:08:54):
I think it's pretty, I

Guillermo (01:08:55):
Feel, I feel like it's the MEV chain though. Like as far as I know, there's like several people on it. Everyone is just like there just to make money. But

Tarun (01:09:02):
The it's not just that it's also just, there's a lot of like retail usage in south America in Asia that

Guillermo (01:09:07):
Uses oh, is there BSC?

Tarun (01:09:08):
Yeah. I mean it, binance binance has extremely high

Guillermo (01:09:12):
In Asia, in south America.

Tarun (01:09:15):
So in south BUSD is actually people basically do remittances by just sending BUSD between Binance and not

Guillermo (01:09:21):
UST.

Tarun (01:09:22):
No, apparently because like most of them, their only gateway is like Binance. Binance is a huge penetration in south America. Wow. Holy Yeah. Not, not, not central America, south

Guillermo (01:09:33):
America, south here. Proper

Tarun (01:09:34):
Definitely south south per se, cuz like yeah, in sure Bitso and stuff definitely own Mexico and that area, but it, it is, it is, is actually quite interesting that a lot of the capital influences are basically Latin America and Asia and the reason there's so much BUSD demand comes from, from people who are basically using Binance as their, as their bank in places

Guillermo (01:09:54):
You don't like whatever, 5000% inflation in Venezuela, you know, there's, there's better inflationary, not inflationary tools.

Tarun (01:10:02):
Is Venezuelan. So he has firsthand experience with O like inflation and

Guillermo (01:10:07):
That's right. That's right. And it did not have provable bounds of like or read most recent paper or whatever. You know,

Tarun (01:10:12):
The thing that was interesting is like, I think one thing that has been kind of, of the narrative around MEV is generally like it's predatory, it's bad. It's whatever. Mm. But I, I, I think like there are conditions and like, if you could understand the theory, you can actually understand a little more of like, when it actually is useful for a network it's not necessarily always bad, which I think maybe is like a contrarian thing to say, but it actually is useful for some, I I'm not like in some cases it is extracting value from users. No doubt. But in some cases it's actually like increasing liquidity for users. So like interesting. If the amount that taken from them versus the like decrease in transaction costs is different than like, it actually can be positive and listening to a lot of the people talking, especially the traders was actually like more surprised at like some of the things they were saying where, where like, they, they effectively increased their participation in certain networks because they were doing MEV on them, which improves user quality.

Guillermo (01:11:12):
And so, I mean, it certainly improves like with

AnnaRose (01:11:14):
The bad comes the good, right,

Guillermo (01:11:17):
Right. So like, I just don't

Tarun (01:11:18):
Like this kind of like, you know, look,

AnnaRose (01:11:19):
Everyone,

Tarun (01:11:20):
Humans

AnnaRose (01:11:20):
Love, I still put them in the category of bad.

Guillermo (01:11:23):
Humans,

Tarun (01:11:24):
Humans love false dichotomy. That's right. They love this idea of this binary classifier that you just like always just, you rely on as ultimate heuristic. The worst one of the internet has produced is the word cell and shape rotator one. Oh

Guillermo (01:11:38):
No, you're not mentioning this this episode. No youre not. You are not bringing up the other Tarun in this episode.

Tarun (01:11:46):
I'd say the worst binary sort of classification dichotomy that humans have that have made on the internet this last year is the word cell versus shape rotator

Guillermo (01:11:58):
Word,

AnnaRose (01:11:59):
Word, cell versus versus

Guillermo (01:12:01):
Shape rotator

AnnaRose (01:12:02):
Shape. Rotator

Guillermo (01:12:04):
Couldn't I cannot believe is, is to ruin. No,

Tarun (01:12:08):
Don't worry. I'm not going to vibe camp. I'm sorry. I'm sorry, everyone. Brooke

Guillermo (01:12:12):
Promise.

Tarun (01:12:14):
I promise. I promise I'm not in the center for applied rationality. <Laugh>

Guillermo (01:12:18):
Well, I think that's everyone who is like X center for applied rationality, right?

Tarun (01:12:22):
Yeah. So I, I, I guess the, the point I, I, I wanna kind of maybe put across is like MEV day as a really interesting event. Having worked in high frequency trading before is like, you would never have that type of conference and people would never be that honest about kind of like what

AnnaRose (01:12:40):
They

Tarun (01:12:41):
Do. And you would also not get the feeling that there were a lot of people there who were like, oh yeah, like actually there's some positives to it for certain networks and certain types of applications do do better when you have that. And as application in base protocol security start getting more intertwined. You, we are gonna inevitably see that, like there's going to be good MEV and bad MEV, and it's kind of going to be too much of a catch all phrase that doesn't actually capture the nuance

AnnaRose (01:13:08):
Of. I did. I did actually notice just generally this week, the use of the word, mev kind of constantly confused. It's even like

Tarun (01:13:17):
ZK and me both me use when they're not, they're like

AnnaRose (01:13:20):
Supposed to yeah. It's like me equals sandwiching equal and that's the only way. And it's always bad and it's kind of ruthless and then like, someone's like, no, it's more complicated. And then it's complicated to actually describe why it's more nuanced.

Tarun (01:13:33):
My, my favorite kind of, you know, of the like six or seven, whatever panels I, I in talks, I did the one that was, did

AnnaRose (01:13:42):
Not attended was on and moderated. Yeah, intense

Tarun (01:13:47):
Man. It was was one where Phil Diane was a moderator and he brought Eric Budish who is a famous academic from IL, Chicago who invented this concept of the batch auction, which was supposed to kind of destroy HFT. And like, of course we've, it's turned out. It didn't, it didn't work. It didn't, it didn't it, in fact like didn't work fully like, like, like I think the theory has a lot of merit, but one interesting thing I learned from this talk, you know, I've had a lot of respect for Budish's work. But interestingly, I learned Phil, first of all, was quite inspired by Budish and that's sort of how he got into thinking about flash bots, because he was like, how do we make a batch auction for this stuff? Because of, I know, I know, but like, look, look, that's just someone's life, their story.

Tarun (01:14:27):
And so no, that's interesting. Yeah. And, and so, and then I basically was kind of, we were on this panel and like, it's very interesting because like you have me and Lev and some Felix from cowswap and the three of us are like way more in the weeds and like, thinking about like the kind of transaction level details, technical details. And then we have like, Phil who's kind of like the philosopher king moderator. And then we have Eric Budish, who's like economist who like, probably couldn't write code, like who couldn't tell you anything about Ethereum transaction ordering to save his life. But he clearly had this kind of view that he's like, yes, this is going to like, we're going to like, implement all my ideas. And then we had like, you know, Lev and me and, and, and Felix giving a lot interesting counter samples.

Tarun (01:15:12):
And one thing that was very clear at the end of this was that like, Budshi left this thing, thinking that like, he came in thinking that like flash bots was just his idea kind of like implemented and like, it provided the same benefits. And I think he left feeling like, oh fuck, actually <laugh> actually, it's like more complicated. It's not always bad. Like, like there was like all these like interesting. And so that's kind of where I think sometimes the, this like being able to kind of have the dialectic, ironically given Dean the dialectic and multi-lectic perspective on these things is actually extremely important. Fair enough.

AnnaRose (01:15:48):
Cool. I think this may bring us to the end of our episode. I, I feel like we could continue forever

Tarun (01:15:54):
If we're not careful, we might,

AnnaRose (01:15:56):
We might

Tarun (01:15:57):
Alcohol dilates time. Yes. That's fair enough.

AnnaRose (01:15:59):
But it was, it was an incredibly fun time and I'm so glad we had this conversation. Yeah. And even though we went a little off the ZK podcast track a little bit <laugh> I think it's good. Why not? No,

Tarun (01:16:14):
I think it's phenomenal.

AnnaRose (01:16:14):
I also feel like isn't it, isn't it time for this show to also like expand and evolve and allow for more spontaneity and more it's

Tarun (01:16:25):
A spicy take.

AnnaRose (01:16:26):
Yeah. Thank you, miss

Tarun (01:16:28):
<Laugh> cheers to

AnnaRose (01:16:29):
You miss anyways. Thank you guys for doing this interview. Yeah, it was fun and it went completely off what we had planned, but I think it's better this way.

Tarun (01:16:43):
I think you know, if you've never actually gone drinks with me, the number one thing you've hopefully learned from the episodes. I love saying the word of epistemology, the more alcohol, the more it's like more he drinks, the more, the more I drink, I say like philosophy, like kinda for better or worse. So <laugh> very nice. Well, thank you for having me. It's been lovely.

AnnaRose (01:17:04):
You know, thank you for coming back and Brendan, thanks for coming on for this like very spontaneous, insane interview.

Brendan (01:17:10):
Yeah. Thanks Anna. For having me, it was all of fun.

Tarun (01:17:13):
<Laugh> we, we in the process we did, we did anoint the polygon polynomials, which

AnnaRose (01:17:18):
Is gonna happen, which is good. I heard that happened on Twitter and now Tarun I heard is be real. The head of marketing. Oh yeah. Polygon,

Tarun (01:17:26):
JD, JD. Congratulations is our new position Tarun!

AnnaRose (01:17:29):
One tweet. <Laugh> all it took. All right. I wanna say thank you to the podcast team and to our listeners. Thanks for listening.

